{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3nXS4RUQQugV"
   },
   "source": [
    "# Tutorial Part-of-Speech tagging  Con Deep Learning\n",
    "\n",
    "### mb-01 Variacion en la estructura de la linea base del modelo Neuronal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WIheRrq2Quga"
   },
   "source": [
    "## PARTE 1  -  Pre-Procesamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lw10qukzQuge"
   },
   "outputs": [],
   "source": [
    "# Asegurar reproducibilidad\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "CUSTOM_SEED = 42\n",
    "np.random.seed(CUSTOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CxOcxDUmJcvL"
   },
   "source": [
    "### Descargamos el Corpus Ancora - Cess_esp del nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "NILevBJxQugr",
    "outputId": "b71b74d4-21a9-4a8e-b184-fcc2b0af12c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package cess_esp to /home/deep-\n",
      "[nltk_data]     learning/miniconda3/envs/tensorflow/lib/nltk_data...\n",
      "[nltk_data]   Package cess_esp is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('cess_esp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eqdUvUCEJjgc"
   },
   "source": [
    "### Extraemos las oraciones tageadas del Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ss3RHo4LQugx"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "from nltk.corpus import cess_esp\n",
    "\n",
    "tagged_sentences = cess_esp.tagged_sents()\n",
    "#print('a random sentence: \\n-> {}'.format(random.choice(sentences)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gCW_ENdLJudC"
   },
   "source": [
    "### Extraemos los datos de la cantidad de oraciones a ser usadas y un ejemplo de una oracion presente en el corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "colab_type": "code",
    "id": "2clQUNdtQug4",
    "outputId": "43ba74e5-5ad6-49da-a84f-288a8e04a64f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('El', 'da0ms0'), ('grupo', 'ncms000'), ('estatal', 'aq0cs0'), ('Electricité_de_France', 'np00000'), ('-Fpa-', 'Fpa'), ('EDF', 'np00000'), ('-Fpt-', 'Fpt'), ('anunció', 'vmis3s0'), ('hoy', 'rg'), (',', 'Fc'), ('jueves', 'W'), (',', 'Fc'), ('la', 'da0fs0'), ('compra', 'ncfs000'), ('del', 'spcms'), ('51_por_ciento', 'Zp'), ('de', 'sps00'), ('la', 'da0fs0'), ('empresa', 'ncfs000'), ('mexicana', 'aq0fs0'), ('Electricidad_Águila_de_Altamira', 'np00000'), ('-Fpa-', 'Fpa'), ('EAA', 'np00000'), ('-Fpt-', 'Fpt'), (',', 'Fc'), ('creada', 'aq0fsp'), ('por', 'sps00'), ('el', 'da0ms0'), ('japonés', 'aq0ms0'), ('Mitsubishi_Corporation', 'np00000'), ('para', 'sps00'), ('poner_en_marcha', 'vmn0000'), ('una', 'di0fs0'), ('central', 'ncfs000'), ('de', 'sps00'), ('gas', 'ncms000'), ('de', 'sps00'), ('495', 'Z'), ('megavatios', 'ncmp000'), ('.', 'Fp')]\n",
      "Tagged sentences:  6030\n",
      "Tagged words: 192685\n"
     ]
    }
   ],
   "source": [
    "print(tagged_sentences[0])\n",
    "print(\"Tagged sentences: \", len(tagged_sentences))\n",
    "print(\"Tagged words:\", len(cess_esp.tagged_words()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "i_aFjuCQKG1O"
   },
   "source": [
    "### Se procede a Dividir en una lista de Oraciones dividida en lista de palabras y cada palabra con un correspondiente tag en un alista diferente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "516a_v5vQuhC"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    " \n",
    "sentences, tagss =[], [] \n",
    "for tagged_sentence in tagged_sentences:\n",
    "    sentence, tags = zip(*tagged_sentence)\n",
    "    sentences.append(np.array(sentence))\n",
    "    tagss.append(np.array(tags))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UN_E4ePpKhvy"
   },
   "source": [
    "### Imprimimos una posicion de la lista como ejemplo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "colab_type": "code",
    "id": "l6uGGSqZQuhM",
    "outputId": "bb432132-d363-46c9-e07c-e24c4e90520a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['EDF' 'tiene' 'previsto' 'invertir' '194' 'millones' 'de' 'euros' '-Fpa-'\n",
      " '186' 'millones' 'de' 'dólares' '-Fpt-' 'en' 'la' 'central' 'de'\n",
      " 'Río_Bravo' ',' 'con' 'una' 'potencia' 'de' '495' 'megavatios' ',' 'y'\n",
      " '134' 'millones' 'de' 'euros' '-Fpa-' '28' 'millones' 'de' 'dólares'\n",
      " '-Fpt-' 'en' 'Saltillo' ',' 'que' 'como' 'la' 'primera' 'funcionará'\n",
      " 'con' 'gas' 'natural' 'y' 'cuya' 'potencia' 'prevista' 'es' 'de' '247'\n",
      " 'megavatios' '.']\n",
      "['np00000' 'vmip3s0' 'aq0msp' 'vmn0000' 'Z' 'ncmp000' 'sps00' 'Zm' 'Fpa'\n",
      " 'Z' 'ncmp000' 'sps00' 'Zm' 'Fpt' 'sps00' 'da0fs0' 'ncfs000' 'sps00'\n",
      " 'np00000' 'Fc' 'sps00' 'di0fs0' 'ncfs000' 'sps00' 'Z' 'ncmp000' 'Fc' 'cc'\n",
      " 'Z' 'ncmp000' 'sps00' 'Zm' 'Fpa' 'Z' 'ncmp000' 'sps00' 'Zm' 'Fpt' 'sps00'\n",
      " 'np00000' 'Fc' 'pr0cn000' 'cs' 'da0fs0' 'ao0fs0' 'vmif3s0' 'sps00'\n",
      " 'ncms000' 'aq0cs0' 'cc' 'pr0fs000' 'ncfs000' 'aq0fsp' 'vsip3s0' 'sps00'\n",
      " 'Z' 'ncmp000' 'Fp']\n"
     ]
    }
   ],
   "source": [
    "print(sentences[5])\n",
    "print(tagss[5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WFQrAblFQuhT"
   },
   "source": [
    "### Dividimos el corpus de la siguiente manera, Utilizamos aproximadamente el 60% de las oraciones etiquetadas para el entrenamiento, el 20% como conjunto de validación y el 20% para evaluar nuestro modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZtLulrEOQuhU"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    " \n",
    "(training_sentences, \n",
    " test_sentences, \n",
    " training_tags, \n",
    " test_tags) = train_test_split(sentences, tagss, test_size=0.2)\n",
    "\n",
    "(train_sentences, \n",
    " eval_sentences, \n",
    " train_tags, \n",
    " eval_tags) = train_test_split(training_sentences, training_tags, test_size=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_Mk0scnsK1OE"
   },
   "source": [
    "### Imprimimos los tamaños de las listas que nos indicaran el tamaño de filas de las matrices con las que estaremos trabajando"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 697
    },
    "colab_type": "code",
    "id": "7HkjbP_IQuhZ",
    "outputId": "70489eac-d99d-4728-b481-2d3bd2faa7e9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_sentences:4824\n",
      "train_sentences: 3618\n",
      "test_sentences: 1206\n",
      "eval_sentences: 1206\n",
      "\n",
      "['*' 'El' 'Madrid' 'precisa' 'que' 'el' 'Deportivo' 'gane' 'la' 'Liga' ','\n",
      " 'porque' 'los' 'gallegos' 'no' 'son' 'considerados' 'unos' 'herederos'\n",
      " ',' 'sino' 'unos' 'entrometidos' 'que' 'se' 'supone' 'temporales' ','\n",
      " 'que' 'pertenecen' 'a' 'la' 'actualidad' 'más' 'rabiosa' 'y' 'no' 'a'\n",
      " 'la' 'historia' 'más' 'enrabietada' '.']\n",
      "['El' 'técnico' 'barcelonista' 'ha' 'asegurado' 'que' 'la' 'visita' 'de'\n",
      " 'Gaspart' 'ha' 'contribuido' 'a' '\"' 'sumar' '\"' ',' 'y' '*0*' 'ha'\n",
      " 'argumentado' 'que' 'el' 'encuentro' 'con' 'el' 'presidente' 'significa'\n",
      " 'que' 'en' 'el' 'Barcelona' '\"' 'todos' 'van' 'en' 'la' 'misma'\n",
      " 'dirección' '\"' '.']\n",
      "['Lo_suyo' ',' 'lo' 'de' 'las' 'ratas' ',' 'no' 'es' 'la' 'carroña' 'pura'\n",
      " 'y' 'dura' 'sino' 'la' 'vida' 'regalada' ',' 'el' 'eterno' 'banquete'\n",
      " 'de' 'sobras' 'y' 'residuos' ',' 'el' 'festín' 'organizado' 'a' 'la'\n",
      " 'sobra' 'de' 'la' 'abundancia' 'y' 'el' 'hartazgo' '.']\n",
      "\n",
      "training_tags:4824\n",
      "train_tags: 3618\n",
      "test_tags: 1206\n",
      "eval_tags: 1206\n",
      "\n",
      "['Fz' 'da0ms0' 'np0000l' 'vmip3s0' 'cs' 'da0ms0' 'np0000o' 'vmsp3s0'\n",
      " 'da0fs0' 'np0000a' 'Fc' 'cs' 'da0mp0' 'ncmp000' 'rn' 'vsip3p0' 'vmp00pm'\n",
      " 'di0mp0' 'ncmp000' 'Fc' 'cc' 'di0mp0' 'ncmp000' 'pr0cn000' 'p0000000'\n",
      " 'vmip3s0' 'aq0cp0' 'Fc' 'pr0cn000' 'vmip3p0' 'sps00' 'da0fs0' 'ncfs000'\n",
      " 'rg' 'aq0fs0' 'cc' 'rn' 'sps00' 'da0fs0' 'ncfs000' 'rg' 'aq0fsp' 'Fp']\n",
      "['da0ms0' 'ncms000' 'aq0cs0' 'vaip3s0' 'vmp00sm' 'cs' 'da0fs0' 'ncfs000'\n",
      " 'sps00' 'np00000' 'vaip3s0' 'vmp00sm' 'sps00' 'Fe' 'vmn0000' 'Fe' 'Fc'\n",
      " 'cc' 'sn.e-SUJ' 'vaip3s0' 'vmp00sm' 'cs' 'da0ms0' 'ncms000' 'sps00'\n",
      " 'da0ms0' 'ncms000' 'vmip3s0' 'cs' 'sps00' 'da0ms0' 'np00000' 'Fe'\n",
      " 'pi0mp000' 'vmip3p0' 'sps00' 'da0fs0' 'di0fs0' 'ncfs000' 'Fe' 'Fp']\n",
      "['px3ns000' 'Fc' 'da0ns0' 'sps00' 'da0fp0' 'ncfp000' 'Fc' 'rn' 'vsip3s0'\n",
      " 'da0fs0' 'ncfs000' 'aq0fs0' 'cc' 'aq0fs0' 'cc' 'da0fs0' 'ncfs000'\n",
      " 'aq0fsp' 'Fc' 'da0ms0' 'aq0ms0' 'ncms000' 'sps00' 'ncfp000' 'cc'\n",
      " 'ncmp000' 'Fc' 'da0ms0' 'ncms000' 'aq0msp' 'sps00' 'da0fs0' 'ncfs000'\n",
      " 'sps00' 'da0fs0' 'ncfs000' 'cc' 'da0ms0' 'ncms000' 'Fp']\n"
     ]
    }
   ],
   "source": [
    "print(\"training_sentences:\" + str(len(training_sentences)))\n",
    "print(\"train_sentences: \" + str(len(train_sentences)))\n",
    "print(\"test_sentences: \" + str(len(test_sentences)))\n",
    "print(\"eval_sentences: \" + str(len(eval_sentences)) + \"\\n\")\n",
    "\n",
    "print(train_sentences[0])\n",
    "print(test_sentences[0])\n",
    "print(eval_sentences[0])\n",
    "\n",
    "print(\"\\ntraining_tags:\" + str(len(training_sentences)))\n",
    "print(\"train_tags: \" + str(len(train_tags)))\n",
    "print(\"test_tags: \" + str(len(test_tags)))\n",
    "print(\"eval_tags: \" + str(len(eval_tags)) + \"\\n\")\n",
    "\n",
    "print(train_tags[0])\n",
    "print(test_tags[0])\n",
    "print(eval_tags[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Jd-i6q85Quho"
   },
   "source": [
    "### Ahora creamos una array con todas las palabras y los tags presentes en el corpus, adicionalmente se crea un diccionario que contiene las palabras unicas y los tags unicos de tal forma que no se repitan y que contienen un indice o llave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "qdCNulCoQuhr",
    "outputId": "a9895d28-f6b4-4a22-9b60-1c397fac3301"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24499\n",
      "291\n"
     ]
    }
   ],
   "source": [
    "words, tagsss = set([]), set([])\n",
    " \n",
    "for s in (train_sentences + eval_sentences + test_sentences):\n",
    "    for w in s:\n",
    "        words.add(w.lower())\n",
    "\n",
    "for ts in (train_tags + eval_tags + test_tags):\n",
    "    for t in ts:\n",
    "        tagsss.add(t)\n",
    "\n",
    "word2index = {w: i + 2 for i, w in enumerate(list(words))}\n",
    "word2index['-PAD-'] = 0  # The special value used for padding\n",
    "word2index['-OOV-'] = 1  # The special value used for OOVs\n",
    " \n",
    "tag2index = {t: i + 2 for i, t in enumerate(list(tagsss))}\n",
    "tag2index['-PAD-'] = 0  # The special value used to padding\n",
    "tag2index['-OOV-'] = 1  # The special value used to padding\n",
    "\n",
    "print (len(word2index))\n",
    "print (len(tag2index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VEA9Ek-GOYOn"
   },
   "source": [
    "### Ahora procedemos a transformar cada uno de los conjuntos de oraciones y tags en vectores numericos, modificando la palabra o tag en un Valor numerico que corresponde a una llave en el diccionario de palbras o tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "69eec13kQuh2"
   },
   "outputs": [],
   "source": [
    "train_sentences_X, eval_sentences_X, test_sentences_X, train_tags_y, eval_tags_y, test_tags_y = [], [], [], [], [], []\n",
    "\n",
    "for s in train_sentences:\n",
    "    s_int = []\n",
    "    for w in s:\n",
    "        try:\n",
    "            s_int.append(word2index[w.lower()])\n",
    "        except KeyError:\n",
    "            s_int.append(word2index['-OOV-'])\n",
    " \n",
    "    train_sentences_X.append(s_int)\n",
    "\n",
    "for s in eval_sentences:\n",
    "    s_int = []\n",
    "    for w in s:\n",
    "        try:\n",
    "            s_int.append(word2index[w.lower()])\n",
    "        except KeyError:\n",
    "            s_int.append(word2index['-OOV-'])\n",
    " \n",
    "    eval_sentences_X.append(s_int)\n",
    "\n",
    "for s in test_sentences:\n",
    "    s_int = []\n",
    "    for w in s:\n",
    "        try:\n",
    "            s_int.append(word2index[w.lower()])\n",
    "        except KeyError:\n",
    "            s_int.append(word2index['-OOV-'])\n",
    " \n",
    "    test_sentences_X.append(s_int)\n",
    "\n",
    "for s in train_tags:\n",
    "    s_int = []\n",
    "    for w in s:\n",
    "        try:\n",
    "            s_int.append(tag2index[w])\n",
    "        except KeyError:\n",
    "            s_int.append(tag2index['-OOV-'])\n",
    "            \n",
    "    train_tags_y.append(s_int)\n",
    "\n",
    "for s in eval_tags:\n",
    "    s_int = []\n",
    "    for w in s:\n",
    "        try:\n",
    "            s_int.append(tag2index[w])\n",
    "        except KeyError:\n",
    "            s_int.append(tag2index['-OOV-'])\n",
    "            \n",
    "    eval_tags_y.append(s_int)\n",
    "\n",
    "for s in test_tags:\n",
    "    s_int = []\n",
    "    for w in s:\n",
    "        try:\n",
    "            s_int.append(tag2index[w])\n",
    "        except KeyError:\n",
    "            s_int.append(tag2index['-OOV-'])\n",
    "            \n",
    "    test_tags_y.append(s_int)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "d_lXW1mBPNkf"
   },
   "source": [
    "### Se imprime la longitud de las matrices y una muesta de cada una de las matrices creadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 292
    },
    "colab_type": "code",
    "id": "Y5A4d_dzQuh6",
    "outputId": "a3d2808b-4ec4-4b5f-e469-eed38caeb48d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Longitudes de las Matrices:\n",
      "3618\n",
      "1206\n",
      "1206\n",
      "3618\n",
      "1206\n",
      "1206\n",
      "\n",
      "Muestra de Datos presentes en las Matrices con las transformaciones:\n",
      "[16383, 23901, 10773, 2234, 2791, 23901, 8251, 18824, 23214, 6782, 2878, 7405, 21747, 23016, 10879, 11638, 13020, 15173, 14917, 2878, 11925, 15173, 7090, 2791, 23338, 7717, 5742, 2878, 2791, 17500, 21537, 23214, 23559, 2966, 15448, 20877, 10879, 21537, 23214, 21636, 2966, 20487, 8877]\n",
      "[6795, 2878, 7731, 4735, 5726, 19259, 2878, 10879, 617, 23214, 15833, 22878, 20877, 8383, 11925, 23214, 6884, 16775, 2878, 23901, 20960, 17997, 4735, 19586, 20877, 20734, 2878, 23901, 15719, 8927, 21537, 23214, 15941, 4735, 23214, 3432, 20877, 23901, 5584, 8877]\n",
      "[23901, 12601, 20450, 3454, 14463, 2791, 23214, 23042, 4735, 5803, 3454, 23195, 21537, 14165, 12937, 14165, 2878, 20877, 23348, 3454, 23730, 2791, 23901, 23457, 2125, 23901, 19174, 20407, 2791, 5224, 23901, 17344, 14165, 24407, 21803, 5224, 23214, 2695, 263, 14165, 8877]\n",
      "[44, 282, 283, 55, 10, 282, 7, 250, 156, 185, 36, 10, 80, 206, 117, 197, 47, 263, 206, 36, 124, 263, 206, 287, 119, 55, 78, 36, 287, 172, 40, 156, 196, 114, 276, 124, 117, 40, 156, 196, 114, 258, 239]\n",
      "[88, 36, 229, 40, 9, 277, 36, 117, 173, 156, 196, 276, 124, 276, 124, 156, 196, 258, 36, 282, 194, 242, 40, 277, 124, 206, 36, 282, 242, 240, 40, 156, 196, 40, 156, 196, 124, 282, 242, 239]\n",
      "[282, 242, 65, 26, 275, 10, 156, 196, 40, 12, 26, 275, 40, 129, 244, 129, 36, 124, 104, 26, 275, 10, 282, 242, 40, 282, 242, 55, 10, 40, 282, 12, 129, 253, 172, 40, 156, 203, 196, 129, 239]\n"
     ]
    }
   ],
   "source": [
    "print(\"Longitudes de las Matrices:\")\n",
    "print(len(train_sentences_X))\n",
    "print(len(eval_sentences_X))\n",
    "print(len(test_sentences_X))\n",
    "print(len(train_tags_y))\n",
    "print(len(eval_tags_y))\n",
    "print(len(test_tags_y))\n",
    "\n",
    "print(\"\\nMuestra de Datos presentes en las Matrices con las transformaciones:\")\n",
    "\n",
    "print(train_sentences_X[0])\n",
    "print(eval_sentences_X[0])\n",
    "print(test_sentences_X[0])\n",
    "print(train_tags_y[0])\n",
    "print(eval_tags_y[0])\n",
    "print(test_tags_y[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kWLspkzfQ513"
   },
   "source": [
    "### Se calcula cual es la oracion que mayor cantidad de Palabras contiene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Gif6KsESQuh_",
    "outputId": "be988786-883f-4a50-af89-78ae8696c26e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "149\n"
     ]
    }
   ],
   "source": [
    "MAX_LENGTH1 = len(max(train_sentences_X, key=len))\n",
    "MAX_LENGTH2 = len(max(eval_sentences_X, key=len))\n",
    "MAX_LENGTH3 = len(max(test_sentences_X, key=len))\n",
    "\n",
    "l = [MAX_LENGTH1, MAX_LENGTH2, MAX_LENGTH3]\n",
    "MAX_LENGTH = max(l)\n",
    "\n",
    "print(MAX_LENGTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "e4ffWaDqRA1_"
   },
   "source": [
    "### Se procede a Normalizar las matrices para que todas contengan el mismo numero de columans, con la longitud maxima de palabras encontradas anteriormente, esto se logra agregando ceros a la derecha en las posiciones que hacen falta en el vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1139
    },
    "colab_type": "code",
    "id": "mn7iuMIOQuiI",
    "outputId": "323f249f-48e1-4b9a-c945-497a47fcb0f7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16383 23901 10773  2234  2791 23901  8251 18824 23214  6782  2878  7405\n",
      " 21747 23016 10879 11638 13020 15173 14917  2878 11925 15173  7090  2791\n",
      " 23338  7717  5742  2878  2791 17500 21537 23214 23559  2966 15448 20877\n",
      " 10879 21537 23214 21636  2966 20487  8877     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0]\n",
      "[ 6795  2878  7731  4735  5726 19259  2878 10879   617 23214 15833 22878\n",
      " 20877  8383 11925 23214  6884 16775  2878 23901 20960 17997  4735 19586\n",
      " 20877 20734  2878 23901 15719  8927 21537 23214 15941  4735 23214  3432\n",
      " 20877 23901  5584  8877     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0]\n",
      "[23901 12601 20450  3454 14463  2791 23214 23042  4735  5803  3454 23195\n",
      " 21537 14165 12937 14165  2878 20877 23348  3454 23730  2791 23901 23457\n",
      "  2125 23901 19174 20407  2791  5224 23901 17344 14165 24407 21803  5224\n",
      " 23214  2695   263 14165  8877     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0]\n",
      "[ 44 282 283  55  10 282   7 250 156 185  36  10  80 206 117 197  47 263\n",
      " 206  36 124 263 206 287 119  55  78  36 287 172  40 156 196 114 276 124\n",
      " 117  40 156 196 114 258 239   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0]\n",
      "[ 88  36 229  40   9 277  36 117 173 156 196 276 124 276 124 156 196 258\n",
      "  36 282 194 242  40 277 124 206  36 282 242 240  40 156 196  40 156 196\n",
      " 124 282 242 239   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0]\n",
      "[282 242  65  26 275  10 156 196  40  12  26 275  40 129 244 129  36 124\n",
      " 104  26 275  10 282 242  40 282 242  55  10  40 282  12 129 253 172  40\n",
      " 156 203 196 129 239   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0]\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    " \n",
    "train_sentences_X = pad_sequences(train_sentences_X, maxlen=MAX_LENGTH, padding='post')\n",
    "eval_sentences_X = pad_sequences(eval_sentences_X, maxlen=MAX_LENGTH, padding='post')\n",
    "test_sentences_X = pad_sequences(test_sentences_X, maxlen=MAX_LENGTH, padding='post')\n",
    "train_tags_y = pad_sequences(train_tags_y, maxlen=MAX_LENGTH, padding='post')\n",
    "eval_tags_y = pad_sequences(eval_tags_y, maxlen=MAX_LENGTH, padding='post')\n",
    "test_tags_y = pad_sequences(test_tags_y, maxlen=MAX_LENGTH, padding='post')\n",
    " \n",
    "print(train_sentences_X[0])\n",
    "print(eval_sentences_X[0])\n",
    "print(test_sentences_X[0])\n",
    "print(train_tags_y[0])\n",
    "print(eval_tags_y[0])\n",
    "print(test_tags_y[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "elkKsVbBNrYO"
   },
   "source": [
    "### Definimos la funcion con la cual categorizaremos los tags y los covertiremos un vector One-hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qGw5_dPX5xc0"
   },
   "outputs": [],
   "source": [
    "def to_categorical(sequences, categories):\n",
    "    cat_sequences = []\n",
    "    for s in sequences:\n",
    "        cats = []\n",
    "        for item in s:\n",
    "            cats.append(np.zeros(categories))\n",
    "            cats[-1][item] = 1.0\n",
    "        cat_sequences.append(cats)\n",
    "    return np.array(cat_sequences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GOmqn-5ZNg23"
   },
   "source": [
    "### Desarrollamos una prueba de la categorisacion de los tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "lepVNGK5bgc1",
    "outputId": "4ee4647c-0b91-4fb4-8676-1bdf1c52ea30"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "cat_train_tags_y = to_categorical(train_tags_y, len(tag2index))\n",
    "print(cat_train_tags_y[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9-_gAQ7qrWTQ"
   },
   "source": [
    "## PARTE 2  -  Entrenamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "odDOhtO4NZDd"
   },
   "source": [
    "### Definimos el Modelo Base con el cual se procedera a desarrollar la fase de Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 272
    },
    "colab_type": "code",
    "id": "x31rRt8PQuiW",
    "outputId": "90e66266-fb83-4408-ad95-11e3ffeeea98"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 149, 128)          3135872   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 149, 128)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 149, 512)          788480    \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 149, 291)          149283    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 149, 291)          0         \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 149, 291)          0         \n",
      "=================================================================\n",
      "Total params: 4,073,635\n",
      "Trainable params: 4,073,635\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, InputLayer, Bidirectional, TimeDistributed, Embedding, Activation, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import plot_model\n",
    "\n",
    "model = Sequential()\n",
    "model.add(InputLayer(input_shape=(MAX_LENGTH, )))\n",
    "model.add(Embedding(len(word2index), 128))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Bidirectional(LSTM(256, return_sequences=True)))\n",
    "model.add(TimeDistributed(Dense(len(tag2index))))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(0.001), metrics=['accuracy'])\n",
    " \n",
    "model.summary()\n",
    "\n",
    "plot_model(model, to_file='../Plot/model-mb01.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4XghotI4NG9G"
   },
   "source": [
    "### Se dedarrolla el entrenamiento del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 680
    },
    "colab_type": "code",
    "id": "C0gOhZznbg6V",
    "outputId": "29cf358f-43dd-448e-c1bb-9cb4e12250d3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3618 samples, validate on 1206 samples\n",
      "Epoch 1/40\n",
      "3618/3618 [==============================] - 17s 5ms/step - loss: 3.6817 - acc: 0.5265 - val_loss: 1.0643 - val_acc: 0.7845\n",
      "Epoch 2/40\n",
      "3618/3618 [==============================] - 14s 4ms/step - loss: 3.0081 - acc: 0.7767 - val_loss: 0.9736 - val_acc: 0.8128\n",
      "Epoch 3/40\n",
      "3618/3618 [==============================] - 14s 4ms/step - loss: 2.9827 - acc: 0.7949 - val_loss: 0.9306 - val_acc: 0.8128\n",
      "Epoch 4/40\n",
      "3618/3618 [==============================] - 14s 4ms/step - loss: 2.9635 - acc: 0.7986 - val_loss: 0.9050 - val_acc: 0.8184\n",
      "Epoch 5/40\n",
      "3618/3618 [==============================] - 14s 4ms/step - loss: 2.9494 - acc: 0.8062 - val_loss: 0.8775 - val_acc: 0.8318\n",
      "Epoch 6/40\n",
      "3618/3618 [==============================] - 14s 4ms/step - loss: 2.9334 - acc: 0.8130 - val_loss: 0.8333 - val_acc: 0.8429\n",
      "Epoch 7/40\n",
      "3618/3618 [==============================] - 14s 4ms/step - loss: 2.8953 - acc: 0.8262 - val_loss: 0.7507 - val_acc: 0.8850\n",
      "Epoch 8/40\n",
      "3618/3618 [==============================] - 14s 4ms/step - loss: 2.8283 - acc: 0.8396 - val_loss: 0.6441 - val_acc: 0.9043\n",
      "Epoch 9/40\n",
      "3618/3618 [==============================] - 14s 4ms/step - loss: 2.7720 - acc: 0.8496 - val_loss: 0.5575 - val_acc: 0.9202\n",
      "Epoch 10/40\n",
      "3618/3618 [==============================] - 14s 4ms/step - loss: 2.7293 - acc: 0.8587 - val_loss: 0.4885 - val_acc: 0.9300\n",
      "Epoch 11/40\n",
      "3618/3618 [==============================] - 14s 4ms/step - loss: 2.6976 - acc: 0.8650 - val_loss: 0.4358 - val_acc: 0.9413\n",
      "Epoch 12/40\n",
      "3618/3618 [==============================] - 14s 4ms/step - loss: 2.6763 - acc: 0.8687 - val_loss: 0.3869 - val_acc: 0.9465\n",
      "Epoch 13/40\n",
      "3618/3618 [==============================] - 14s 4ms/step - loss: 2.6511 - acc: 0.8721 - val_loss: 0.3446 - val_acc: 0.9528\n",
      "Epoch 14/40\n",
      "3618/3618 [==============================] - 14s 4ms/step - loss: 2.6319 - acc: 0.8748 - val_loss: 0.3153 - val_acc: 0.9579\n",
      "Epoch 15/40\n",
      "3618/3618 [==============================] - 14s 4ms/step - loss: 2.6151 - acc: 0.8786 - val_loss: 0.2855 - val_acc: 0.9627\n",
      "Epoch 16/40\n",
      "3618/3618 [==============================] - 14s 4ms/step - loss: 2.6003 - acc: 0.8812 - val_loss: 0.2592 - val_acc: 0.9659\n",
      "Epoch 17/40\n",
      "3618/3618 [==============================] - 14s 4ms/step - loss: 2.5880 - acc: 0.8835 - val_loss: 0.2406 - val_acc: 0.9687\n",
      "Epoch 18/40\n",
      "3618/3618 [==============================] - 14s 4ms/step - loss: 2.5716 - acc: 0.8852 - val_loss: 0.2195 - val_acc: 0.9714\n",
      "Epoch 19/40\n",
      "3618/3618 [==============================] - 14s 4ms/step - loss: 2.5580 - acc: 0.8864 - val_loss: 0.2070 - val_acc: 0.9734\n",
      "Epoch 20/40\n",
      "3618/3618 [==============================] - 14s 4ms/step - loss: 2.5590 - acc: 0.8868 - val_loss: 0.1897 - val_acc: 0.9744\n",
      "Epoch 21/40\n",
      "3618/3618 [==============================] - 14s 4ms/step - loss: 2.5547 - acc: 0.8877 - val_loss: 0.1787 - val_acc: 0.9758\n",
      "Epoch 22/40\n",
      "3618/3618 [==============================] - 14s 4ms/step - loss: 2.5521 - acc: 0.8884 - val_loss: 0.1678 - val_acc: 0.9763\n",
      "Epoch 23/40\n",
      "3618/3618 [==============================] - 14s 4ms/step - loss: 2.5416 - acc: 0.8891 - val_loss: 0.1620 - val_acc: 0.9773\n",
      "Epoch 24/40\n",
      "3618/3618 [==============================] - 14s 4ms/step - loss: 2.5395 - acc: 0.8895 - val_loss: 0.1519 - val_acc: 0.9776\n",
      "Epoch 25/40\n",
      "3618/3618 [==============================] - 14s 4ms/step - loss: 2.5315 - acc: 0.8903 - val_loss: 0.1470 - val_acc: 0.9780\n",
      "Epoch 26/40\n",
      "3618/3618 [==============================] - 14s 4ms/step - loss: 2.5347 - acc: 0.8907 - val_loss: 0.1389 - val_acc: 0.9785\n",
      "Epoch 27/40\n",
      "3618/3618 [==============================] - 14s 4ms/step - loss: 2.5236 - acc: 0.8910 - val_loss: 0.1351 - val_acc: 0.9788\n",
      "Epoch 28/40\n",
      "3618/3618 [==============================] - 14s 4ms/step - loss: 2.5216 - acc: 0.8908 - val_loss: 0.1303 - val_acc: 0.9790\n",
      "Epoch 29/40\n",
      "3618/3618 [==============================] - 14s 4ms/step - loss: 2.5188 - acc: 0.8911 - val_loss: 0.1237 - val_acc: 0.9794\n",
      "Epoch 30/40\n",
      "3618/3618 [==============================] - 14s 4ms/step - loss: 2.5180 - acc: 0.8910 - val_loss: 0.1217 - val_acc: 0.9793\n",
      "Epoch 31/40\n",
      "3618/3618 [==============================] - 14s 4ms/step - loss: 2.5129 - acc: 0.8914 - val_loss: 0.1204 - val_acc: 0.9793\n",
      "Epoch 32/40\n",
      "3618/3618 [==============================] - 14s 4ms/step - loss: 2.5142 - acc: 0.8921 - val_loss: 0.1169 - val_acc: 0.9796\n",
      "Epoch 33/40\n",
      "3618/3618 [==============================] - 14s 4ms/step - loss: 2.5112 - acc: 0.8919 - val_loss: 0.1136 - val_acc: 0.9800\n",
      "Epoch 34/40\n",
      "3618/3618 [==============================] - 14s 4ms/step - loss: 2.5125 - acc: 0.8919 - val_loss: 0.1118 - val_acc: 0.9799\n",
      "Epoch 35/40\n",
      "3618/3618 [==============================] - 14s 4ms/step - loss: 2.5166 - acc: 0.8920 - val_loss: 0.1111 - val_acc: 0.9798\n",
      "Epoch 36/40\n",
      "3618/3618 [==============================] - 14s 4ms/step - loss: 2.5114 - acc: 0.8916 - val_loss: 0.1084 - val_acc: 0.9799\n",
      "Epoch 37/40\n",
      "3618/3618 [==============================] - 14s 4ms/step - loss: 2.5077 - acc: 0.8918 - val_loss: 0.1091 - val_acc: 0.9799\n",
      "Epoch 38/40\n",
      "3618/3618 [==============================] - 14s 4ms/step - loss: 2.5031 - acc: 0.8923 - val_loss: 0.1057 - val_acc: 0.9801\n",
      "Epoch 39/40\n",
      "3618/3618 [==============================] - 14s 4ms/step - loss: 2.5035 - acc: 0.8922 - val_loss: 0.1047 - val_acc: 0.9800\n",
      "Epoch 40/40\n",
      "3618/3618 [==============================] - 14s 4ms/step - loss: 2.5102 - acc: 0.8919 - val_loss: 0.1015 - val_acc: 0.9801\n"
     ]
    }
   ],
   "source": [
    "model_hist = model.fit(train_sentences_X, to_categorical(train_tags_y, len(tag2index)),\n",
    "                       validation_data=(eval_sentences_X, to_categorical(eval_tags_y, len(tag2index))),\n",
    "                       batch_size=128, \n",
    "                       epochs=40,\n",
    "                       validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9hTDgQb2rWTa"
   },
   "source": [
    "## PARTE 3  -  Evaluación del Modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LdSkk8mzM1KN"
   },
   "source": [
    "### Evaluamos el modelo y calculamos el valor de precision con respecto a los datos de prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "cD-YI5Fgb3Kt",
    "outputId": "4a3aa89a-6081-4bb9-a299-8ac9cdbac680"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1206/1206 [==============================] - 5s 4ms/step\n",
      "acc: 97.89920660789136\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(test_sentences_X, to_categorical(test_tags_y, len(tag2index)))\n",
    "print(f\"{model.metrics_names[1]}: {scores[1] * 100}\")   # acc: 97.38805993872496"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sAhkgtWHQuij"
   },
   "source": [
    "### Definimos la funcion que nos servira para graficar el comportamiento del modelo en cada epoca del entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JaBUkInNQuik"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_model_performance(train_loss, train_acc, train_val_loss, train_val_acc):\n",
    "    \"\"\" Plot model loss and accuracy through epochs. \"\"\"\n",
    "    blue= '#34495E'\n",
    "    green = '#2ECC71'\n",
    "    orange = '#E23B13'\n",
    "    # plot model loss\n",
    "    fig, (ax1, ax2) = plt.subplots(2, figsize=(10, 8))\n",
    "    ax1.plot(range(1, len(train_loss) + 1), train_loss, blue, linewidth=5, label='training')\n",
    "    ax1.plot(range(1, len(train_val_loss) + 1), train_val_loss, green, linewidth=5, label='validation')\n",
    "    ax1.set_xlabel('# epoch')\n",
    "    ax1.set_ylabel('loss')\n",
    "    ax1.tick_params('y')\n",
    "    ax1.legend(loc='upper right', shadow=False)\n",
    "    ax1.set_title('Model loss through #epochs', color=orange, fontweight='bold')\n",
    "    # plot model accuracy\n",
    "    ax2.plot(range(1, len(train_acc) + 1), train_acc, blue, linewidth=5, label='training')\n",
    "    ax2.plot(range(1, len(train_val_acc) + 1), train_val_acc, green, linewidth=5, label='validation')\n",
    "    ax2.set_xlabel('# epoch')\n",
    "    ax2.set_ylabel('accuracy')\n",
    "    ax2.tick_params('y')\n",
    "    ax2.legend(loc='lower right', shadow=False)\n",
    "    ax2.set_title('Model accuracy through #epochs', color=orange, fontweight='bold')\n",
    "    \n",
    "    fig.savefig('../Plot/training-mb-01.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TxQh1AtuQuis"
   },
   "source": [
    "### Procedemos a Graficar el comportamiento del Entrenamiento, tanto del conjunto de entrenamiento como el de validación con respecto a la cantidad de epocas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 512
    },
    "colab_type": "code",
    "id": "Gs5f3U1nQuit",
    "outputId": "86aa7473-9513-40a7-b098-807da720926b"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmQAAAHwCAYAAAAIDnN0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4xLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvDW2N/gAAIABJREFUeJzs3XmcHHWd//HXp3t67jPpyd05CCGBxBwQEGSAoIDAInhExWsJyuKyHrCrrtfvp8hv3dXVdcUfHj9UPFkVQRQVFVGukSsHSchBIAlJOoQk08ncZx/f3x9VPdMzmUwmyfT0HO+nj7aqvlVd/a2aZuad7/dbVeacQ0RERERyJ5DrCoiIiIiMdwpkIiIiIjmmQCYiIiKSYwpkIiIiIjmmQCYiIiKSYwpkIiIiIjmmQCYyjkRrwquiNWEXrQmvP473OP81+yjrH/XXrxqqep6MjGN8NNd16c9Ir9/JGMvHJpJtebmugIj0iNaEdwGz/MWaSG3sb375BcDjfvnuSG1s9vDXbuTJOF8XR2pjj+a2NsMjWhP+PbAvUhv7h2hNeAvw00ht7N9zXS8ROTlqIRMZuW7KmP/HnNViHIjWhAPRmvCI/30YrQkXACuAP0ZrwrOA04EHc1opERkSaiETGZnqgZXRmvAtgAFv88uqMjfyuxG/AtQAhcB64FOR2tgz/vppwA+B84F1wF/7flC0JrwI+DJwtv9ZjwP/HKmN7TmRikdrwiHg48B1QATYA9wJ3B6pjaX8On8HeK1f5z3AzyO1sc9Ha8JV/rYXA6XAq8BDkdrYB/v5nF30tCY+Eq0JA1yfsUkgWhP+EvBBoA3410ht7G7/vY8CFwH/iRdwzgJOjdaE64BbgbcCk4HtwH9FamM/8d/3Q/+4vhCpjd3qH8vLAJHamPnb1ADfBk4BfgWEgHf6x3/LYOrXz7F2f47v3oz556I14R9FamOr/G3fD9wMzPXP3w+A/4zUxhJ+t/IPgFrgOWAVEAP+d8a5KRnoHPjbvA+4BTgNiAO/7PMzGujcvxv4X8AcoB3YBnwiUhur7e/YRcaLEf8vQpFx6kdAAfB+/1WAF6y6+X84/wqsBF7051cAf43WhOf6m/0PcCle6HkZ+GSffUzBC2CX4v2RfgbvD/Gf/NaYE/FF4N+BMuDnQBj4WsZn/xvwRmA18GMgihfOAD7mH89LeMFhK/C6o3zOXUCzP38fcDuwJWN9DfB6/3OmAf8vWhMu77OPTwAHgZ8Bnf5nfhxIAvcA84AfR2vC7xrMgUdrwpXAb4FFwLPAJODtR9l8MPVLa/KP71m/vrcDL+CFpduBh/zP/yDwfbzgfq9/HF8EPttnf+fjBfCH8ILRT6I14cX+ugHPQbQm/A94P7clwB/xWujmDebYojXhIrzv8SzgbuD3QDleeBQZ1xTIREamx/DCxY3+aws9Y8jS/g7vj+lOYEWkNvY24NdAMfCBaE14Bl4rEMBlkdrY3wPf7LOP9+H98d6OF9q2A3XAArxWquMSrQkb8E/+4rsjtbEPADf4yx/xpyF/+gheS9lV/rFkrnsGLxi8A1ja32dFamO3AYf9xTsitbFbIrWxZzM2qQcu9PedBErwWnQy/TRSG3tTpDb2Pn+bdHi6NFIbez/wmT51P5argEq8n8nrI7WxNwLPH2XbwdQPgEht7LDfutYI3O/PB4Hv+8f9P/6mH/WnzwINwBp/+SZ6qwMujNTGVuJ9Zwx4X7QmnBkgj3YObvann4jUxt4eqY29Fy9gD+bYgv6r3v/cz0dqYwuBn/Z/ikTGDwUykZHrO3gtB6fgdYH1NdufbovUxpw//4I/nQVM9+fbI7WxqD//4lH2cTreH9qbgWq/7NQTqHM13h9f8Fq3Mus0NVoTzsfrDnsS+D943agNwJf8bb4O/Akv1D3jr/vxCY7v2hqpjXVEamNxoNUvK+2zzd8y5mf70/ZIbWx3n7rPon/BPsvpc575M9lK/wZTP6DnSla8lswP+vPzgP/w5/sew9vwfpbv8ZcnR2vCmfve4X8u9BzjDAZ3Dub406fTO8vY14DHFqmNteCFQ8NrSdwRrQlHgQv6O26R8USBTGTk+jHe+JtW4Cf9rN/lT0/zW6YA5vvT3cAr/nxRtCYcSW97lH38KlIbs/QLmIrX9XW86uj5A7ygT51ejdTGuoCdkdrY+UAFcA5eK9fH/ToejtTGLsfr7lwCbAbejdfF1p+kP+3vd1kiY971sx68bsq0Xf60KFoTntmn7ulwkj62dNfioj77S5/zzDC7gP4Npn5p9+J1/wJ8D6+bMIHXXXl7xna7/OnVfX6ep/hhKG2uP9Yvs357Gdw5SI9lS3czE60J9x2PPNCx/ShSG5uO15V5M14Q/N+IjHMa1C8yQkVqY43RmvCFGfN9N/k93h/QuXiD2mPAW/AGSt8VqY3tjdaEH8frOnooWhNejTe4PNPdeF1Sb43WhP+Usb+L8Fpgdh1nnV20JvxtvDFI/xOtCf8RuNpffYc//Va0Jjwfr+UlD2+MWRJoAT4VrQlfjdfN10VPi03jUT4yiteCeJv/vv86nvr2qfvBaE34XrwxbH+O1oT/htdlmln35/zpddGacIKeFqi03+G16s2L1oQfxgsmizlJkdrYHdGacDNe1+CNwOeAyX0uEkjX81vAT6M14fvxgupyvHFnKzK2CwOPRWvC+4A344Wmuwd5Dm7Hu/DiK9Ga8Ovwvm/T8FrvBuOAf1HFPuA1flnDIN8rMmaphUxkBIvUxtZGamNrj7KuFXgD3oD2BcAleGPP3hCpjW33N3sP8DBed9NpeIPrM/exDy98/Q5vrNZ78brdvol39d2J+Cxei0cbXuvWYbzB81/21z+J1zX3Trw/9tuA90RqY/V4XZgJvJDw98AB4KOR2tjGo3zWrXjj3s7Da22ZfIJ1Tns/8N9Avl+/ncD1GWO0foJ3oUQIb7zYf2e+OVIbawDeBGzy61QHPOCvzmyNOxHnA0/5XaHn07u7Ne07eGP2XsYLVVfi/Ry/12e7v+H9HC7Fa/m6LlIbS98seMBzEKmNfRfvZ7PR3/+b/G0G68/AmcAHgIV4/7D42HG8X2RMMueO1VIuIiKDFa0JV0RqY43+fACv23UBcEOkNnYi3cBDWbdVeBdLPBapja3IZV1EpDd1WYqIDK3v+d2ZW/FaHxfgdc/dl9NaiciIpi5LEZGhtQ7vPlyfxesm/gVwkd+dKSLSL3VZioiIiOSYWshEREREckyBTERERCTHRt2g/nA47GbPnp3raoiIiIgc09q1a2POuepjbTfqAtns2bNZs2bNsTcUERERyTEz233srdRlKSIiIpJzCmQiIiIiOaZAJiIiIpJjo24M2XCJ7jvAlOqJhEI6RSIiMvbE43H27t1LR0dHrqsyJhQWFjJjxgxCodAJvV9pI0N7Ryd//dtqfvOnx3lu0zb+8399hItftzzX1RIRERlye/fupaysjNmzZ2Nmua7OqOac49ChQ+zdu5c5c+ac0D4UyHy//uOjfP27P6O1vedfCg889IQCmYiIjEkdHR0KY0PEzJg4cSJ1dXUnvA+NIfNNmTSxVxgDeHLNBuoO1eeoRiIiItmlMDZ0TvZcKpD5zl6ykMnVE3qVpVKO3//lbzmqkYiIyNjV0NDAt771reN+35VXXklDQ8OA23zuc5/j4YcfPtGq5YQCmS8YDPCmSy84ovy3Dz2OHsAuIiIytI4WyJLJ5IDve/DBB6msrBxwm9tuu41LLrnkpOo33DSGLMNVl1zA9/7nN73K9uw7wPrNL7Js0fwc1UpERCR7zr7yuqx/xuoHf3RE2ac+9Sl27NjB0qVLCYVClJaWMnXqVNavX8+WLVt485vfTDQapaOjg5tvvpkbb7wR6HliT0tLC1dccQU1NTU8+eSTTJ8+nd/85jcUFRWxatUqrrrqKlauXMns2bO57rrr+O1vf0s8HueXv/wlCxYsoK6ujne/+90cOnSIs88+mz/+8Y+sXbuWcDic9fPRH7WQZZg+pZqzl55xRPlvHno8B7UREREZu770pS8xd+5c1q9fz1e+8hWeffZZvvjFL7JlyxYA7rrrLtauXcuaNWv4xje+waFDh47Yx0svvcSHPvQhNm/eTGVlJffdd1+/nxUOh1m3bh033XQTX/3qVwH4whe+wOtf/3rWrVvHW97yFvbs2ZO9gx0EBbI+rr70wiPK/vLEs7S0teegNiIiIuPDOeec0+uWEd/4xjdYsmQJ5557LtFolJdeeumI98yZM4elS5cCcNZZZ7Fr165+9/3Wt771iG1qa2u59tprAbj88supqqoawqM5flkLZGZWaGbPmtkGM9tsZl/oZ5tVZlZnZuv91w3Zqs9grXjdWZSVFvcq6+js4s+PP5OjGomIiIx9JSUl3fOPPvooDz/8ME899RQbNmxg2bJl/d7AtqCgoHs+GAySSCT63Xd6u8xtRtr48Gy2kHUCr3fOLQGWApeb2bn9bPcL59xS//W9LNZnUAoL8nnjRecdUf5bdVuKiIgMmbKyMpqbm/td19jYSFVVFcXFxbzwwgs8/fTTQ/75NTU13HPPPQA89NBD1Nfn9jZXWRvU77zo2eIvhvzXyIqjR3HNGy/k3t//pVfZ8y/sYOeeVzhl5vQc1UpERGTo9TfgfjhMnDiR888/n0WLFlFUVMTkyZO7111++eV85zvfYfHixcyfP59zz+2vPefkfP7zn+dd73oXv/jFL7jooouYOnUqZWVlQ/45g2XZbLIzsyCwFjgV+KZz7pN91q8C/gOoA14E/tk5Fx1on8uXL3dr1qzJToV9zjne85HP8dLO3gP83vPWy7nlhndl9bNFRESGw9atWzn99NNzXY2c6ezsJBgMkpeXx1NPPcVNN93E+vXrT2qf/Z1TM1vrnDvmY3+yOqjfOZd0zi0FZgDnmNmiPpv8FpjtnFsMPAz0G9PN7EYzW2Nma07msQSDZWZcc9mRg/sf/MvfiMf7758WERGR0WPPnj2cffbZLFmyhI9+9KN897vfzWl9huUqS+dcA/AocHmf8kPOuU5/8bvAWUd5/53OueXOueXV1dVZrWvaG1ecRyivd49ufWMztatPLj2LiIhI7s2bN4/nnnuODRs2sHr1as4+++yc1iebV1lWm1mlP18EXAK80GebqRmLVwNbs1Wf41VZXsqK1x2ZDx/4kwb3i4iIyNDKZgvZVOARM9sIrAb+7Jz7nZndZmZX+9t81L8lxgbgo8CqLNbnuF192ZGPUnpy7UY9cFxERESGVDavstwILOun/HMZ858GPp2tOpyss5csZEr1RPbX9dwdOJVy/O7hWq5/55tyWDMREREZS3Sn/gEEgwGuurTmiPLf/vmJEXdDORERERm9FMiO4U2XHtltGd13gOc2bctBbURERMan0tJSAPbt28fKlSv73WbFihUc69ZYX//612lra+tevvLKK2loaBi6ip4gBbJjmDa5/weOP6A794uIiAy7adOmce+9957w+/sGsgcffJDKysqhqNpJydoYsrHkmssuZPX6Lb3KHq5dzcdveh+lxUU5qpWIiMjJW7L2X7L+GRvO+toRZZ/85CeZNWsW//RP/wTArbfeipnx+OOPU19fTzwe59/+7d+45pprer1v165dXHXVVWzatIn29nauv/56tmzZwumnn057e3v3djfddBOrV6+mvb2dlStX8oUvfIFvfOMb7Nu3j4svvphwOMwjjzzC7NmzWbNmDeFwmK997WvcddddANxwww3ccsst7Nq1iyuuuIKamhqefPJJpk+fzm9+8xuKiob2779ayAbhovOOfOB4Z2cXDz029M/WEhERGQ+uvfZafvGLX3Qv33PPPVx//fXcf//9rFu3jkceeYSPfexjA47Z/va3v01xcTEbN27ks5/9LGvXru1e98UvfpE1a9awceNGHnvsMTZu3MhHP/pRpk2bxiOPPMIjjzzSa19r167lBz/4Ac888wxPP/003/3ud3nuuecAeOmll/jQhz7E5s2bqays5L777hvis6FANiiFBflcvqK/B44/kYPaiIiIjH7Lli3j4MGD7Nu3jw0bNlBVVcXUqVP5zGc+w+LFi7nkkkt45ZVXOHDgwFH38fjjj/Pe974XgMWLF7N48eLudffccw9nnnkmy5YtY/PmzWzZsuVouwGgtraWt7zlLZSUlFBaWspb3/pWnnjC+zs/Z84cli5dCsBZZ53Frl27TvLoj6Quy0G6+rIL+eXvej9wfNO2HezYvZe5s2bkqFYiIiKj18qVK7n33nvZv38/1157LXfffTd1dXWsXbuWUCjE7Nmz6ejoGHAfZnZE2csvv8xXv/pVVq9eTVVVFatWrTrmfgZqiSsoKOieDwaDvbpGh4payAZpwamzOe2UmUeUP6BWMhERkRNy7bXX8vOf/5x7772XlStX0tjYyKRJkwiFQjzyyCPs3r17wPdfeOGF3H333QBs2rSJjRs3AtDU1ERJSQkVFRUcOHCAP/zhD93vKSsro7m5ud99/frXv6atrY3W1lbuv/9+LrjgyDstZItayI7D1ZddyFe/89NeZQ/+5W98eNXbCYV0KkVEZPTpb8D9cFm4cCHNzc1Mnz6dqVOn8p73vIc3velNLF++nKVLl7JgwYIB33/TTTdx/fXXs3jxYpYuXco555wDwJIlS1i2bBkLFy7klFNO4fzzz+9+z4033sgVV1zB1KlTe40jO/PMM1m1alX3Pm644QaWLVuWle7J/thou8Hp8uXL3bHuMZItjc0tXPGem4knEr3Kv/zZj/D685fnpE4iIiInYuvWrZx++um5rsaY0t85NbO1zrljhgR1WR6HirKjPHBc9yQTERGRk6BAdpyuuezCI8qeWruRg7HDOaiNiIiIjAUKZMfp7KVnMKV6Yq+yVMrx+7/8LUc1EhERkdFOgew4BQKBfp9v+cBDj+uB4yIiMqro79bQOdlzqUB2Aq66tOaI+57sffUg6/TAcRERGSUKCws5dOiQQtkQcM5x6NAhCgsLT3gfulfDCZg2uZqzl5zBs+s39yr/7UOPc9ZrBr5EV0REZCSYMWMGe/fupa6uLtdVGRMKCwuZMePEbxSftUBmZoXA40CB/zn3Ouc+32ebAuDHwFnAIeCdzrld2arTULr6sguOCGQP167m4//4XkpLio/yLhERkZEhFAoxZ86cXFdDfNlsIesEXu+cazGzEFBrZn9wzmU+kfsDQL1z7lQzuxb4MvDOLNZpyKx4nffA8eaWtu6yzs4uPvvlb7Ng7iwmTqgkPKGS6omVhKsqmTihgvxQKIc1FhERkZEqa4HMeZ3SLf5iyH/17ai+BrjVn78XuMPMzI2CDu2CfO+B432fb/nkmo08uWZjv++pKCvxglqVF9QmTqiksryUirJSKspLqfSnFeWllJWWkBcMDsehiIiISI5ldQyZmQWBtcCpwDedc8/02WQ6EAVwziXMrBGYCMSyWa+hcs0bLzoikA2ksbmVxuZWdu5+ZVDbl5UWe2HND2rlZSVUlJVSVlpMSXGR9yoqoqS4kFJ/ubi4sHudAp2IiMjokNVA5pxLAkvNrBK438wWOec2ZWxy5CPaj2xFw8xuBG4EmDnzyAd858r8ubNYNH8um7btyMr+m1vaaG5pY++rB0/o/QUF+ZQUF1FaVEhpaTGlxcWUlRZTWuJNy0q8+dKSIspKSo5YV1RYcMTVpCIiIjL0hu1Zlmb2eaDVOffVjLI/Abc6554yszxgP1A9UJdlLp9l2Z/de/fz0c99lX37x95VKuWlJUSmTWbm9ClEpk9m1vQp3vy0yZQUF+W6eiIiIiPeYJ9lmc2rLKuBuHOuwcyKgEvwBu1negC4DngKWAn8dTSMH8s0a8YU7v/ef/LC9t0ciB0idriR2OEGDh1uIFbvzccON3C4oWnU3eulqaWVzS/uZPOLO49YN7GqgpndYW0KM6d787OmTyEvT3dTEREROR5ZayEzs8XAj4Ag3g1o73HO3WZmtwFrnHMP+LfG+AmwDDgMXOucO/Kvf4aR1kI2WIlkkvqGJj+gNRKr94JaU3MrjU0tNDa39EybW3pdvTmaFBUWsHThaZy95AyWLzmd006ZRTCo+w+LiMj4NNgWsmHrshwqozWQHa9EMklzix/WmlpoaG7xwltzC61t7bS2tdPW1kFrWzst7R3dZd7LWx4JP9uy0mLOes0Czl56BsuXnMGcyDSNSxMRkXFDgWycS6VSdHR2eYGttZ2WNu8CgZZWb9rc6s23tHrz6XUtre00t7bR0NRMIpEc8npNqKrg7MWns3zJ6Zy9dCHTp1QP+WeIiIiMFApkclKSyRQHY4fZ88p+dr+yn+i+A+zxp/v215FMpYbkc6ZNDrNs0XwWLZjLaxacytzZM3S7DhERGTMUyCRr4vEE+w7E2PPKfj+k7Wf3Kwd4aeduGptbT2rfBQX5nHHqbBYumMtr5s9l0YK5TApPGKKai4iIDC8FMhl2qVSKl16OsmbDVtZs2MK6Tdtoa+846f1OmljFogVzWeQHtNNPnU1hYcEQ1FhERCS7FMgk5xKJBFte2sWaDVtYvWErG7e8RFc8ftL7DQYCzI5MY87MaZwycxpzZk5nzsxpzJw2hVBIt9wQEZGRQ4FMRpzOri42btnuBbSNW9mybeeQjUUDCAaDzJw2mTl+SPPC2jRmTp9CQX7+kH2OiIjIYCmQyYjX2tbO8y9sZ9MLO9m0bQebtu2gsanl2G88ToGAMWPKJGZMm8zUyWGmTvJfkycydVKYCZXlBAK6V5qIiAw9BTIZdZxz7H31IM+/sJ3N23by/As7eHHnHpLJob/9Rqb8UIgp1ROYOjnMlElhpk6a2B3cwhMqqaooo6S4SPdPExGR46ZAJmNCR2cX23bsZvO2HTz/wg42vbCD/XWHhr0eobw8KitKqawop6q8jKqKMiorvGlVRXnPfGU5EyvLKS0pVoATEZHcP8tSZCgUFuSz5Ix5LDljXndZQ2MzO/e8wst79vFydB8797zCzt2vcKi+MWv1iCcS1B1qoO5Qw6C2L8gPMXFCJeGqCsITKrtfE6sqmJhRVlVRpu5SERFRC5mMHY3NLezas4+d0X287Ie0l/fs4+Ch+lxX7aiCgQATqsqprCinoqyUyrISKspLqSgr9aaZ8/60rKRYIU5EZJRQC5mMOxVlpSxZeBpLFp7Wq7yltY3de1/l1YOHePVAjFcPxrrn9x+M0ToE90o7UclU6rha3sC7SKGstITy0hLKSospKynuXi4tLfbKS4q9daXeurISr7y0pIi8PP1nLyIy0ug3s4x5pSXFLJw/l4Xz5x6xzjlHc0ubF9IOeEFtvx/Y9tcdor6hifqmZjo7u3JQ8/6lUq77ofMnoqAgn9LiIkqKiygt8afFxT3zJd5ySXEhpSXFFBcVUlxUSFFhQfd8cVEhhQX5GicnIjJEFMhkXDMzystKKC8rYf7cWUfdrr2jk/rGJuobm2lobKa+sZn6xqae+Yam7rJD9Y10dp38DXCzpbOzi87OrpMec2dmFBUWdAe1zMBWWlJEWUkxpSU9LXTdLXYlxZSW9LTu6Wa+IiIKZCKD4gWPaqZNrj7mts45WlrbiB1uJHa4gVh9A4fq/fnDjRzyy2KHG2lpbRuG2meHc4629g7a2jtOKtwVFuRTVlpMSXERJUVFFBcXUlJUSElxEcW9pj3zxUVFlBQVEggEcDjwx8I6Bw7nTb3/w/l1TY+XDQYCBINBgkFvmpcXJBjwlvP88syyYDBIMBAgEAgQCJhaBUUkKxTIRIaYmTfGq6y0hDkzpw24bYffUtXY1EJjc8ugprkc85YNHZ1ddHR2Hdc4ulwyMwJm3QEtEAh4y8FARnmAgvwQBQX5FBUWUFhQQGH3fD6F6WlBQU9ZQT55eUF//733bQGvzJtaRjgMEMoLUpAfIj8/RH4on4L8EKFQXndZKC/vhEOkc45UyuFcimAwqDAqkkVZC2RmFgF+DEwBUsCdzrnb+2yzAvgN8LJf9Cvn3G3ZqpPISFNYkM/0KdVMn3Lslre0eDxBY3MLzS1tNLe20dzSSnNLG00trbS0+tOWNpoy1/vT1rZ2UqnRdWX1SOOcI+nckD72K9t6Apv3Au+CkmQySSqVIpVKkUw5f5oilUyRTCV7fVfMrCdUFhZQlA6ThQUUFXrlRQXpZe+VFwweESbNfwX6Ke8Ot36oDQYD3dulQ6hXFiAYCGBm3tS/6tgMDOuexw+Qhnnr0sv++/LyvBbSvGCePw32mo72EOr872kymSSZ7JkmkkmSqRQBs4zjzes+7tF8zKNZNlvIEsDHnHPrzKwMWGtmf3bObemz3RPOuauyWA+RMSUUyuu+j9nxcs7R3tFJS2sbLW3ttLa109LaPuBye3sHbR2dvaftHSN6nJz01tkVP+mfV/q7097ROUS1Gh2CGSENOKIb3Hv5y353ORnzZnQHyO6gmZ7PaFUNpgOnHy4H/IyU69U13xO8+oSvE/xHQ3dYTQfTjLCW53fhdwfjYJC8jPlgMNA9LMAL0EHyAgF/H4FeYbfvvDdcwPusdCZM35nLO+t0Dz0gPUkPVwCSySRd8QTxeJx4IkFXPEEinsgoS9LlT+PxuLfe3+4zH1nFma9ZcELna6hkLZA5514FXvXnm81sKzAd6BvIRGSYmFn3wPtJJ7mvRDJJR0enN44sI7C1tXXQ0tbmteD5rXMtfmtdU0sbLa1ei15Lq1emFjsZybyAk+REY6hzkEolSZDdR8ANpWQqRbIrRSfj5x9dzSNgPO+wjCEzs9nAMuCZflafZ2YbgH3Ax51zm4ejTiJycvKCQUr9KylPVCqVoq2jk5YWr0XOu0ignda2DlrbvGlbu1fe2tZOq98619rWTlt7J86lvC4qsz7dVdbdZWXdy9b9mUm/Sy6ZTJFIeH9wE326dhJ9Whq8rj2FR5GxKJHIfWDOeiAzs1LgPuAW51xTn9XrgFnOuRYzuxL4NTCvn33cCNwIMHPmzCzXWESGSyAQoLS4iNLiolxXZdBSqRQp5423SiV75pOpFC7lusNbZ1cXHR3eBQvtHZ3+xQudPfPdZen1nd1juZxL+YPpewbVp5zr+TzncP62iUSCzq44XV1xuuLx7vl4PE5nPD4kf2gCAVNJKNRZAAAgAElEQVQYlTGtK5771sCsBjIzC+GFsbudc7/quz4zoDnnHjSzb5lZ2DkX67PdncCd4D06KZt1FhEZSCAQIAAQDEIo17U5tmQy1R3OuvyxZOlB7ekrOTPHA2WOZUqPeYKeLup0gEy/OtLznT3r0mU94XWAkNldljoi7KbDadJvnUxfcNAdgNMXV2SMsQJ6jeXqtUx6HJbXFZlIeC2h6WkykehVNpou3Diavrd56bmVixeyE33OQzKZ+5aiXIjHE7muQlavsjTg+8BW59zXjrLNFOCAc86Z2TlAADiUrTqJiIw33h9g7+rHkzEUXdSjjXMuI6x4f7DNrLsrPBAIeJ3k1nMVZ88VnQHM6BMwe1/RmsroCu9Z54XA9H4CAfOW/M8IWAC6P6unO94bTN/3/nqB475i0jnXb1iNxxPdV2emu/ZT6fmU6+nuz7h6t6f7P0Uimei+wrN7mED6qs9EImM+SSLZE47SwxD8k5856blq1t8mGAyQH8ojFPJu9xIK5fnLeYTyQoRCQfJDIX85r9e21ROP/yKpoZbNFrLzgfcBz5vZer/sM8BMAOfcd4CVwE1mlgDagWvdaHvauYiIjElm5v3xDuUBJxZoR1NrKnjHnJeXp2fe5kA2r7KsBQaM5s65O4A7slUHERERkdEgkOsKiIiIiIx3CmQiIiIiOaZAJiIiIpJjCmQiIiIiOaZAJiIiIpJjCmQiIiIiOaZAJiIiIpJjCmQiIiIiOaZAJiIiIpJjCmQiIiIiOaZAJiIiIpJjCmQiIiIiOaZAJiIiIpJjCmQiIiIiOaZAJiIiIpJjCmQiIiIiOaZAJiIiIpJjWQtkZhYxs0fMbKuZbTazm/vZxszsG2a23cw2mtmZ2aqPiIiIyEiVl8V9J4CPOefWmVkZsNbM/uyc25KxzRXAPP/1WuDb/lRERERk3BhUC5mZ3Wxm5X6L1vfNbJ2ZXTbQe5xzrzrn1vnzzcBWYHqfza4Bfuw8TwOVZjb1BI5DREREZNQabJfl+51zTcBlQDVwPfClwX6Imc0GlgHP9Fk1HYhmLO/lyNCGmd1oZmvMbE1dXd1gP1ZERERkVBhsIDN/eiXwA+fchoyygd9oVgrcB9zih7r+9pvJHVHg3J3OueXOueXV1dWDrLKIiIjI6DDYQLbWzB7CC2R/8seEpY71JjML4YWxu51zv+pnk71AJGN5BrBvkHUSERERGRMGG8g+AHwKONs51waE8Lotj8rMDPg+sNU597WjbPYA8Pf+2LRzgUbn3KuDrJOIiIjImDDYqyzPA9Y751rN7L3AmcDtx3jP+cD7gOfNbL1f9hlgJoBz7jvAg3itbtuBNo4R8kRERETGosEGsm8DS8xsCfCveC1fPwYuOtobnHO1HGOcmXPOAR8aZB1ERERExqTBdlkm/PB0DXC7c+52oCx71RIREREZPwbbQtZsZp/G64K8wMyCeOPIREREROQkDbaF7J1AJ979yPbj3SvsK1mrlYiIiMg4MqhA5oewu4EKM7sK6HDO/TirNRMREREZJwb76KR3AM8CbwfeATxjZiuzWTERERGR8WKwY8g+i3cPsoMAZlYNPAzcm62KiYiIiIwXgx1DFkiHMd+h43iviIiIiAxgsC1kfzSzPwE/85ffiXdTVxERERE5SYMKZM65T5jZ2/Duvm/Anc65+7NaMxEREZFxYrAtZDjn7sN7ULiIiIiIDKEBA5mZNQOuv1V4Tz4qz0qtRERERMaRAQOZc06PRxIRERHJMl0pKSIiIpJjCmQiIiIiOaZAJiIiIpJjCmQiIiIiOZa1QGZmd5nZQTPbdJT1K8ys0czW+6/PZasuIiIiIiPZoO9DdgJ+CNwB/HiAbZ5wzl2VxTqIiIiIjHhZayFzzj0OHM7W/kVERETGilyPITvPzDaY2R/MbOHRNjKzG81sjZmtqaurG876iYiIiGRdLgPZOmCWc24J8H+BXx9tQ+fcnc655c655dXV1cNWQREREZHhkLNA5pxrcs61+PMPAiEzC+eqPiIiIiK5krNAZmZTzMz8+XP8uhzKVX1EREREciVrV1ma2c+AFUDYzPYCnwdCAM657wArgZvMLAG0A9c65/p7kLmIiIjImJa1QOace9cx1t+Bd1sMERERkXEt11dZioiIiIx7CmQiIiIiOaZAJiIiIpJjCmQiIiIiOaZAJiIiIpJjCmQiIiIiOaZAJiIiIpJjCmQiIiIiOaZAJiIiIpJjCmQiIiIiOaZAJiIiIpJjCmQiIiIiOaZAJiIiIpJjCmQZ9nUe5oYXv8V9dU/RmGjNdXVERERknMjLdQVGkj/WP8fq5u2sbt7Ov0d/xfnlC7hiwplcVHEGxcGCXFdPRERExigFsgx/PPxc93zCJXmscTOPNW6mKJDPxZWLuLxqGa8rn08ooNMmIiIiQydrycLM7gKuAg465xb1s96A24ErgTZglXNuXbbqcyzb2/ezrX1fv+vaU108eHgdDx5eR0WwmEurlnDFhGWcWXoKAVOvr4iIiJycbDb1/BC4A/jxUdZfAczzX68Fvu1Pc6K2ccugtmtMtnFv7CnujT3F5FAlb5ywlCsnnMmCoul4GVNERETk+JhzLns7N5sN/O4oLWT/D3jUOfczf3kbsMI59+pA+1y+fLlbs2bNkNfVOceWtr08eHgdf6p/jrp403G9f1ZBNRdUnMHcosnMLZzCKUWTKQsWDXk9RUREZPQws7XOueXH2i6Xg6GmA9GM5b1+2YCBLFvMjIUlERaWRPiXGW9ibcsO/nB4HX+u30hzsv2Y79/dWcfug4/1KpsUqmBu0RTmFk5mbtEUTimczCmFUyjPU1ATERGRHrkMZP317/XbXGdmNwI3AsycOTObdQIgaAHOKZvHOWXz+HTkbTzZ9AIPHl7HYw2b6XDxQe/nYLyRg/FGnmra1qu8OlTO3MIpzC2azLT8CVSHKqgOlRMOlREOleuKThERkXEml4FsLxDJWJ4B9Duq3jl3J3AneF2W2a9aj/xAHisqF7GichFtyU4eadjEH+qf46nGF0iQOqF91sWbqIs38XTzi/2uLw0UEg6VU51fTnWo3A9rPfPVoQom5VdQFMg/mUMTERGRESKXgewB4MNm9nO8wfyNxxo/lmvFwQL+buJZ/N3Es6hPtPDn+o388fA61rbsHNLPaUl10NLZwa7OgwNuVxYsYpIfzib700mhiu6ySaEKqvJKdCWoiIjICJe1Qf1m9jNgBRAGDgCfB0IAzrnv+Le9uAO4HO+2F9c75445Wj9bg/pPxoGuBta27GBH+wF2dOxnR/sB9nbGSPXfAzus8izIpFA5MwuqObVoCnOLpnBqoTctCRbmunoiIiJj2mAH9Wf1KstsGImBrD+dqTi7Og6ys+MAO9r3s8OfRkdIUAOYll/lj2WbwqlFUzm1aApzCidRqK5QERGRITEarrIc0woCIeYXT2d+8fRe5V2pBLs7D7K9/QC7Ow5SF28i5o8pq4s3cSjeTPIEx6Ydr31d9ezrqueJpq3dZQGMGQVhTi2awuKSWVxcuYjZhZOGpT4iIiLjlVrIRpiUS1GfaO0OagfjjcTizd3zdV3edDiD29zCKbyh6jW8oXIx84um6Qa4IiIig6QuyzEu6VIcijd331rjYFfv6QF/2pbqHNLPnZY/gTdUvoY3VC1mScksXTAgIiIyAAUyAaAl2cG+zsP+GLZX2d6+n+0dr7K38zDuJMeyTcwr4+LKRbyhajFnl87VQ9dFRET6UCCTAbWnuni5/QDbO/azvf1VdrTvZ3v7fvbHG05of2XBQi6sWMhlVUuoqTidPAsOcY1FRERGHwUyOSHNyXZ2tO9nbfMO/tLwPJvbosd+Ux+TQhW8LXwubw2fy6T8iizUUkREZHRQIJMhsb+rnr82bOKvDc+ztnnHcd2yI0iAiysX8Y7q13FO2TxdDCAiIuOOApkMufpEC481bOEvDRt5qmkbcZcc9HtnF0zi7dXncfXEsynPK85iLUVEREYOBTLJqtZkB7WNL/CXho080bh10FdzFlqIN05YxjuqX8eikuw/KF5ERCSXFMhk2HSlEjzd/CL3x57hsYbNg74/2sLiCG+vfh2XT1imB6WLiMiYpEAmOXGgq4H7Yk/zq9jT1MWbBvWekkABF1Uu5I1VSzmvfD4FgVCWaykiIjI8FMgkp+IuyWMNm/hF3ZM82/zSoN9XGijkosqFXFa1lNeVzydf9zYTEZFRTIFMRoxdHQf5Zd2T/ObQszQnOwb9vtJAISsqF3Fp1RKFMxERGZUUyGTEaU918cfDz/HLuieP+/5mpYFCLvbD2XkKZyIiMkookMmItql1D/fUPclf6jfSkhp8qxl4TwW4oOIMziufz2vL5jE5vzJLtRQRETk5CmQyKnSm4jzVtI2H6jfwaMMmWk/gYehzCifx2rLTOLf8NJaXzaUsWJSFmoqIiBy/ERHIzOxy4HYgCHzPOfelPutXAV8BXvGL7nDOfW+gfSqQjV3pcPan+vU81rD5hMJZkACLSmby2vJ5nFt2GotLZumh5yIikjM5D2RmFgReBC4F9gKrgXc557ZkbLMKWO6c+/Bg96tANj50puI82bSNh+rX82jD5kHfeLavokA+y0vn8lq/9ezUwikKaCIiMmwGG8iy+ZfpHGC7c26nX6GfA9cAWwZ8lwhQEAhxceUiLq5cdFLhrD3VxRNNW3miaSsAIQtyWtE0FpZEOKM4wsLiCKcUTSbPgtk6FBERkWPKZiCbDmReSrcXeG0/273NzC7Ea037Z+fc8V1+J2NeZjjrSHXxXMvLPN30Ik83vcgL7a8cewcZ4i7J5rZor6s8Cy3E/OLpnFE8g4UlM1lYHGFWYTVBCwz1oYiIiPQrm4HM+inr2z/6W+BnzrlOM/tH4EfA64/YkdmNwI0AM2fq+YfjWWEgn/PK53Ne+XzAe+D5s03beab5RZ5qepF9XYePe58dLs6G1l1saN0FdV5ZcaCA04unc3rxDOYXT2dB0XTmFE0mpJY0ERHJgmyOITsPuNU590Z/+dMAzrn/OMr2QeCwc65ioP1qDJkMZG/nIZ5uepFnml/kmaaXaEy2Ddm+Qxbk1KKpzC+a5oW04umcVjSN0mDhkH2GiIiMLSNhDNlqYJ6ZzcG7ivJa4N2ZG5jZVOfcq/7i1cDWLNZHxoEZBRNZWX0eK6vPI+lSbGt7haebX2Rd8042t0U5nGg54X3HXZKtbXvZ2rYXDvWUzywIM79oOvOLp7GgeDrziqYyOVSJWX+NxCIiIkfK9m0vrgS+jnfbi7ucc180s9uANc65B8zsP/CCWAI4DNzknHthoH2qhUxOlHOOg/FGNrdF2dIaZZM/HcpWtLSSQAFzCidzStFkTin0XnOLpjA1v0pj00RExpGc3/YiWxTIZCg553il6zBb2qJsbo2ypW0vW1qjx/30gMEqsDxmF05mrh/U5vjz0/Mn6nFQIiJj0EjoshQZ8cyMGQUTmVEwkcuqlgKQcin2dMbY2raXF9peYVv7Pl5oe4X6k+juTOt0Cba1v8K2fq4OnZhXxpT8SibnVzIlv5IpoYz5/ErCoXLdnkNEZIxSIBPpI2ABZhdOYnbhJK6YcCbgtaTVxZvY1v6KF9La9rGt/RX2dMaG7HMPJZo5lGg+6oPXAxjhUHl3QJuSX8WUUMZ8fiUT8ko1dk1EZBRSIBMZBDNjUn4Fk/IruKDijO7ylmQHL7bvY5sf0l5s38fOjgO0p7qGvA4pvDFwB+ONbGzd3e82+ZbH5PyKfsPalPwqJoUqKAsWKrSJiIwwCmQiJ6E0WMiZpadwZukp3WUpl+JAvJGd7fvZ0XGAlzsOsLP9ADs6DtCcbM9qfbpcgmjnIaKdh466TaGFqM4vpzpUQXXIm04KlfcqmxSqoDhYkNW6iohIDwUykSEWsABT86uYml/F+RWnd5c75ziUaGZH+wF2duzn5Y6D7Gjfz+7OOmLxZtwR903Ojg4XP2ZoAygNFBIOlTMhVEpFsJjyvGIq84qpCBZTkVdCRV6x9wr607wSCi2k1jcRkROgQCYyTMy8MWDhUDmvLZ/Xa108leBAvJGDXY3sj9ezv6uB/V0NHEhP4w3UJ1qHtb4tqQ5aOjvY1Xlw0O/Jtzwq8oqpzCuhKq+UqozphFApVXmlvdZV5pXoNiAiIiiQiYwIoUBe99WeR9OR6uJAV2N3QPNCmxfeXvWnx/Pg9Wzocgnq4k3UxZsGtb1hVASLqQqVUBospCRQSFEwn+JAASXBAooDBRQF8ikJFlIcyKfYL0tPS4OFVOQVUxYsUrATkVFNgUxklCgM5DOrsJpZhdX9rnfO0Zzs4EC8nle7ege2A35oq4s30eUSw1zzo3M4GpKtNCRPvvWvNFBIeV4RZcFiyvOKKA8WUd49X9y9riTohbxer6A3LVCXq4jkiAKZyBhhZl74yCtiXtG0frdxztGUbOOg34pV19VIXbyJg/FGv2WrkbquJmLxJhKkhvkITk5LqoOWrg6g/oT3YRiFgVA/Ya2gV3lhxrrCvuEuEKIoUEAoECRkeYQs6L0CeeSl581bl2cBAmrZExEUyETGFTPzB+SXMK9o6lG3S7kU9YlW6uJNNCbaaEq20ZBopSnRRkOyzStLtNGQbKUx4S03JttIuOQwHs3QczjaU11ZuW3J0QQJ+IEtSIGFKAzkUxjomaYDYGZZoR/8CgKh7mCXZ8GMV6DPtPe6/EAe+RaioNc0T62DIjmkQCYiRwhYgImhMiaGygb9HuccbalOGhJeeKtPtPgvfz7emrHszWf7NiCjQZIUSZeiIxmnmew8smuw8i2PgkAeIcujIBDqXs63UHeYC/qtenl4890vAgQtSNACXssfAX97730hPxAGe4XEI9d70zzyA17rYn66lTGQ192y2Hdd0AIYpkApo5oCmYgMCTOjJFhISbCQ6QUTBvWeuEvSkGilIdFCa7KTtlQXbckOf9pJa6qT9mQnbanO7vXtfnlrspPmZDvNyTaak7kNMmNFl0vQlRw5YwyPl2EE/GAWyJgPEugpM6Pnf973tv9l/JCHvye8MIr5wdMygqgXUoN+CA1khFSv3HtPwK9LwH9vgIC/n6C/354y6+c4vKlXl97HGaAni1r3/1vmfJ+wmj5XAf+YvDpnlh257J07cNB9mx7vcdj+vF+evoFP+lnZ6Z9B+liD3Z/Xc/76ntvu/5n1OZb0zySz3CvrPg569jeaQroCmYjkTMiC/s1py09qP0mXoiXZTlOy3e9ibafJnzanl5NtNCXau7sk21NdtCe76MhYHkkXPMjxcziSOHrd0m94bu8nI1RPSPOmed3hMtArGH5ixjW8oWpxTuuqQCYio17QAt1j4yIn8YCBhEvSkYr3hLRkT1jr6BPkjlUedwkSLkncJYmnvKm3nPDK/GURyZ4UjpRLkoABw3mniw9XlY5KgUxExJdnQUqDQUqDhcPyec45EqSIpxLEXYLOVIKOVFdGKIz3Ws4Mi+n5dLBLuBQJlyTpTxMZoS/hUiTp2aYrlaDLJehMxelKJeh0ceIKhzKOBQnmugoKZCIiuWJmhAgSCgaB3D47NOVS3hiy7rCWoMvF6Ux5wS3pUt0XICS7Q16KlEt5873WZ4RDegJi+tUTGvtOk92th+mQ2uUSxFNJuvwWx65UuoUxQZe/XarXyCWR4xccAWPNshrIzOxy4HYgCHzPOfelPusLgB8DZwGHgHc653Zls04iInKkgAUoNO8WG6ORc14oS+FwzvlhsXeZ133lSJHyBqD769Nxzlump6zPcsq5I4Jnej4dTFNHrHOk+myXZIAyl+pVZwekMo/lKMcEGQPtM8Kpdxz0WU/38aW66+JNM5ddP+Vp6UH20HMhhFd+5DrnHAmX7N5Hz3lyJP3yhH8eUnjrjzz//hG4jJ9Pn7LMuqfP42CNhPsBZi2QmVkQ+CZwKbAXWG1mDzjntmRs9gGg3jl3qpldC3wZeGe26iQiImNTOhQEAAxCua6Q5FxmME+35qaDcjpcp4NhVV5Jrqub1Rayc4DtzrmdAGb2c+AaIDOQXQPc6s/fC9xhZubS18qKiIiInAAzI48g5L43clCy2UY3HYhmLO/1y/rdxjmXABqBoz9dWURERGQMymYg6y+T9m35Gsw2mNmNZrbGzNbU1dUNSeVERERERopsBrK9QCRjeQaw72jbmFkeUAEc7rsj59ydzrnlzrnl1dXVWaquiIiISG5kM5CtBuaZ2RwzyweuBR7os80DwHX+/Ergrxo/JiIiIuNN1gb1O+cSZvZh4E94t724yzm32cxuA9Y45x4Avg/8xMy247WMXZut+oiIiIiMVDbaGqTMrA7YfZxvCwOxLFRnNNE50DkAnQPQOQCdA9A5AJ0DGJ5zMMs5d8zxVqMukJ0IM1vjnFue63rkks6BzgHoHIDOAegcgM4B6BzAyDoHub81rYiIiMg4p0AmIiIikmPjJZDdmesKjAA6BzoHoHMAOgegcwA6B6BzACPoHIyLMWQiIiIiI9l4aSETERERGbHGdCAzs8vNbJuZbTezT+W6PrlgZrvM7HkzW29ma3Jdn+FgZneZ2UEz25RRNsHM/mxmL/nTqlzWMduOcg5uNbNX/O/CejO7Mpd1zDYzi5jZI2a21cw2m9nNfvm4+S4McA7GzXfBzArN7Fkz2+Cfgy/45XPM7Bn/e/AL/wbmY9IA5+CHZvZyxvdgaa7rmm1mFjSz58zsd/7yiPkejNlAZmZB4JvAFcAZwLvM7Izc1ipnLnbOLR0pl/YOgx8Cl/cp+xTwF+fcPOAv/vJY9kOOPAcA/+1/F5Y65x4c5joNtwTwMefc6cC5wIf83wHj6btwtHMA4+e70Am83jm3BFgKXG5m5wJfxjsH84B64AM5rGO2He0cAHwi43uwPndVHDY3A1szlkfM92DMBjLgHGC7c26nc64L+DlwTY7rJMPAOfc4Rz4T9RrgR/78j4A3D2ulhtlRzsG44px71Tm3zp9vxvslPJ1x9F0Y4ByMG87T4i+G/JcDXg/c65eP9e/B0c7BuGJmM4C/A77nLxsj6HswlgPZdCCasbyXcfaLyOeAh8xsrZndmOvK5NBk59yr4P2RAibluD658mEz2+h3aY7Zrrq+zGw2sAx4hnH6XehzDmAcfRf8bqr1wEHgz8AOoME5l/A3GfN/H/qeA+dc+nvwRf978N9mVpDDKg6HrwP/CqT85YmMoO/BWA5k1k/ZuPsXAXC+c+5MvK7bD5nZhbmukOTMt4G5eF0WrwL/ldvqDA8zKwXuA25xzjXluj650M85GFffBedc0jm3FJiB13tyen+bDW+thlffc2Bmi4BPAwuAs4EJwCdzWMWsMrOrgIPOubWZxf1smrPvwVgOZHuBSMbyDGBfjuqSM865ff70IHA/3i+j8eiAmU0F8KcHc1yfYeecO+D/Uk4B32UcfBfMLIQXRO52zv3KLx5X34X+zsF4/C4AOOcagEfxxtNVmlmev2rc/H3IOAeX+13azjnXCfyAsf09OB+42sx24Q1hej1ei9mI+R6M5UC2GpjnX0GRD1wLPJDjOg0rMysxs7L0PHAZsGngd41ZDwDX+fPXAb/JYV1yIh1CfG9hjH8X/PEh3we2Oue+lrFq3HwXjnYOxtN3wcyqzazSny8CLsEbS/cIsNLfbKx/D/o7By9k/MPE8MZOjdnvgXPu0865Gc652Xh54K/Oufcwgr4HY/rGsP6l3F8HgsBdzrkv5rhKw8rMTsFrFQPIA/5nPJwDM/sZsAIIAweAzwO/Bu4BZgJ7gLc758bsoPejnIMVeF1UDtgFfDA9lmosMrMa4AngeXrGjHwGbwzVuPguDHAO3sU4+S6Y2WK8wdpBvEaIe5xzt/m/H3+O11X3HPBev6VozBngHPwVqMbrulsP/GPG4P8xy8xWAB93zl01kr4HYzqQiYiIiIwGY7nLUkRERGRUUCATERERyTEFMhEREZEcUyATERERyTEFMhEREZEcUyATkVHNzP7DzFaY2ZvNLCcPCjezR81seS4+W0TGBgUyERntXot3b7GL8O65JSIy6iiQiYwS0ZrwqmhN2EVrwuuP4z3Of83OYtVywsy+YmYb8Z7D9xRwA/BtM/tcP9tWm9l9Zrbaf53vl99qZj8xs7+a2Utm9g/Qc95OKQpuM7PnzeydGfv6V79sg5l9KeNj3m5mz5rZi2Z2QTaPfSz/XMfysYkMJO/Ym4jIYERrwruAWf5iTaQ29je//ALgcb98d6Q2Nnv4azf2OOc+YWa/BN4H/AvwqHPu/KNsfjvw3865WjObCfwJOP1b80tXXBUuuCiecj+d+9ThdwDPmdnv95w/EYD7F1dcsfTZ+lZgtZk9jnd3+zcDr3XOtZnZhIzPyHPOneM/IeTzeI+nGXGiNeG34z23cAJwC3BDpDZ2Wm5rJSJqIRPJjpsy5v8xZ7UYRaI14RP5B+IyvEe+LAC2DLDdJcAdZrYe71mW5ennvAKEApZ0zsXwnmvX/YDlCaFAyjl3AHgMryXuEuAHzrk2gMxHLlXlWfoZeGuB2SdwLMPljcAjkdpYF3AF8GCO6yMiqIVMJBvqgZXRmvAteM+Ie5tfVpW5kd8l8xWgBijECxafitTGnvHXTwN+CJwPrAP+2veDojXhRcCX8cKC4bXE/XOkNrZnMBWN1oQ/DnwQmIb3++AF4P9EamP3+uvzgA8B/wCcAjQD34zUxm7z178Pr5XlNCAO/DJSG/tgtCZ8K14r0Y8itbFV/rbp57TNidTGdmW0KP4v4N14oSoYrQn/l3/OpuA9f3Gjf14e9fdTvL0t+bX8AKtePG9CQVPCJf7v3vamF1sTiWhN+IaUcy/N+tuh0/xtzwWeevzMytSF6xpmOefaM479VrxxZwDXRWvC1z20tOLAZesb78s4RZdEa8Ife/G8Cae+2pmKXL6+YX17ChetCa/Ca2X6G/D8tnMn1OzpTL4XePyxMyvf2JZykU1HQcwAACAASURBVGhNuBk4DPwO+GykNtYQrQmvwAt93S2l0Zrwo349ro/Uxn4YrQlXAHfihaVdeN+B/wIaI7Wxyj4/wkuiNeGPATPwHor8fj9o9fezTn9Oejn981gRrQnfHKmNmV8+4Hcq430fAf4ZmAjcB3w4Uhtr97d5C94zMxf0PQf++tOBf8cb/1cFbAOuidTGdh/r2Pz/br7jv7cQ73mkP4/Uxj7f33GLjBZqIRMZej8CCv5/e3ceH2dZ7///9ZnJ2jZtk0y6pxu0tAVLC2VRwqogRY4IopYjKrigiB49x/VsCh49+vvqccEFFQ8g56hQNsFjWUTKEtm60AJNoS2lbdLQNmubNOvMXL8/7nuSSTJJJmkmk+X99DGP+76ve/vMndvOh+u67usGPu5/svF+VDuUl4Qm4iVYVwI7/PnzgCfKS0LH+Zv9HrgQ7wfnTeBr3Y4xA+/H8kKgFK9j+xXAo+UloewkY12A9+LpO/B+9E4E/jeu/85NwI/xkrH78GqKlvjn/xRwJ3Ay8AheTcuiJM8b7yY/hvvjYnoB+G+85OUM4J7yklCsRuvW4ycEPz03J9j0RG3boaJMe/i0vIy3njsSPh/YHjBbVF4SitVyvRfgucPtZcDnYic0sxXA8xUtkf0AUedeawhHf3XvodYsYENsO+fcd49G3BYguCA3eO5PF+c54ONHwtEsf5OzgAv+Wtd2qLrNVZSXhFYvyA3+dlFuMMv/Pg3AZ/FeXpysm4EPAkfwattu7GPb7/rXKgP4MF7zbW/upfM+/F86r/cv8Jp0B3pP/Tve/dCGd59/2z/Gav/Yy0lwDfxzPIPX9HvAj8Xo9h8sfXy3b+PV8m3Au//K8e4RkVFNCZnI0HsKr/nsOv9TRmcfspj34CUeu4Hzikur3w/8EZgAfKK8JDSHztqMi4pLqz8K/LzbMT6C9yO2Cy9p2wVU4SVM5ycZ61f989YC+/39s4F3lJeEDPgHf7sPF5dWf6S4tPqDwMf8si/4068Ul1Z/oLi0+mq8H8qB+s/i0uo1xaXVH/CXPwn8FTgM7ASagBDwtvKSUAivNo2/1be//zOvN26c+7ea9/7jzsajzrkyvCQO4Gp/+l6AwszAJ4FVZvaymZUBnykurX5kS2N4F8Djte1TTnyh7p2/rmz5mnOuMhbYl3YdbV76fO1J+1oizwBcVJiVCTz0//Y2fROgNeragDM++3rjjqu2HVmHV2vErZUt9cWl1R/DS7LDwLvLS0L99tMqLwkFgTX+4oeLS6uvxatp7M1n/RrItf7yyt42LC6t/hnwF7wE6eN4yd7rxaXVNxSXVn/R32wg99R1xaXVH8erPQX4qD/9vD/9z16uwdV4tWpbgFXFpdWfKi6tPhl4NcnvlulP1+PVlF2K9/8nkVFNTZYiqfFLvJoO6PyBijffn75eXFodawJ6zZ/OA2b7883FpdXl/vyOXo6x1P/EO76/AMtLQlnA88BJCVYX4SVBk/zl52Mrikur2/3ZBX2s636uYB+h/C1uu0K82rKZvcQUO37bmlcPr1/j/SjTFnWxGpI78WpWPlReEvoZXo3fxk9sP/LCJ+BDPY7ou6gw6zHn3DXdy3+4aNIF9xxs2VVeEvoJcA4wyTn3vfKS0AHg9uyAbS4ura53XtIRa4bmhjm5nwYoLq2uLi8JVeM1v86Liz9e/LUJAbHat+3+tK++cS/503p/OinRRnFNrDFtcescfnMpA7unYvHF7tuQX4s2P359gmsQu29eLC6tjsYOVlxaHU7yu92I14z5H3jNnq3AT4GvIDKKqYZMJDXuxKvZOQr8T4L1e/zpYr8mCuAEf7oXr7YKILe8JFQc27aXY9xfXFptsQ9eMvPf9G8ZXjIWwWtqDND5429ANdDoL3c0CcV1vn+zj3VH/elkf5oo6YtpjZs/24+/Cu8HPJvOH2SLO2dWeUloRffzFpdWV+F12p8G/Mxf/fveThx1xBKC3v4tjCUJrpf1rd2W9/jTWLNuIV6SBd7fNXZd8vz1mXT9u1bTmSzFmn+X9HLuZOKLKcNrlqwFnvXnw8DD/nzs7x6LP5l7KpawxeKrLi6tbqX/axD7G55WXhLquO4JHuro7bvtLi6tPguYgvcARi3w5bj/n4iMSkrIRFKguLT6MF6Nyrn+fHd/xvvhOg5YX14Suhe4HGgGbisura6gs5nzsfKS0J3E9YHy/Q4vWbmivCT0aHlJ6FflJaHH8frUTE8izGq8TvNB4Id4zVkdfcD8mrtYLd/vyktCd5aXhH5PZz+kn/jT75eXhNaWl4R+i/cDD521G5f4nfST7UN10J8WAT/CuwYdtT7FpdXVdCZYfy0vCf13eUnofuA7ccf4jT+90P9+vZ77vUXZd/qzq8tLQj8tLwm9P8k4exNrVv6X8pLQHcCTeC0Rfykurd6BV8vZBBT4f9M/4yWPABSXVkeAP/iLfygvCd0GfOsYY6K4tPpFvD6IE/EeJPmRH9dXi0urv+ivh4HdU78qLwn9N3Crvxz7D4/+rsH/AjV4TZAv+ufYSN9Je7xflJeESvHuvxvwkr0Inf/xIDIqKSETSZHi0upNxaXVm3pZdxR4J15H+SV4wyk8BbyzuLR6l7/Zh4HH8Zp5FuMlTfHHqMTrZ/Z/eONjXY3X1PlzvGSrv/gq8JpTD/rH2YRXexLvm3hP0r2J9wDCO/GbTotLq2/F6zf0MnAJ8Hd4feIoLq1+HC+Za8ZLNH9GEopLq5/DS67q8BKqP9BZWxjzKbzmqmq8a3Q6Xl+nmMfw+j8BPFlcWv1WH6e8B29Msol4CW+yfe96i//PeB3yt+FdrynAr/CbS/3k/DNAJXAx8AZxTb6+L/hx5QOr8J54hJ61cQN1Kl6N47N4DyPU+3HGxz+Qe+obeP/RkY33IMu/+cfo7xocwKsJ/aN/7I/iJWx1SX6PZ/GS9A/553kdr79dsvuLjEjmXH813SIio0t5SegWvMTnE8Wl1belO56B8J8mbYz1LSwvCf0zXl+p0uLS6pS+ASAZ3YcvSWcsImOJOvWLyJhRXhJaBlwGfACvb9Hd6Y1oUN4J/Ft5SehhvKcRr/XLb+59FxEZ7ZSQichYcjpebdI+4NN+0/Bosw+vX9+X8Dr4bwX+q7i0+p60RiUiKaUmSxEREZE0S1mnfjO7zcwOmVn3wf5i683MbjazXf5gjaekKhYRERGRkSyVT1negfcUUW9W4z1ivwhvNPNbUhiLiIiIyIiVsj5kzrmnzWx+H5tcBtzpvDbT581sqpnNdM719Yg6oVDIzZ/f12FFRERERoZNmzZVO+eK+tsunZ36Z+MNNhhT4Zf1SMjMLPZOQObOncvGjRuHJUARERGRY2Fme5PZLp0Dw1qCsoRPGDjnfu2cW+WcW1VU1G+SKSIiIjKqpDMhqwDi3z02B2/0ahEREZFxJZ0J2UPAR/2nLc8EDvfXf0xERERkLEpZHzIz+wNwHhAyswq8d+JlAjjnfgmsw3v/3S68l+1em/hIIiIiImNbKp+yvKqf9Q64IVXnFxGR0c05RxRH1EWJECXay3JMfMdk69ZNObZsiXovJxULOP9/ERfF4brEE/XXeWXxsToiRHH+NLZt1HUeJ9JRFu31+8SWYmVmsWXrsjZ+vfklHeu6lcXO5EXuXW/8+e7lzi/pck26zHcuxQ847+LWRp3rPCbRLte063rX8W1iscZij31HwzCLX4qPxz+KI+5o3b8LXc51et4i5mQXkk56dZKISIpFXJQ2F6Y9GqbVhWmLhmlz7bRGw7S5MG3RdtpcxEs0Yj/23X7ce0sAIi7a8aPvJSr++rj5zuTFm4ZdlCjeucIu0pEQxOY7PnSddz2Si1gMXsQR1xlTfLzxiYrrUeY6E69uscf/yIuk0vcXflQJmYhIqkRclNZoO20uTGu0ndZoOy3RdpqjbTRH22jxpx3Lkdh8O83RVn+b9i6JSthFuiQqYRch3JG0RPyyKO0u3JFwhV0k3ZdCREY4JWQiMiJEXJSjkRYaIi00Rppp7DHfdXo00kJLtJ1W105bNExLt8SrVYmQiCRpJLzWWwmZiAw55xzN0TZqw43UhRupCx+lrr1zvrZbWX34KEejrekOW0TGqZHQPK6ETESS0u4i1LU3Uhv2P+0N1IYbqfGn3de1unC6Q5YxwDCCGAELeB+MoBkBOpe7duju/HHt0bXcda7v3uk/qVjMCGAEOs7vdTkPxOLz11nHNl3Lg3Exd36XuGV/H8O6dpLv9r1wXZdjXfE79ujSeT6+wz5dyi3uKnQ+9BDfTZ7O+W7lHdeky7wlXBG7RvEd8bt21vfXd3tQoeP7ufjvkqgsdhW6fp/Y8TuXu5bFbzc7u4B0U0ImMo4552iINHOo/QjV7Ueo8qfx816C1cjhSFO6wx3VsiyD7EAGWZZJViCDLMvomGYHMsmyjI4fZ/N/vPtLAAz8fbx1sflYwhL0f+RjiUAssQnGPnTOZ1jQTxCCZHQkC/583L7d4wsSiEs+usYZtEBcvLFEJdDx49yRgMQlIt0Tl/gfT5GxTAmZyBh2NNLCvtZq9rZUUdFaw6H2w37C1dCRcLWN8ZqsHD8BiiU9uYEscgJZ5AazOucDsfnMjvn49ZkWJMOCnckLnfNeMhMgGFeWYQEy4xKtTAsqsRCRPikhExnlmqNtlLdUs6+1ir2t1exrqepIwmrCDekOb0AmBrKZFMxlUjCHvGAOk4I5HcteWef8pGBuRxKVFcgg2zLJDmSS7Sdf2ZapREhERg0lZCKjQMRFeautjjdbDvJmyyH2tBxiX2s1+1qqOdhen+7wEsq0IPkZk/zPRAoyvWl8WX7mJAoyJjE1YyJ5wVyCls63uYmIpI8SMpERpDHSwh4/4fI+VbzZcpB9rdVpb1o0jKkZE8jP8JKogsw8Cv2ptzyJwow8P/nKY2IgW7VTIiJJUkImkgYt0TZ2Nr/Fa0372dFc2VHrVdV+ZNhjybFMQpmTCWVOZlrW5I75In8aysijINOrxcqw4LDHJyIyHighE0mxhkgzrzftZ3vTfl5r2s/2pgr2tBwiQjTl5w5gzMoqYF5OEXOzQ8zMLqAoM69LwjUpkKOaLBGRNFNCJjKEatob2N5UwWtxyVdFW01Kz2kYM7KmMjc75CdeRR3zs7MKyAzo/+YiIiOd/qUWGaCoi1LZVseelkPsbjnY0dH+zeZD1EeOpuy8k4O5LMiZzvycaczPKWJedhHzcqZRnF1IdiAzZecVEZHUU0Im0ou2aJi9rV6n+t3NB/0E7BB7Ww7R4tpTcs4AxpzsQj/pmsYCfzo/exr5GRPVtCgiMkYpIROJU9veyOP1W3mk9iW2NO5JaT+vGZlTWTJhNksnzOH43JksyJlGcXaILDUxioiMO/qXX8a9I+Fmnqh/hUfqXuLFIzuHPAkzjLnZIZZOmMOSCbM7PvkZk4b0PCIiMnopIZNxqSnSylOHy3i09iVKj2yn3UWG5LiZFmRhznSWxCVfJ+TOYmIwZ0iOLyIiY5MSMhk32qJhSo9s55Hal3jqcBkt0bZBH2tSIIcFudNYkDOdhTnTWZDjzc/OLtBYXSIiMmBKyGRMa4m28WLDLv5St5X19a/QEGkZ0P6hjDwW5s5gQc40P/Hykq+izMnqYC8iIkNGCZmMOQfb6nn6cBlPHy7jxSM7B/xE5MysfN6dv4KLC1ayJHe2Ei8REUk5JWQy6kVdlG1N5Tx9uIyn6st4vXn/gI8RysjjooIVXJy/krdNnEtAL7kWEZFhpIRMRqWjkRaeO7KDpw+X8czhMmrDjQM+xuRgLhfmn8y781eyKu84gkrCREQkTZSQyajRHg2zrnYz62o3s7HxDcKDeDJyQiCb86eexOqClZyZt1ivFRIRkRFBv0Yy4rVE2/hj9YvcfuAJDrTXD3j//IyJnD1lGedOWUbJlKXkBLJSEKWIiMjgKSGTEasp0so91c9x54H1VIcbBrTv4tyZnDvlRM6ZsowTJ85Vc6SIiIxoSshkxGmINHPXoVL+9+DTSb+sO8syOCNvEedMXcbZU5YxMys/xVGKiIgMHSVkMmLUhRv53cFnuKvqmaTGCyvKnMw5U5ZxzpQTOT3veCYEs4chShERkaGnhEzSrrr9CHcefJK1Vc/SnMTo+edPPYlrp1/A8onzNEaYiIiMCUrIJG0OtNVx+4H13F/9PG0u3Oe2hvHu/BV8cuY7WZQ7a5giFBERGR4pTcjM7GLgJ0AQ+I1z7nvd1s8DbgOKgFrgaudcRSpjkvRrjrZx24G/cseB9f0mYkECvKfwVD4x453Mz5k2TBGKiIgMr5QlZGYWBH4OXAhUABvM7CHnXFncZj8A7nTO/dbMLgC+C3wkVTFJejnneKxuKz+seKjf4SsyLcj7Cs/g2hkXMDu7YJgiFBERSY9U1pCdDuxyzu0GMLO7gMuA+IRsGfCP/vx64I8pjEfSaGdzJd/b9wAbG9/oc7scy+TKorfz0ennMT1r6jBFJyIikl6pTMhmA+VxyxXAGd222Qq8H69Z83Igz8wKnXM1KYxLhtHh8FF+Ufkoa6v+RhTX63YTA9l8aNpZXD3tXAoz84YxQhERkfRLZUKW6PG37r/IXwZ+ZmbXAE8D+4EenYrM7DrgOoC5c+cObZSSEhEX5YHqF/jp/nV9jiWWaUGunnYu1844nykZE4cxQhE5Fs45nHNEo1GizhGNRIlEozjnvGnU++feAoZhmIEFAhgQ8KeYEYhfbwEc/jGjncePP2Y0dk7/vLHzxOvy9LUlLveOFe04V/z3iJ0jds7Y9wqHI4QjYcLhCO3hsL8c6Zi2t4cJRyJEOsrDOAdm3nc1/O/rx2HmzVts3r8WA/5b+D+tzjlw/t+m29+p+98N/+/gfYxgMEjQXw4GAwQDAYLBoLeuYz7QcYzY3yXqX0fnHJGIX+b/Xbzr61/LiHetw5FIx3IkGiUSiRCJRjvuH6+887V4sXuD2DXruFesy9/TzAj41zBgAX/qf4IBb50FOq5/IBDo3D4Q4B2nvo35xel9YCyVCVkFUBy3PAeojN/AOVcJXAFgZpOA9zvnDnc/kHPu18CvAVatWtV7NYuMCFsa3+R75Q+wvanv5zPOmbKML8+5jHk5RcMUmUjqxH6w43+oO+b98kjcj3bXbcO0t0eIRLv+WEX9H6dIJPaj5v94xW0TjkQIt4dpD8c+fS+Hw5GOH8dEiUdHshONWxeXEHnL3nqRsaLgK58Z0wnZBmCRmS3Aq/laA/x9/AZmFgJqnXNR4J/xnriUUepQ22F+vP//+HPtpj63m5tdxFeLL+PsKcuGKTIZrZxztLa109rWRktrGy0tbR3zra1tnf+17ScvsflI3Hz8NBqN0tYepr09TGtbO+3t7bS1h2lra6etvd0r96dt7e1+ebgj6QknSqj8+Uhk4C+7F5GRIVb7l04pS8icc2Ez+xzwKN6wF7c557aZ2beAjc65h4DzgO+amcNrsrwhVfFI6jjn+J9DT3FL5aM0RVt73S43kMV1My/k6mnnkhXQEHhjUUtrGw2NRzna1MzR5haamlpoam7haHMzTf7y0eYWjjb5y80t/nbNXpLV1k5La2tHwtXa1t6luUVEJBUCgfQPMp7SX0Xn3DpgXbeyb8TN3wvcm8oYJPV+uP9P3HnwyT63eU/BqXxx9qVMy5oyPEHJoDnnONrUTN3hBuqPNHCk4ShHGo/S0HiUww3etLOsicMNjTQ0NnGk4Sht7e3pDl9EZMACI+CtL6qmkGPycO1LfSZjS3Jn8/W5V7By0oLhC0p6ONrUzKHqOuoOH6H+cAN1/qf+SINf1kjdkQbq/fn2cN8D9opAZ0fqWMfwzo7SgY4fOIfDOXBR7znrWKdvnFfudQgH/PL4jtmxY5rf+b/78b11dOkI74jvwB4XbHzHdhxmXsd18zutm1m/yxkZGWQEg2RkeJ/M+OVgkIzMbssZGZh5p3ax7wxeh3g/Jq8fvvM724Nz0UF17O/o9B7r8B7rDO8Xxh4ciP3dDIj6HfE7+yVG/I73nU388fORSMR7EKOjA31cx/huf5eAX4YZGbGHA/wHAzICAQLBAMFAsOMBgu7LZuY/nOA6/nRebbnrvJ7+n9XR7X7q8vCH8/o8+g8g9PagyJxZ0wd+zYeYEjIZtF3NB7hp790J100NTuRzs1dzRehMgpb+tvmxrL09zKGaOg5W1XCgqoaDVbUc9KcHqmo4WF1LQ2NTusMcF4JxP8aZGRlkZgbJCGZ0/IDHftAz/fnMuLLYfgH/x6n7j1aiH7RAIOCdJ3au2PEzMzrKMzJ6Lgf9fb0fvgDBoHU8cdeRjAS7LXdJTgJdnhYUkWOnhEwGpTHSwj+9cXvCl4FfETqDL86+VMNYHINwJEL94YaO2iyvJqshrnbriJd4VddQXXt4TPezysrMJDs7k5zsLHKys8nOyvSm2ZlkBIMdSUrHI/sB60hkArH/+vYTiUAgQGZmJlmZGd4nK4vM2Hxmpv/J8LbJ6twuI5bY+NNY0hOrBcnM8OJQgiIig6WETAbMOce/7/kDe1ureqy7KH8F35j7Qf0wJeCco/5IA4eq66iqqeNQTR3VNfVU1dZRV9816TrS2PvYbSNZMBhk8qQJTJo4gQm5OUzIzWFibg4TJvjzE3K95dxcJkzw1/mf3JxscrKzycnOIjs7y5tmZREMqoZVRMY+JWQyYHccXM8T9a/0KF+YM52b5n1oXCZj7e1hDlbXcqi6tiPZqqqpo6raT7xq66mqqR81fbOyszKZOiWPqZPzmJI3icl5E5k8aWKXad6knmW5Odnj8u8vInKslJDJgLxwZCc37/9zj/KJgWx+eNw1TAhmD39QKRaJRKmuq+/sm1Vd6897TYYHqmqpresxnvGIEgwGmR7KpzB/ClOn5JE/ZbI/9ZKu/Cl5XZaVWImIDC8lZJK0A211fO3N/0n4Tspvzb+KBTnpf0rlWDS3tLJrTzk73tjH67v3snvvfg5U1VBdU08kGk13eH0qyJ/C9FABM4oKmV7Uc1owdYqa/kRERjAlZJKUtmiYL+/+LXXhxh7rrpl+Pu/KX56GqAavtv4IO3bv7Ui+duzex779B0bU62AmT5rYUWvVWYPVWbNVVJDPjGkFFBXmk52Vle5wRUTkGCghk6R8v+KPvHJ0X4/yVZOO4/OzL0lDRMmrrq1na9lOdryxl9d372PH7r1U1dSnJZYJuTkUFeZTVDDVm4bymVaYT8HUyV2SrSmTJ5ERDKYlRhERGX5KyKRff6rZwNqqZ3uUT8ucwv9b+FEybGQlDm3t7WzdtpPnN7/Cc5tfZefunolkKsSaDaeH8r1kK+4zzU++Jk3IHZZYRERkdFFCJn16rWk//7H3nh7lGRbkBws/RmFmXhqi6so5x779B3l+8ys8v+kVNr68nZbWnuOjHYspeROZVlToJVxFBZ1Tv2xaKJ+szMwhPaeIiIwfSsikV0fCTXzpjTtodT2HavjqnPdx8qT5wx+Ur7GpmY1byrxasE2vUHmwekiOO2t6iMXHzWPxwrmccNw85s6ewfRQAbk5Y+/pURERGTmUkElCURflX/b8noq2mh7rLi1YxQeL3jGs8TjneLO8kqeff4lnN2zl5dfe8N6rNkjBYJCFc2d1Jl8L57J44VzyJuntAiIiMvyUkElCtx54nGcOl/UoX5w7k3+bd+WwjFEVDofZsm0nT7+wmWde2ELFW4cGfazj5s3hlLedwJLj57N44VwWzputJkYRERkxlJBJD387vJ1bKh/tUZ4XzOGHx11LbiB1Qyw0Hm3i2Y2v8PQLL/Hsxq2Dfin2lLyJnL7yJM48xftMCxUMcaQiIiJDRwmZdNjXUsWjdVu48+CTuASDv357/ocpzg4N+Xn3H6jimRde4ukXXmLzK68PqikyGAhw4gkLefupy3n7qSex5PgFGghVRERGDSVk41xFaw2P1W3h0dotvNa8v9ftPjXjQs6beuKQnbeqpo6HHnuax595kV17KgZ1jBlFhZx56km8/ZS3cdqKZer/JSIio5YSsnHorbY6HqvbyqO1L7Gtqbzf7d8++QSun/XuYz5vNBplw9bt3L/uCZ56bvOAX0cUCBgnL13E2WeupOS0Fcwvnqn3LYqIyJighGycONhWz1/qtvJY3Va2Ht2T9H4zs/L53oKrCdrgm//qjzTyf48/wwPr1rOv8uCA9p2Qm8PbT30b55yxknecdjJTJ08adBwiIiIjlRKyMexopIV1tZv5c+0mXmp8c8D7v2PyCdw470NMzRh4U6Bzjldee4P7/vxXHn9mA23t7UnvO72ogLNPX8k5Z67k1OVL9DSkiIiMeUrIxqAdTZWsrXqWP9duoinaOqB9l06Yw7vzV3Bh/snMyS4c8LmPNjXzyPrnuO/h9QN6ZdHS4+dz9pkrOeeMlSxeOFdNkSIiMq4oIRsjWqPtPFa3lXuqnh1QkyTACbmzuCh/BRfln8zcnKJBnX/H7n3cv+4JHl7/HE3NLUntEyqYyvsuPpfLLjqXGdMGnvyJiIiMFUrIRrm9LVXcW/0cD1a/yOFI8mN2HZczg4vyT+bdBStYkDN9UOduaWnlsadf4IGHn+TV199Ier8zVp7IFZdcwDlnrCAjQ7egiIiIfg1HoXYX4an6bdxT9SzPN+xIer/52dN4d8EKLspfwfG5MwZ9/l17Knjg4fWse+JZGo8mlwROyZvIpReezRWrz2fu7MGfW0REZCxSQjZKtEbbebPlEE/Uv8L91c9T1X4kqf0mBLJ5T8GpvL/oTJbkzh5036yW1jaeKN3A/Q+vZ2vZzqT3W770eN5/yQW88+zTyM5K3Qj/IiIio5kSshEm4qKUt1azq/ktdjUf8D4tb7GvpZoIyY/btTh3Jh8oOov3FJzCxGDOoOPZU17J/Q+v58+P/40jjUeT2mdCbg6rL3gHV6w+n8UL5w763CIiIuOFErIhciTcTLsLD2if5mgbb7Yc7Ey8mt9id8tBphpe6gAAH4xJREFU2gZ4nJgsy+Ci/BV8oOjtnDxx/uBrw1paefK5zdz/8HpeevX1pPdbvHAuV6w+n4vPfzsTJ+QO6twiIiLjkRKyY7Sr+QD/tuf3bG8a3Ot/hkJxdiEfCL2D94ZOIz9jYAOnhsNh3ti7n207dlO2403Kdr7J7j0VSY+in5OdxUXnnskVq89j2eKFGq5CRERkEJSQHYPnjrzOl9/4LY3R5IZ5GEpBApw79UQ+WPQOzshbRCCJkfSj0Sj79h/oSLzKduxmx+59tLYlP2hrzPHz53D56vO55IJ3MGnihMF8BREREfEpIRuk+6uf5zt77yU8gH5dx2pa5hSOz53BKZMW8t7C05ieNbXP7esOH2Hrtp288touyna8yfZdezja1Dzo82dnZfKuc87gitXn87Ylx6k2TEREZIgoIRugqIvy08p13HbgiZSdY3Iwl0W5Mzm+4zOD43NmMDmj95oo5xx79x9g67YdbC3bydaynezbf2BI4llQPIvLV5/Pe955FpPzBv4aJREREelbShMyM7sY+AkQBH7jnPtet/Vzgd8CU/1tvu6cW5fKmI5FS7SNf9/zBx6r25pwfW4gi9xA8kM7GMaMrKkcnzvTT8BmcHzuTEIZef3WPrW1t7N95x5eLtvJlrIdvFy2i/ojDQP6Pn2ZXlTAquVLuezd57LixMWqDRMREUmhlCVkZhYEfg5cCFQAG8zsIedcWdxm/wasdc7dYmbLgHXA/FTFdCxq2xv54hu39fpaolWTjuNHx13bZy3WYDS3tHKwupaDVbUcrKph7/4DvFy2k7Idbw7ohd19mTo5j2WLF3ifRQtZtngBhflThuTYIiIi0r+kEjIzuw+4DXjYOZdsp6nTgV3Oud3+Me4CLgPiEzIHTPbnpwCVSR57WL3ZcpDP7fwNFW01Cdf/XcEqvjnvg2QGBpbftrS2UVVT5yVb1TV+0lXLoerajiQs2bG/kjUxN4cli+Z3JF7LFi9g5rSQasBERETSKNkM4hbgWuBmM7sHuMM591o/+8wGyuOWK4Azum1zI/CYmX0emAi8K9GBzOw64DqAuXOHd6DRDQ27+Kc3budIJHFn+M/OupjrZlw4oIRmy7Yd/Op/H2DzK9uJRt1QhdqDmXHcvNmcvGwRb1t6PMsWLWTenBkEAv0/kSkiIiLDJ6mEzDn3OPC4mU0BrgL+YmblwK3A/zrnErWdJcpQumcfV+Eld/9lZm8H/sfMTupeC+ec+zXwa4BVq1alLoPp5k81G7hx71rCLtJjXaYFuWneGt5TeGrSx9u3/wA/u/0e1j+7cSjD7JCdncWJixeyYtkili9bxPKlx5M3SZ3wRURERrqk29jMrBC4GvgI8BLwO6AE+BhwXoJdKoDiuOU59GyS/ARwMYBz7jkzywFCwKFk40oF5xy3vPUov3rrsYTrpwQn8KPjruXUvOOSOl794QZ+84cHuffPTxCJ9EzuBqsgfwonL13EycsWseLERSxeOI/MTD04KyIiMtok24fsfmAJ8D/A3znn3vJX3W1mvVX3bAAWmdkCYD+wBvj7btvsA94J3GFmS4EcoGpgX2FotUXDfHPvXayr3Zxw/dzsED89/pPMz5nW77Fa29pY+9Dj3Hb3n2g82jSoeIKBAEWF+UwL5TO9qJDpRQUcN28OJy9bxJyZ09T3S0REZAxItjrlZ865hANvOedW9VIeNrPPAY/iDWlxm3Num5l9C9jonHsI+BJwq5n9I15z5jXOuWFrkuyuPnyUf3zjdjY37k64fsXEBfz4+Gv7fT2Rc46/PP0CP7/jHioPVve5bcHUycyeUcT0UAHTQgVMLyrwEq9QAdNC+RTmTyUYVJ8vERGRsSzZhGypmW12ztUDmFk+cJVz7hd97eSPKbauW9k34ubLgLMGFnJq7Gup4oZdv2Ffa+IKutX5K7lp/hqyA5l9HuelV1/nJ7+5i207Eid1MUWFU/nMR97Pe95ZooRLRERknEs2IfuUc+7nsQXnXJ2ZfQroMyEbTf5f+R97TcY+NeNCPjvr3X2+L3JvxQF+dsdannx2U5/nyc3J5iNXXsLVV6wmNyf7mGIWERGRsSHZhCxgZhZrTvQHfU1+SPpR4Mb5H+Ijr/2Eyra6jrIMAvz7vA/yvtDpve4XjkT42e1ruevBv/TZYT8QMN570Tl8+uorCBX0/Q5KERERGV+STcgeBdaa2S/x+np9BngkZVGlQShzMj89/lNc8/rNNERayAvm8F8Lr+WMyYv63O9nt6/ld/f3fSnesWo5n//4hzh+/pyhDFlERETGiGQTsq8Bnwauxxtf7DHgN6kKKl2Oz53BDxZew3f23cdPjvs4C3On97vPw0882+u6RQuK+cIn1nDGKScNZZgiIiIyxiQ7MGwUb7T+W1IbTvqdOXkx95/4VTIt2O+2jUebqK0/0qNcHfZFRERkIJIdh2wR8F1gGd5YYQA45xamKK60SiYZA9h/oOdDANOLCrjnV99Th30RERFJWrLVN7fj1Y6FgfOBO/EGiR3XEiVk8+fMVDImIiIiA5JsQpbrnPsrYM65vc65G4ELUhfW6FB5sGdCNntG/yP4i4iIiMRLtlN/i5kFgJ3+6Pv7gXGfeex/K1FCVpSGSERERGQ0S7aG7IvABOAfgFPxXjL+sVQFNVrsP9DzHeizlJCJiIjIAPVbQ+YPAvtB59xXgEbg2pRHNUokek+lashERERkoPqtIXPORYBTzcyGIZ5RIxqNUpmgU79qyERERGSgku1D9hLwoJndAxyNFTrn7k9JVKNAdW097eFwl7JJEycwedLENEUkIiIio1WyCVkBUEPXJysdMG4TskRDXsyeUYQqEkVERGSgkh2pX/3GukmUkM2aruZKERERGbhkR+q/Ha9GrAvn3MeHPKJRIlH/sdkzlZCJiIjIwCXbZPl/cfM5wOVA5dCHM3okHPJCNWQiIiIyCMk2Wd4Xv2xmfwAeT0lEo4SGvBAREZGhkuzAsN0tAuYOZSCjTaIaMr02SURERAYj2T5kDXTtQ3YA+FpKIhoFWlrbqKqp71JmZsycXpimiERERGQ0S7bJMi/VgYwmBw71bK4sKswnKzMzDdGIiIjIaJdUk6WZXW5mU+KWp5rZ+1IX1siWcAyy6aE0RCIiIiJjQbJ9yL7pnDscW3DO1QPfTE1II1/CMchmqv+YiIiIDE6yCVmi7ZIdMmPM6W2UfhEREZHBSDYh22hmPzSz48xsoZn9CNiUysBGsspET1hqDDIREREZpGQTss8DbcDdwFqgGbghVUGNdPs1BpmIiIgMoWSfsjwKfD3FsYwKzjkq30owSr8SMhERERmkZJ+y/IuZTY1bzjezR1MX1sh1uOEoR5tbupRlZ2VSmD+llz1ERERE+pZsk2XIf7ISAOdcHTAuHytMNEL/zOkhAoHBvvRARERExrtks4iomXW8KsnM5tN15P5xY/9biZ6wHJe5qYiIiAyRZIeu+Feg1Mye8pfPAa7rbyczuxj4CRAEfuOc+1639T8CzvcXJwDTnHNTGcEqD2rICxERERlayXbqf8TMVuElYVuAB/GetOyVmQWBnwMXAhXABjN7yDlXFnfcf4zb/vPAygF/g2GWqMlyloa8EBERkWOQ7MvFPwl8AZiDl5CdCTwHXNDHbqcDu5xzu/1j3AVcBpT1sv1VjILR/ysPaMgLERERGVrJ9iH7AnAasNc5dz5eTVbPtruuZgPlccsVflkPZjYPWAA8kWQ8aZOwhkwJmYiIiByDZBOyFudcC4CZZTvnXgNO6GcfS1DW24MAa4B7nXORhAcyu87MNprZxqqq/vLA1AlHIhw4VNOjXAmZiIiIHItkE7IKfxyyPwJ/MbMHgcr+9gGK45bn9LHPGuAPvR3IOfdr59wq59yqoqL0JT+HqmuJRKNdyqZOzmPShNw0RSQiIiJjQbKd+i/3Z280s/XAFOCRfnbbACwyswXAfryk6++7b2RmJwD5eH3SRrREQ17MmhFKQyQiIiIyliQ77EUH59xT/W8FzrmwmX0OeBRv2IvbnHPbzOxbwEbn3EP+plcBdznnRvy4ZomHvNAYZCIiInJsBpyQDYRzbh2wrlvZN7ot35jKGIbS/gMJasimq4ZMREREjo3e9zMAiZ6wnD1TNWQiIiJybJSQDYDGIBMREZFUUEI2ABqlX0RERFJBCVmSmppbqDvc0KUsGAgwo6ggTRGJiIjIWKGELEmVCTr0Ty8qICMjpc9FiIiIyDighCxJCZ+w1JAXIiIiMgSUkCVpf8IxyNR/TERERI6dErIkJWqyVEImIiIiQ0EJWZISNVkqIRMREZGhoIQsSRryQkRERFJFCVkSnHNUHkwwKOxMJWQiIiJy7JSQJaGm7jCtrW1dyibk5jB1cl6aIhIREZGxRAlZEnp7qbiZpSEaERERGWuUkCUh4UvFNQaZiIiIDBElZElI9FLxWTNCaYhERERExiIlZElQDZmIiIikkhKyJCR8wlJjkImIiMgQUUKWhIRjkCkhExERkSGihKwfbe3tHKqu61E+a5r6kImIiMjQUELWjwOHanDOdSkrzJ9CTk52miISERGRsUYJWT/0DksRERFJNSVk/ahMmJDpCUsREREZOkrI+pFwlH7VkImIiMgQUkLWj8RjkCkhExERkaGjhKwflQdVQyYiIiKppYSsH+rULyIiIqmmhKwPRxqO0tDY1KUsMyODooL8NEUkIiIiY5ESsj4kaq6cOa2QYFCXTURERIaOMos+JHzCcqaGvBAREZGhpYSsDwnHIJuuVyaJiIjI0FJC1ofEQ16ohkxERESGVkoTMjO72MxeN7NdZvb1Xrb5oJmVmdk2M/t9KuMZqP0Hq3uU6QlLERERGWoZqTqwmQWBnwMXAhXABjN7yDlXFrfNIuCfgbOcc3VmNqKqnyrf6llDpjHIREREZKilsobsdGCXc263c64NuAu4rNs2nwJ+7pyrA3DO9cyA0iQSiVJ5SDVkIiIiknqpTMhmA+VxyxV+WbzFwGIz+5uZPW9mF6cwngGpqq0jHI50KcubNIG8SRPTFJGIiIiMVSlrsgQsQZlLcP5FwHnAHOAZMzvJOVff5UBm1wHXAcydO3foI01AI/SLiMhY1t7eTkVFBS0tLekOZUzIyclhzpw5ZGZmDmr/VCZkFUBx3PIcoDLBNs8759qBN83sdbwEbUP8Rs65XwO/Bli1alX3pC4lEg15MWu6EjIRERkbKioqyMvLY/78+ZglqkORZDnnqKmpoaKiggULFgzqGKlsstwALDKzBWaWBawBHuq2zR+B8wHMLITXhLk7hTElLXEN2Yh65kBERGTQWlpaKCwsVDI2BMyMwsLCY6ptTFlC5pwLA58DHgW2A2udc9vM7Ftm9l5/s0eBGjMrA9YDX3HO1aQqpoFIPAaZashERGTsUDI2dI71WqZ0HDLn3Drn3GLn3HHOue/4Zd9wzj3kzzvn3D8555Y5597mnLsrlfEMRMImSyVkIiIiQ6K+vp5f/OIXA97vkksuob6+vs9tvvGNb/D4448PNrS00Ej9vVCnfhERkdTpLSGLRCIJtu60bt06pk6d2uc23/rWt3jXu951TPENt1R26h+1Wlpaqak73KXMzJgxrTBNEYmIiKTGaZd8LOXn2LDutz3Kvv71r/PGG2+wYsUKMjMzmTRpEjNnzmTLli2UlZXxvve9j/LyclpaWvjCF77AddddB8D8+fPZuHEjjY2NrF69mpKSEp599llmz57Ngw8+SG5uLtdccw2XXnopV155JfPnz+djH/sYf/rTn2hvb+eee+5hyZIlVFVV8fd///fU1NRw2mmn8cgjj7Bp0yZCofS8s1o1ZAkkGhB2WiifrEE+yioiIiJdfe973+O4445jy5YtfP/73+fFF1/kO9/5DmVl3gt9brvtNjZt2sTGjRu5+eabqanp2cV8586d3HDDDWzbto2pU6dy3333JTxXKBRi8+bNXH/99fzgBz8A4KabbuKCCy5g8+bNXH755ezbty91XzYJSsgS2P+WnrAUEREZTqeffnqXISNuvvlmTj75ZM4880zKy8vZuXNnj30WLFjAihUrADj11FPZs2dPwmNfccUVPbYpLS1lzZo1AFx88cXk5+cP4bcZODVZJlB5MNEYZOmpwhQRERkPJk7sfBPOk08+yeOPP85zzz3HhAkTOO+88xIOKZGdnd0xHwwGaW5uTnjs2HbBYJBwOAx4Y4eNJKohSyDxkBeqIRMRERkqeXl5NDQ0JFx3+PBh8vPzmTBhAq+99hrPP//8kJ+/pKSEtWvXAvDYY49RV1c35OcYCNWQJVB5oGcfslkzVEMmIiJjT6IO98OhsLCQs846i5NOOonc3FymT5/ese7iiy/ml7/8JcuXL+eEE07gzDPPHPLzf/Ob3+Sqq67i7rvv5txzz2XmzJnk5eUN+XmSZSOtyq4/q1atchs3bkzpOa767L+ya09Fl7Lf/ODfOHnZopSeV0REZLhs376dpUuXpjuMtGltbSUYDJKRkcFzzz3H9ddfz5YtW47pmImuqZltcs6t6m9f1ZB145zTGGQiIiJj3L59+/jgBz9INBolKyuLW2+9Na3xKCHrpv5IA80trV3KsrOzKMyfkqaIREREZKgtWrSIl156Kd1hdFCn/m4SDXkxa3pI7/sSERGRlFFC1k2iIS9mT1dzpYiIiKSOErJuEvYfm6khL0RERCR1lJB1s/+tnmOQzVKHfhEREUkhJWTd7D/YcwwyNVmKiIik16RJkwCorKzkyiuvTLjNeeedR39DY/34xz+mqampY/mSSy6hvr5+6AIdJCVk3VQmHKVfCZmIiMhIMGvWLO69995B7989IVu3bh1Tp04ditCOiYa9iBMOhzlQ1fNt8mqyFBGRserkTf+U8nNsPfWHPcq+9rWvMW/ePD772c8CcOONN2JmPP3009TV1dHe3s63v/1tLrvssi777dmzh0svvZRXX32V5uZmrr32WsrKyli6dGmXd1lef/31bNiwgebmZq688kpuuukmbr75ZiorKzn//PMJhUKsX7+e+fPns3HjRkKhED/84Q+57bbbAPjkJz/JF7/4Rfbs2cPq1aspKSnh2WefZfbs2Tz44IPk5uYO6TVSDVmcA1W1RKNd31yQPyWPCbk5aYpIRERkbFqzZg133313x/LatWu59tpreeCBB9i8eTPr16/nS1/6Up8vAb/llluYMGECL7/8Mv/6r//Kpk2bOtZ95zvfYePGjbz88ss89dRTvPzyy/zDP/wDs2bNYv369axfv77LsTZt2sTtt9/OCy+8wPPPP8+tt97aMU7Zzp07ueGGG9i2bRtTp07lvvvuG+KroYSsi8Qj9OsJSxERkaG2cuVKDh06RGVlJVu3biU/P5+ZM2fyL//yLyxfvpx3vetd7N+/n4MHD/Z6jKeffpqrr74agOXLl7N8+fKOdWvXruWUU05h5cqVbNu2jbKysj7jKS0t5fLLL2fixIlMmjSJK664gmeeeQaABQsWsGLFCgBOPfVU9uzZc4zfvic1WcZJNAaZXiouIiKSGldeeSX33nsvBw4cYM2aNfzud7+jqqqKTZs2kZmZyfz582lpaenzGIkGbn/zzTf5wQ9+wIYNG8jPz+eaa67p9zh91cRlZ2d3zAeDwS5No0NFNWRxEg15oRoyERGR1FizZg133XUX9957L1deeSWHDx9m2rRpZGZmsn79evbu3dvn/ueccw6/+93vAHj11Vd5+eWXAThy5AgTJ05kypQpHDx4kIcffrhjn7y8PBoaGhIe649//CNNTU0cPXqUBx54gLPPPnsIv23fVEMWJ1GT5azpqiETEZGxK1GH++Fy4okn0tDQwOzZs5k5cyYf/vCH+bu/+ztWrVrFihUrWLJkSZ/7X3/99Vx77bUsX76cFStWcPrppwNw8skns3LlSk488UQWLlzIWWed1bHPddddx+rVq5k5c2aXfmSnnHIK11xzTccxPvnJT7Jy5cqUNE8mYn1V0Y1Eq1atcv2NMTJYH/vijZTteLNL2S/+82uctmJZSs4nIiKSLtu3b2fp0qXpDmNMSXRNzWyTc25Vf/uqyTJO4tcmacgLERERSS0lZL7GpmYOH2nsUhYMBJgWKkhTRCIiIjJeKCHzvZXgCcsZ0wrJCAbTEI2IiIiMJ+rU71u0YC5/vfsXVB6sYv+BKioPVJGRocsjIiJjl3Mu4bARMnDH2idfGUecyXkTmZw3kSXHz093KCIiIimVk5NDTU0NhYWFSsqOkXOOmpoacnIG/2YfJWQiIiLj0Jw5c6ioqKCqqmeXHRm4nJwc5syZM+j9lZCJiIiMQ5mZmSxYsCDdYYhPnfpFRERE0kwJmYiIiEiaKSETERERSbNR9+okM6sC+n7baE8hoDoF4Ywmuga6BqBrALoGoGsAugagawDDcw3mOef6fe3PqEvIBsPMNibzHqmxTNdA1wB0DUDXAHQNQNcAdA1gZF0DNVmKiIiIpJkSMhEREZE0Gy8J2a/THcAIoGugawC6BqBrALoGoGsAugYwgq7BuOhDJiIiIjKSjZcaMhEREZERa0wnZGZ2sZm9bma7zOzr6Y4nHcxsj5m9YmZbzGxjuuMZDmZ2m5kdMrNX48oKzOwvZrbTn+anM8ZU6+Ua3Ghm+/17YYuZXZLOGFPNzIrNbL2ZbTezbWb2Bb983NwLfVyDcXMvmFmOmb1oZlv9a3CTX77AzF7w74O7zSwr3bGmSh/X4A4zezPuPliR7lhTzcyCZvaSmf2fvzxi7oMxm5CZWRD4ObAaWAZcZWbL0htV2pzvnFsxUh7tHQZ3ABd3K/s68Ffn3CLgr/7yWHYHPa8BwI/8e2GFc27dMMc03MLAl5xzS4EzgRv8fwPG073Q2zWA8XMvtAIXOOdOBlYAF5vZmcD/h3cNFgF1wCfSGGOq9XYNAL4Sdx9sSV+Iw+YLwPa45RFzH4zZhAw4HdjlnNvtnGsD7gIuS3NMMgycc08Dtd2KLwN+68//FnjfsAY1zHq5BuOKc+4t59xmf74B7x/h2Yyje6GPazBuOE+jv5jpfxxwAXCvXz7W74PersG4YmZzgPcAv/GXjRF0H4zlhGw2UB63XME4+4fI54DHzGyTmV2X7mDSaLpz7i3wfqSAaWmOJ10+Z2Yv+02aY7aprjszmw+sBF5gnN4L3a4BjKN7wW+m2gIcAv4CvAHUO+fC/iZj/veh+zVwzsXug+/498GPzCw7jSEOhx8DXwWi/nIhI+g+GMsJmSUoG3f/RQCc5Zw7Ba/p9gYzOyfdAUna3AIch9dk8RbwX+kNZ3iY2STgPuCLzrkj6Y4nHRJcg3F1LzjnIs65FcAcvNaTpYk2G96ohlf3a2BmJwH/DCwBTgMKgK+lMcSUMrNLgUPOuU3xxQk2Tdt9MJYTsgqgOG55DlCZpljSxjlX6U8PAQ/g/WM0Hh00s5kA/vRQmuMZds65g/4/ylHgVsbBvWBmmXiJyO+cc/f7xePqXkh0DcbjvQDgnKsHnsTrTzfVzDL8VePm9yHuGlzsN2k751wrcDtj+z44C3ivme3B68J0AV6N2Yi5D8ZyQrYBWOQ/QZEFrAEeSnNMw8rMJppZXmweuAh4te+9xqyHgI/58x8DHkxjLGkRS0J8lzPG7wW/f8h/A9udcz+MWzVu7oXersF4uhfMrMjMpvrzucC78PrSrQeu9Dcb6/dBomvwWtx/mBhe36kxex845/7ZOTfHOTcfLx94wjn3YUbQfTCmB4b1H+X+MRAEbnPOfSfNIQ0rM1uIVysGkAH8fjxcAzP7A3AeEAIOAt8E/gisBeYC+4APOOfGbKf3Xq7BeXhNVA7YA3w61pdqLDKzEuAZ4BU6+4z8C14fqnFxL/RxDa5inNwLZrYcr7N2EK8SYq1z7lv+v4934TXVvQRc7dcUjTl9XIMngCK8prstwGfiOv+PWWZ2HvBl59ylI+k+GNMJmYiIiMhoMJabLEVERERGBSVkIiIiImmmhExEREQkzZSQiYiIiKSZEjIRERGRNFNCJiKjmpl918zOM7P3mVlaXhRuZk+a2ap0nFtExgYlZCIy2p2BN7bYuXhjbomIjDpKyERkVDKz75vZy3jv4XsO+CRwi5l9I8G2RWZ2n5lt8D9n+eU3mtn/mNkTZrbTzD7ll5t//FfN7BUz+1Dcsb7ql201s+/FneYDZvaime0ws7NT+uVFZMzJ6H8TEZGRxzn3FTO7B/gI8E/Ak865s3rZ/CfAj5xzpWY2F3iUzhdML8d7t+FE4CUz+zPwdryR7E/Ge9vBBjN72i97H3CGc67JzArizpHhnDvdf0PIN/FeTyMikhQlZCIymq3Ee+XLEqCsj+3eBSzzXtkHwOTYe16BB51zzUCzma3He8FyCfAH51wE72XkT+HVxJ0L3O6cawLo9sql2MvLNwHzj/WLicj4ooRMREYdM1sB3AHMAaqBCV6xbQHe7idY8QKJyv0Erfv74xzeu/0SnjrB9jGx999F0L+tIjJA6kMmIqOOc26Lc24FsANYBjwBvNs5tyJBMgbwGPC52IKf0MVcZmY5ZlaI9wL2DcDTwIfMLGhmRcA5wIv+cT5uZhP848Q3WYqIDJoSMhEZlfxEqc45FwWWOOf6arL8B2CVmb1sZmXAZ+LWvQj8GXge+A/nXCXwAPAysBUv2fuqc+6Ac+4R4CFgo18b9+Uh/2IiMi6Zc73VvouIjG1mdiPQ6Jz7QbpjEZHxTTVkIiIiImmmGjIRERGRNFMNmYiIiEiaKSETERERSTMlZCIiIiJppoRMREREJM2UkImIiIikmRIyERERkTT7/wHnsahxG1fZaQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 720x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_model_performance(\n",
    "    train_loss=model_hist.history.get('loss', []),\n",
    "    train_acc=model_hist.history.get('acc', []),\n",
    "    train_val_loss=model_hist.history.get('val_loss', []),\n",
    "    train_val_acc=model_hist.history.get('val_acc', [])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pqiuy8q4GYjF"
   },
   "source": [
    "### Función que Permite convertir Indices en Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YJ6GaLot9yZR"
   },
   "outputs": [],
   "source": [
    "def logits_to_tokens(sequences, index):\n",
    "    token_sequences = []\n",
    "    for categorical_sequence in sequences:\n",
    "        token_sequence = []\n",
    "        for categorical in categorical_sequence:\n",
    "            token_sequence.append(index[np.argmax(categorical)])\n",
    " \n",
    "        token_sequences.append(token_sequence)\n",
    " \n",
    "    return token_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "W-1GH3ZYuLc-"
   },
   "source": [
    "### Hacemos la prediccion sobre el conjunto de pruebas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "6HgbDqqsR4a7",
    "outputId": "8ad10360-dafc-4a75-eeda-b4ed4c5c4e34"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['da0ms0', 'ncms000', 'aq0cs0', 'vaip3s0', 'vmp00sm', 'cs', 'da0fs0', 'ncfs000', 'sps00', 'ncms000', 'vaip3s0', 'vmp00sm', 'sps00', 'Fe', 'vmn0000', 'Fe', 'Fc', 'cc', 'sn.e-SUJ', 'vaip3s0', 'vmp00sm', 'cs', 'da0ms0', 'ncms000', 'sps00', 'da0ms0', 'ncms000', 'vmip3s0', 'cs', 'sps00', 'da0ms0', 'np0000l', 'Fe', 'pi0mp000', 'vmip3p0', 'sps00', 'da0fs0', 'di0fs0', 'ncfs000', 'Fe', 'Fp', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "prediction = model.predict(test_sentences_X)\n",
    "log_tokens = logits_to_tokens(prediction, {i: t for t, i in tag2index.items()})\n",
    "\n",
    "print(log_tokens[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uT6IIQXrQuix"
   },
   "source": [
    "### Hallamos los valores de F1 score, recall, precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1142
    },
    "colab_type": "code",
    "id": "GqTuNxppFNu-",
    "outputId": "cc280315-02e5-4be6-d4b3-eccfae561837"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/deep-learning/miniconda3/envs/tensorflow/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/deep-learning/miniconda3/envs/tensorflow/lib/python3.6/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "classification_report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       -PAD-       0.00      0.00      0.00         0\n",
      "         Faa       1.00      1.00      1.00         2\n",
      "         Fat       1.00      1.00      1.00         5\n",
      "          Fc       1.00      1.00      1.00      2291\n",
      "          Fd       1.00      1.00      1.00        87\n",
      "          Fe       1.00      1.00      1.00       631\n",
      "          Fg       1.00      1.00      1.00       226\n",
      "          Fh       0.00      0.00      0.00         3\n",
      "         Fia       1.00      1.00      1.00         6\n",
      "         Fit       1.00      1.00      1.00        19\n",
      "          Fp       1.00      1.00      1.00      1178\n",
      "         Fpa       1.00      1.00      1.00       156\n",
      "         Fpt       1.00      1.00      1.00       160\n",
      "          Fs       1.00      1.00      1.00        13\n",
      "          Fx       1.00      1.00      1.00        41\n",
      "          Fz       0.00      0.00      0.00         2\n",
      "           W       0.99      0.61      0.75       194\n",
      "           Z       0.96      0.62      0.76       320\n",
      "          Zm       0.94      0.94      0.94        35\n",
      "          Zp       0.94      0.38      0.54        45\n",
      "      ao0fp0       1.00      1.00      1.00        17\n",
      "      ao0fs0       0.97      0.95      0.96        66\n",
      "      ao0mp0       1.00      0.91      0.95        23\n",
      "      ao0ms0       0.95      0.93      0.94        59\n",
      "     aq00000       0.00      0.00      0.00         2\n",
      "      aq0cn0       0.14      0.25      0.18         4\n",
      "      aq0cp0       0.95      0.72      0.82       228\n",
      "      aq0cs0       0.92      0.83      0.87       590\n",
      "      aq0fp0       0.60      0.80      0.68       128\n",
      "      aq0fpp       0.43      0.42      0.43        52\n",
      "      aq0fs0       0.73      0.82      0.77       355\n",
      "      aq0fsp       0.66      0.49      0.56       140\n",
      "      aq0mp0       0.54      0.70      0.61       202\n",
      "      aq0mpp       0.37      0.59      0.46        96\n",
      "      aq0ms0       0.64      0.81      0.71       491\n",
      "      aq0msp       0.72      0.66      0.69       222\n",
      "          cc       0.98      0.99      0.99      1222\n",
      "          cs       0.93      0.90      0.92       927\n",
      "      da0fp0       0.98      1.00      0.99       374\n",
      "      da0fs0       0.99      1.00      0.99      1324\n",
      "      da0mp0       0.99      1.00      1.00       637\n",
      "      da0ms0       1.00      1.00      1.00      1275\n",
      "      da0ns0       0.92      0.98      0.95       110\n",
      "      dd0cp0       1.00      0.50      0.67         2\n",
      "      dd0cs0       1.00      0.75      0.86         4\n",
      "      dd0fp0       0.86      1.00      0.92        18\n",
      "      dd0fs0       0.96      1.00      0.98        67\n",
      "      dd0mp0       0.86      1.00      0.92        30\n",
      "      dd0ms0       0.92      1.00      0.96       101\n",
      "      di0cp0       1.00      0.40      0.57         5\n",
      "      di0cs0       1.00      0.88      0.94        26\n",
      "      di0fp0       0.93      0.97      0.95        71\n",
      "      di0fs0       0.97      0.99      0.98       335\n",
      "      di0mp0       0.90      0.97      0.94       112\n",
      "      di0ms0       0.98      0.95      0.97       482\n",
      "      dn0cp0       0.94      0.98      0.96       149\n",
      "      dn0cs0       0.00      0.00      0.00         1\n",
      "      dn0fp0       1.00      1.00      1.00         4\n",
      "      dn0fs0       0.00      0.00      0.00         2\n",
      "      dn0mp0       0.75      0.60      0.67         5\n",
      "      dn0ms0       0.00      0.00      0.00         9\n",
      "      dp1cps       1.00      1.00      1.00         1\n",
      "      dp1css       1.00      1.00      1.00         8\n",
      "      dp1fpp       1.00      1.00      1.00         1\n",
      "      dp1fsp       1.00      1.00      1.00         6\n",
      "      dp1mpp       1.00      0.86      0.92         7\n",
      "      dp1msp       1.00      1.00      1.00         8\n",
      "      dp2css       1.00      0.67      0.80         3\n",
      "      dp3cp0       1.00      1.00      1.00       107\n",
      "      dp3cs0       1.00      1.00      1.00       275\n",
      "      dp3fs0       0.00      0.00      0.00         1\n",
      "      dt0cn0       0.00      0.00      0.00         3\n",
      "           i       0.09      0.25      0.13         4\n",
      "     nc00000       0.06      0.27      0.10        26\n",
      "     nccn000       0.00      0.00      0.00         5\n",
      "     nccp000       0.92      0.85      0.88       103\n",
      "     nccs000       0.89      0.68      0.77       146\n",
      "     ncfn000       1.00      0.67      0.80        15\n",
      "     ncfp000       0.93      0.87      0.90       788\n",
      "     ncfs000       0.91      0.93      0.92      2132\n",
      "     ncmn000       0.93      0.54      0.68        24\n",
      "     ncmp000       0.91      0.87      0.89      1166\n",
      "     ncms000       0.79      0.95      0.86      2365\n",
      "     np00000       0.30      0.12      0.17        51\n",
      "     np0000a       0.84      0.33      0.48       202\n",
      "     np0000l       0.57      0.73      0.64       412\n",
      "     np0000o       0.79      0.59      0.68       656\n",
      "     np0000p       0.74      0.69      0.71       720\n",
      "    p0000000       0.69      0.53      0.60       193\n",
      "    p010p000       0.00      0.00      0.00         2\n",
      "    p010s000       0.00      0.00      0.00         3\n",
      "    p020s000       0.00      0.00      0.00         1\n",
      "    p0300000       0.64      0.81      0.71       217\n",
      "    pd0fp000       0.00      0.00      0.00         3\n",
      "    pd0fs000       0.60      0.60      0.60         5\n",
      "    pd0mp000       1.00      0.17      0.29         6\n",
      "    pd0ms000       1.00      0.50      0.67         8\n",
      "    pd0ns000       1.00      1.00      1.00        22\n",
      "    pi0cp000       0.67      1.00      0.80         2\n",
      "    pi0cs000       0.97      0.97      0.97        40\n",
      "    pi0fp000       0.50      0.14      0.22         7\n",
      "    pi0fs000       0.60      0.55      0.57        11\n",
      "    pi0mp000       0.89      0.71      0.79        35\n",
      "    pi0ms000       0.85      0.87      0.86        54\n",
      "    pn0cp000       0.84      0.78      0.81        27\n",
      "    pn0fp000       0.00      0.00      0.00         0\n",
      "    pn0mp000       0.67      0.67      0.67         3\n",
      "    pn0ms000       0.00      0.00      0.00         2\n",
      "    pp1cp000       0.93      1.00      0.96        27\n",
      "    pp1cs000       0.90      0.96      0.93        27\n",
      "    pp1csn00       1.00      1.00      1.00        16\n",
      "    pp1cso00       1.00      1.00      1.00         5\n",
      "    pp1mp000       1.00      1.00      1.00         9\n",
      "    pp2cs000       0.80      1.00      0.89         4\n",
      "    pp2cs00p       1.00      0.75      0.86         4\n",
      "    pp2csn00       0.00      0.00      0.00         2\n",
      "    pp2cso00       0.00      0.00      0.00         1\n",
      "    pp3cn000       0.00      0.00      0.00        10\n",
      "    pp3cna00       0.00      0.00      0.00         2\n",
      "    pp3cno00       1.00      1.00      1.00         5\n",
      "    pp3cpa00       0.00      0.00      0.00         2\n",
      "    pp3cpd00       0.85      1.00      0.92        11\n",
      "    pp3csa00       0.00      0.00      0.00         1\n",
      "    pp3csd00       0.98      0.98      0.98        63\n",
      "    pp3fp000       0.86      1.00      0.92         6\n",
      "    pp3fpa00       1.00      0.20      0.33        10\n",
      "    pp3fs000       1.00      1.00      1.00        13\n",
      "    pp3fsa00       1.00      0.06      0.11        17\n",
      "    pp3mp000       1.00      1.00      1.00        26\n",
      "    pp3mpa00       0.00      0.00      0.00         4\n",
      "    pp3ms000       1.00      1.00      1.00        23\n",
      "    pp3msa00       0.89      0.73      0.80        33\n",
      "    pp3ns000       1.00      1.00      1.00        15\n",
      "    pr000000       0.95      0.77      0.85        26\n",
      "    pr0cn000       0.89      0.93      0.91       616\n",
      "    pr0cp000       1.00      1.00      1.00        10\n",
      "    pr0cs000       0.94      1.00      0.97        32\n",
      "    pr0fp000       1.00      1.00      1.00         1\n",
      "    pr0fs000       1.00      1.00      1.00         5\n",
      "    pr0ms000       0.00      0.00      0.00         3\n",
      "    pt000000       1.00      1.00      1.00        12\n",
      "    pt0cp000       0.00      0.00      0.00         1\n",
      "    pt0cs000       0.85      0.94      0.89        18\n",
      "    pt0mp000       0.00      0.00      0.00         2\n",
      "    px1fs0p0       1.00      1.00      1.00         1\n",
      "    px3ns000       0.00      0.00      0.00         1\n",
      "          rg       0.95      0.89      0.92      1208\n",
      "          rn       0.97      0.99      0.98       265\n",
      "      sn-SUJ       0.00      0.00      0.00         1\n",
      "        sn.e       0.00      0.00      0.00         4\n",
      "    sn.e-SUJ       0.99      1.00      0.99       818\n",
      " sn.e.1n-SUJ       0.00      0.00      0.00         6\n",
      "       spcms       1.00      0.99      0.99       692\n",
      "       sps00       1.00      0.99      1.00      5056\n",
      "     vaic3p0       0.00      0.00      0.00         1\n",
      "     vaic3s0       1.00      1.00      1.00         4\n",
      "     vaif1p0       0.00      0.00      0.00         1\n",
      "     vaif3s0       1.00      1.00      1.00         3\n",
      "     vaii1s0       0.00      0.00      0.00         1\n",
      "     vaii3p0       1.00      1.00      1.00        13\n",
      "     vaii3s0       0.95      1.00      0.98        41\n",
      "     vaip1p0       1.00      1.00      1.00         8\n",
      "     vaip1s0       1.00      1.00      1.00         9\n",
      "     vaip3p0       1.00      1.00      1.00        48\n",
      "     vaip3s0       1.00      0.99      1.00       185\n",
      "     vais3s0       1.00      0.60      0.75         5\n",
      "     van0000       0.91      1.00      0.95        21\n",
      "     vap00sm       1.00      1.00      1.00         1\n",
      "     vasi1p0       0.00      0.00      0.00         1\n",
      "     vasi3p0       1.00      1.00      1.00         2\n",
      "     vasi3s0       0.92      1.00      0.96        11\n",
      "     vasp1s0       0.00      0.00      0.00         1\n",
      "     vasp3p0       1.00      1.00      1.00         1\n",
      "     vasp3s0       0.89      1.00      0.94         8\n",
      "     vmg0000       0.52      0.45      0.48        92\n",
      "     vmic1p0       0.00      0.00      0.00         2\n",
      "     vmic3p0       1.00      0.55      0.71        11\n",
      "     vmic3s0       1.00      0.70      0.82        30\n",
      "     vmif1p0       0.00      0.00      0.00         7\n",
      "     vmif1s0       1.00      0.33      0.50         3\n",
      "     vmif2s0       0.00      0.00      0.00         1\n",
      "     vmif3p0       1.00      0.55      0.71        40\n",
      "     vmif3s0       0.92      0.59      0.72       114\n",
      "     vmii1p0       0.40      0.22      0.29         9\n",
      "     vmii1s0       0.00      0.00      0.00         7\n",
      "     vmii3p0       0.51      0.42      0.46        67\n",
      "     vmii3s0       0.82      0.65      0.72       143\n",
      "     vmip1p0       0.87      0.68      0.77        60\n",
      "     vmip1s0       0.82      0.77      0.79        60\n",
      "     vmip2s0       0.60      0.50      0.55         6\n",
      "     vmip3p0       0.94      0.68      0.79       279\n",
      "     vmip3s0       0.93      0.89      0.91       599\n",
      "     vmis1p0       0.00      0.00      0.00         5\n",
      "     vmis1s0       0.08      0.58      0.13        12\n",
      "     vmis3p0       0.87      0.60      0.71       148\n",
      "     vmis3s0       0.94      0.88      0.91       606\n",
      "     vmm02s0       0.00      0.00      0.00         3\n",
      "     vmm03p0       0.00      0.00      0.00         1\n",
      "     vmm03s0       0.00      0.00      0.00         7\n",
      "     vmn0000       0.80      0.88      0.84       849\n",
      "     vmp00pf       0.00      0.00      0.00         5\n",
      "     vmp00pm       0.42      0.31      0.36        16\n",
      "     vmp00sf       0.57      0.21      0.31        19\n",
      "     vmp00sm       0.89      0.92      0.91       311\n",
      "     vmsi1p0       0.00      0.00      0.00         2\n",
      "     vmsi1s0       0.00      0.00      0.00         2\n",
      "     vmsi3p0       0.06      0.08      0.07        12\n",
      "     vmsi3s0       0.40      0.38      0.39        26\n",
      "     vmsp1p0       0.07      0.11      0.09         9\n",
      "     vmsp1s0       0.50      0.14      0.22         7\n",
      "     vmsp3p0       0.38      0.40      0.39        45\n",
      "     vmsp3s0       0.25      0.65      0.36        66\n",
      "     vsg0000       1.00      1.00      1.00         7\n",
      "     vsic1s0       0.00      0.00      0.00         1\n",
      "     vsic3p0       0.00      0.00      0.00         2\n",
      "     vsic3s0       0.89      1.00      0.94         8\n",
      "     vsif3s0       1.00      1.00      1.00        13\n",
      "     vsii3p0       1.00      1.00      1.00        13\n",
      "     vsii3s0       0.90      1.00      0.95        26\n",
      "     vsip1p0       1.00      1.00      1.00         1\n",
      "     vsip1s0       1.00      1.00      1.00         3\n",
      "     vsip2s0       0.00      0.00      0.00         2\n",
      "     vsip3p0       1.00      1.00      1.00        48\n",
      "     vsip3s0       1.00      1.00      1.00       190\n",
      "     vsis3p0       0.95      1.00      0.97        18\n",
      "     vsis3s0       1.00      1.00      1.00        39\n",
      "     vsn0000       0.97      1.00      0.99        35\n",
      "     vsp00sm       1.00      1.00      1.00        32\n",
      "     vssi3p0       0.00      0.00      0.00         1\n",
      "     vssi3s0       1.00      1.00      1.00         3\n",
      "     vssp3p0       1.00      0.80      0.89         5\n",
      "     vssp3s0       1.00      1.00      1.00        12\n",
      "\n",
      "   micro avg       0.90      0.90      0.90     38876\n",
      "   macro avg       0.68      0.63      0.64     38876\n",
      "weighted avg       0.91      0.90      0.90     38876\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "results = pd.DataFrame(columns=['Expected', 'Predicted'])\n",
    "k = 0\n",
    "for i, lista_etiquetas_oracion in enumerate(test_tags):\n",
    "    for j, etiquetas in enumerate(lista_etiquetas_oracion):\n",
    "        k = k + 1\n",
    "        results.loc[k, 'Expected'] = etiquetas\n",
    "        results.loc[k, 'Predicted'] = log_tokens[i][j]\n",
    "\n",
    "# print(results)\n",
    "\n",
    "\n",
    "print('\\nclassification_report:\\n', classification_report(results['Expected'], results['Predicted']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nrAAFx0XrWT1"
   },
   "source": [
    "## PARTE 4  -  Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uvOz-IShFzRR"
   },
   "source": [
    "### Creamos un pequeño Ejemplo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_WT1PtS_Qui0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Correr', 'es', 'importante', 'para', 'mi', '.'], ['El', 'hombre', 'bajo', 'corre', 'bajo', 'el', 'puente', 'con', 'bajo', 'índice', 'de', 'adrenalina', '.']]\n"
     ]
    }
   ],
   "source": [
    "test_samples = [\n",
    "    \"Correr es importante para mi .\".split(),\n",
    "    \"El hombre bajo corre bajo el puente con bajo índice de adrenalina .\".split()\n",
    "]\n",
    "print(test_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "X5E7-zZdGCjY"
   },
   "source": [
    "### Convertimos el texto en Una entrada para el Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BApB6ScZ9jU8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 7941   617 21602  2220 20222  8877     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0]\n",
      " [23901 16877 23244  5286 23244 23901 19857  2125 23244 17720  4735     1\n",
      "   8877     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0]]\n"
     ]
    }
   ],
   "source": [
    "test_samples_X = []\n",
    "for s in test_samples:\n",
    "    s_int = []\n",
    "    for w in s:\n",
    "        try:\n",
    "            s_int.append(word2index[w.lower()])\n",
    "        except KeyError:\n",
    "            s_int.append(word2index['-OOV-'])\n",
    "    test_samples_X.append(s_int)\n",
    "\n",
    "test_samples_X = pad_sequences(test_samples_X, maxlen=MAX_LENGTH, padding='post')\n",
    "print(test_samples_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "trNZCjTWGLp-"
   },
   "source": [
    "### Se Ejecuta la predicion con la Entrada del modelo entrenado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OX6Bd2Rz9oha"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[5.9572947e-03 3.2702534e-04 5.6603662e-04 ... 1.6515359e-03\n",
      "   5.1788881e-04 5.0997027e-05]\n",
      "  [3.5487523e-04 5.9204336e-05 2.4830436e-04 ... 3.6646071e-04\n",
      "   1.0035676e-04 1.4941623e-04]\n",
      "  [1.4444198e-04 3.0377274e-05 4.3721877e-05 ... 1.4524778e-05\n",
      "   3.0109790e-05 3.4003365e-06]\n",
      "  ...\n",
      "  [9.9998188e-01 1.3932119e-07 1.1467339e-08 ... 1.3632433e-08\n",
      "   7.4429245e-08 3.2310892e-09]\n",
      "  [9.9997115e-01 2.5822567e-07 2.2973538e-08 ... 2.2812722e-08\n",
      "   1.3430355e-07 6.6483965e-09]\n",
      "  [9.9995363e-01 4.6912484e-07 4.6259956e-08 ... 3.6808217e-08\n",
      "   2.3453256e-07 1.3701961e-08]]\n",
      "\n",
      " [[2.3739225e-04 1.4915314e-05 4.4271201e-05 ... 5.3221334e-05\n",
      "   2.6989554e-05 3.6569767e-05]\n",
      "  [5.7456741e-04 4.4412151e-05 4.5734279e-05 ... 1.0499076e-04\n",
      "   6.1320454e-05 3.8390048e-05]\n",
      "  [1.6579446e-03 9.7062271e-05 1.8817073e-04 ... 3.5916226e-05\n",
      "   1.5669098e-04 2.1783504e-05]\n",
      "  ...\n",
      "  [9.9998188e-01 1.3919173e-07 1.1485069e-08 ... 1.3633681e-08\n",
      "   7.4354610e-08 3.2281018e-09]\n",
      "  [9.9997115e-01 2.5798838e-07 2.3009147e-08 ... 2.2814243e-08\n",
      "   1.3416671e-07 6.6424648e-09]\n",
      "  [9.9995363e-01 4.6870224e-07 4.6332186e-08 ... 3.6809972e-08\n",
      "   2.3429067e-07 1.3690180e-08]]] (2, 149, 291)\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(test_samples_X)\n",
    "print(predictions, predictions.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "l-XS5z-NGiM-"
   },
   "source": [
    "### Conversion de la Salida del Modelo a un lista de Indices de Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IgIutMjq92cp"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['vmn0000', 'vsip3s0', 'aq0cs0', 'sps00', 'dp1css', 'Fp', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-'], ['da0ms0', 'ncms000', 'sps00', 'vmip3s0', 'sps00', 'da0ms0', 'ncms000', 'sps00', 'sps00', 'ncms000', 'sps00', 'np0000l', 'Fp', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-']]\n"
     ]
    }
   ],
   "source": [
    "#print(len(predictions))\n",
    "log_tokens = logits_to_tokens(predictions, {i: t for t, i in tag2index.items()})\n",
    "print(log_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VmWp09kyGrQC"
   },
   "source": [
    "### Presentacion de los Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wNMCM8_jSdCL"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correr    es       importante    para    mi      .\n",
      "--------  -------  ------------  ------  ------  ---\n",
      "vmn0000   vsip3s0  aq0cs0        sps00   dp1css  Fp\n",
      "\n",
      "\n",
      "El      hombre    bajo    corre    bajo    el      puente    con    bajo    índice    de     adrenalina    .\n",
      "------  --------  ------  -------  ------  ------  --------  -----  ------  --------  -----  ------------  ---\n",
      "da0ms0  ncms000   sps00   vmip3s0  sps00   da0ms0  ncms000   sps00  sps00   ncms000   sps00  np0000l       Fp\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n## postagging Freeling 4.1\\n\\nEl      hombre   bajo     corre    bajo  el      puente   con  bajo  índice   de  adrenalina  .\\nDA0MS0  NCMS000  AQ0MS00  VMIP3S0  SP    DA0MS0  NCMS000  SP   SP    NCMS000  SP  NCFS000     Fp\\n\\n\\n## pos tagger Stanford NLP\\n\\nEl      hombre   bajo     corre    bajo  el      puente   con    bajo   índice  de    adrenalina  .\\nda0000  nc0s000  aq0000   vmip000  sp000 da0000  nc0s000  sp000  aq0000 nc0s000 sp000 nc0s000     fp\\nRub1k0n$$\\n\\n'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!pip install tabulate\n",
    "from tabulate import tabulate\n",
    "\n",
    "heads1 = test_samples[0]\n",
    "body1 = [log_tokens[0][:len(test_samples[0])]]\n",
    "\n",
    "heads2 = test_samples[1]\n",
    "body2 = [log_tokens[1][:len(test_samples[1])]]\n",
    "\n",
    "print(tabulate(body1, headers=heads1))\n",
    "\n",
    "print (\"\\n\")\n",
    "\n",
    "print(tabulate(body2, headers=heads2))\n",
    "\n",
    "'''\n",
    "## postagging Freeling 4.1\n",
    "\n",
    "El      hombre   bajo     corre    bajo  el      puente   con  bajo  índice   de  adrenalina  .\n",
    "DA0MS0  NCMS000  AQ0MS00  VMIP3S0  SP    DA0MS0  NCMS000  SP   SP    NCMS000  SP  NCFS000     Fp\n",
    "\n",
    "\n",
    "## pos tagger Stanford NLP\n",
    "\n",
    "El      hombre   bajo     corre    bajo  el      puente   con    bajo   índice  de    adrenalina  .\n",
    "da0000  nc0s000  aq0000   vmip000  sp000 da0000  nc0s000  sp000  aq0000 nc0s000 sp000 nc0s000     fp\n",
    "Rub1k0n$$\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zEqVaw-HSPiu"
   },
   "source": [
    "## PARTE 5  -  Mejorando la Precision y Exactitud del Modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1gR8kcV0GwFS"
   },
   "source": [
    "### Definimos una clase que permita ignorar los Valores de Relleno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QwNvdZiE956Y"
   },
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    " \n",
    "def ignore_class_accuracy(to_ignore=0):\n",
    "    def ignore_accuracy(y_true, y_pred):\n",
    "        y_true_class = K.argmax(y_true, axis=-1)\n",
    "        y_pred_class = K.argmax(y_pred, axis=-1)\n",
    " \n",
    "        ignore_mask = K.cast(K.not_equal(y_pred_class, to_ignore), 'int32')\n",
    "        matches = K.cast(K.equal(y_true_class, y_pred_class), 'int32') * ignore_mask\n",
    "        accuracy = K.sum(matches) / K.maximum(K.sum(ignore_mask), 1)\n",
    "        return accuracy\n",
    "    return ignore_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AxT3F3pHIGHk"
   },
   "source": [
    "### Definimos nuevamente nuestro modelo, agregado la clase Creada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KO4DTAAE-BaS"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, InputLayer, Bidirectional, TimeDistributed, Embedding, Activation\n",
    "from keras.optimizers import Adam\n",
    " \n",
    "\n",
    "model = Sequential()\n",
    "model.add(InputLayer(input_shape=(MAX_LENGTH, )))\n",
    "model.add(Embedding(len(word2index), 128))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Bidirectional(LSTM(256, return_sequences=True)))\n",
    "model.add(TimeDistributed(Dense(len(tag2index))))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Activation('softmax'))\n",
    " \n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(0.001),  metrics=['accuracy', ignore_class_accuracy(0)]) \n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Z8AiPXp8IVOu"
   },
   "source": [
    "### Procedemos a Entrenar Nuevamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CwgZVEIW-ECo"
   },
   "outputs": [],
   "source": [
    "model.fit(train_sentences_X, to_categorical(train_tags_y, len(tag2index)), batch_size=128, epochs=40, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LnExWbEmIa5U"
   },
   "source": [
    "### Calculamos nuevamente la Precisión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FKOa73gRNMm7"
   },
   "outputs": [],
   "source": [
    "scores2 = model.evaluate(test_sentences_X, to_categorical(test_tags_y, len(tag2index)))\n",
    "print(f\"{model.metrics_names[1]}: {scores2[1] * 100}\")   # acc: 99.09751977804825"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZzeCdasrIkuN"
   },
   "source": [
    "### Relaizamos nuevamente el calculo de F1-score, recall, y precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VbqNJa0pIvVT"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Nri9gFnwIxcN"
   },
   "source": [
    "### Realizamos nuevamente una prueba con el Ejemplo de Prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xruHro6L-LT2"
   },
   "outputs": [],
   "source": [
    "predictions1 = model.predict(test_samples_X)\n",
    "log_tokens1  = logits_to_tokens(predictions1, {i: t for t, i in tag2index.items()})\n",
    "print(log_tokens1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VL9taLbrI641"
   },
   "source": [
    "### Presentamos los Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QeRx8eSThbuq"
   },
   "outputs": [],
   "source": [
    "from tabulate import tabulate\n",
    "\n",
    "heads1 = test_samples[0]\n",
    "body1 = [log_tokens[0][:len(test_samples[0])]]\n",
    "\n",
    "heads2 = test_samples[1]\n",
    "body2 = [log_tokens[1][:len(test_samples[1])]]\n",
    "\n",
    "print(tabulate(body1, headers=heads1))\n",
    "\n",
    "print (\"\\n\")\n",
    "\n",
    "print(tabulate(body2, headers=heads2))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Preprocesamiento-Copy1.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
