{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mb-01.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "colab_type": "text",
        "id": "3nXS4RUQQugV"
      },
      "cell_type": "markdown",
      "source": [
        "# Tutorial Part-of-Speech tagging  Con Deep Learning\n",
        "\n",
        "### mb-01 Variacion en la estructura de la linea base del modelo Neuronal"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "WIheRrq2Quga"
      },
      "cell_type": "markdown",
      "source": [
        "## PARTE 1  -  Pre-Procesamiento"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "lw10qukzQuge",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Asegurar reproducibilidad\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "CUSTOM_SEED = 42\n",
        "np.random.seed(CUSTOM_SEED)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "CxOcxDUmJcvL"
      },
      "cell_type": "markdown",
      "source": [
        "### Descargamos el Corpus Ancora - Cess_esp del nltk"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "NILevBJxQugr",
        "outputId": "ef4757de-b7ff-41a1-fb4f-cba3006098ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('cess_esp')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package cess_esp to /root/nltk_data...\n",
            "[nltk_data]   Package cess_esp is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "eqdUvUCEJjgc"
      },
      "cell_type": "markdown",
      "source": [
        "### Extraemos las oraciones tageadas del Corpus"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "ss3RHo4LQugx",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import random\n",
        "from nltk.corpus import cess_esp\n",
        "\n",
        "tagged_sentences = cess_esp.tagged_sents()\n",
        "#print('a random sentence: \\n-> {}'.format(random.choice(sentences)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "gCW_ENdLJudC"
      },
      "cell_type": "markdown",
      "source": [
        "### Extraemos los datos de la cantidad de oraciones a ser usadas y un ejemplo de una oracion presente en el corpus"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "2clQUNdtQug4",
        "outputId": "16a20aa1-0b8c-485b-d04f-e36a41be158f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "cell_type": "code",
      "source": [
        "print(tagged_sentences[0])\n",
        "print(\"Tagged sentences: \", len(tagged_sentences))\n",
        "print(\"Tagged words:\", len(cess_esp.tagged_words()))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('El', 'da0ms0'), ('grupo', 'ncms000'), ('estatal', 'aq0cs0'), ('Electricité_de_France', 'np00000'), ('-Fpa-', 'Fpa'), ('EDF', 'np00000'), ('-Fpt-', 'Fpt'), ('anunció', 'vmis3s0'), ('hoy', 'rg'), (',', 'Fc'), ('jueves', 'W'), (',', 'Fc'), ('la', 'da0fs0'), ('compra', 'ncfs000'), ('del', 'spcms'), ('51_por_ciento', 'Zp'), ('de', 'sps00'), ('la', 'da0fs0'), ('empresa', 'ncfs000'), ('mexicana', 'aq0fs0'), ('Electricidad_Águila_de_Altamira', 'np00000'), ('-Fpa-', 'Fpa'), ('EAA', 'np00000'), ('-Fpt-', 'Fpt'), (',', 'Fc'), ('creada', 'aq0fsp'), ('por', 'sps00'), ('el', 'da0ms0'), ('japonés', 'aq0ms0'), ('Mitsubishi_Corporation', 'np00000'), ('para', 'sps00'), ('poner_en_marcha', 'vmn0000'), ('una', 'di0fs0'), ('central', 'ncfs000'), ('de', 'sps00'), ('gas', 'ncms000'), ('de', 'sps00'), ('495', 'Z'), ('megavatios', 'ncmp000'), ('.', 'Fp')]\n",
            "Tagged sentences:  6030\n",
            "Tagged words: 192685\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "i_aFjuCQKG1O"
      },
      "cell_type": "markdown",
      "source": [
        "### Se procede a Dividir en una lista de Oraciones dividida en lista de palabras y cada palabra con un correspondiente tag en un alista diferente"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "516a_v5vQuhC",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        " \n",
        "sentences, tagss =[], [] \n",
        "for tagged_sentence in tagged_sentences:\n",
        "    sentence, tags = zip(*tagged_sentence)\n",
        "    sentences.append(np.array(sentence))\n",
        "    tagss.append(np.array(tags))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "UN_E4ePpKhvy"
      },
      "cell_type": "markdown",
      "source": [
        "### Imprimimos una posicion de la lista como ejemplo"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "l6uGGSqZQuhM",
        "outputId": "ce3e55e7-c2da-4629-c102-53f5f00a7092",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "cell_type": "code",
      "source": [
        "print(sentences[5])\n",
        "print(tagss[5])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['EDF' 'tiene' 'previsto' 'invertir' '194' 'millones' 'de' 'euros' '-Fpa-'\n",
            " '186' 'millones' 'de' 'dólares' '-Fpt-' 'en' 'la' 'central' 'de'\n",
            " 'Río_Bravo' ',' 'con' 'una' 'potencia' 'de' '495' 'megavatios' ',' 'y'\n",
            " '134' 'millones' 'de' 'euros' '-Fpa-' '28' 'millones' 'de' 'dólares'\n",
            " '-Fpt-' 'en' 'Saltillo' ',' 'que' 'como' 'la' 'primera' 'funcionará'\n",
            " 'con' 'gas' 'natural' 'y' 'cuya' 'potencia' 'prevista' 'es' 'de' '247'\n",
            " 'megavatios' '.']\n",
            "['np00000' 'vmip3s0' 'aq0msp' 'vmn0000' 'Z' 'ncmp000' 'sps00' 'Zm' 'Fpa'\n",
            " 'Z' 'ncmp000' 'sps00' 'Zm' 'Fpt' 'sps00' 'da0fs0' 'ncfs000' 'sps00'\n",
            " 'np00000' 'Fc' 'sps00' 'di0fs0' 'ncfs000' 'sps00' 'Z' 'ncmp000' 'Fc' 'cc'\n",
            " 'Z' 'ncmp000' 'sps00' 'Zm' 'Fpa' 'Z' 'ncmp000' 'sps00' 'Zm' 'Fpt' 'sps00'\n",
            " 'np00000' 'Fc' 'pr0cn000' 'cs' 'da0fs0' 'ao0fs0' 'vmif3s0' 'sps00'\n",
            " 'ncms000' 'aq0cs0' 'cc' 'pr0fs000' 'ncfs000' 'aq0fsp' 'vsip3s0' 'sps00'\n",
            " 'Z' 'ncmp000' 'Fp']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "WFQrAblFQuhT"
      },
      "cell_type": "markdown",
      "source": [
        "### Dividimos el corpus de la siguiente manera, Utilizamos aproximadamente el 60% de las oraciones etiquetadas para el entrenamiento, el 20% como conjunto de validación y el 20% para evaluar nuestro modelo."
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "ZtLulrEOQuhU",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        " \n",
        "(training_sentences, \n",
        " test_sentences, \n",
        " training_tags, \n",
        " test_tags) = train_test_split(sentences, tagss, test_size=0.2)\n",
        "\n",
        "(train_sentences, \n",
        " eval_sentences, \n",
        " train_tags, \n",
        " eval_tags) = train_test_split(training_sentences, training_tags, test_size=0.25)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "_Mk0scnsK1OE"
      },
      "cell_type": "markdown",
      "source": [
        "### Imprimimos los tamaños de las listas que nos indicaran el tamaño de filas de las matrices con las que estaremos trabajando"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "7HkjbP_IQuhZ",
        "outputId": "7202774e-fb62-427f-e878-52abd816ca6d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 697
        }
      },
      "cell_type": "code",
      "source": [
        "print(\"training_sentences:\" + str(len(training_sentences)))\n",
        "print(\"train_sentences: \" + str(len(train_sentences)))\n",
        "print(\"test_sentences: \" + str(len(test_sentences)))\n",
        "print(\"eval_sentences: \" + str(len(eval_sentences)) + \"\\n\")\n",
        "\n",
        "print(train_sentences[0])\n",
        "print(test_sentences[0])\n",
        "print(eval_sentences[0])\n",
        "\n",
        "print(\"\\ntraining_tags:\" + str(len(training_sentences)))\n",
        "print(\"train_tags: \" + str(len(train_tags)))\n",
        "print(\"test_tags: \" + str(len(test_tags)))\n",
        "print(\"eval_tags: \" + str(len(eval_tags)) + \"\\n\")\n",
        "\n",
        "print(train_tags[0])\n",
        "print(test_tags[0])\n",
        "print(eval_tags[0])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training_sentences:4824\n",
            "train_sentences: 3618\n",
            "test_sentences: 1206\n",
            "eval_sentences: 1206\n",
            "\n",
            "['*' 'El' 'Madrid' 'precisa' 'que' 'el' 'Deportivo' 'gane' 'la' 'Liga' ','\n",
            " 'porque' 'los' 'gallegos' 'no' 'son' 'considerados' 'unos' 'herederos'\n",
            " ',' 'sino' 'unos' 'entrometidos' 'que' 'se' 'supone' 'temporales' ','\n",
            " 'que' 'pertenecen' 'a' 'la' 'actualidad' 'más' 'rabiosa' 'y' 'no' 'a'\n",
            " 'la' 'historia' 'más' 'enrabietada' '.']\n",
            "['El' 'técnico' 'barcelonista' 'ha' 'asegurado' 'que' 'la' 'visita' 'de'\n",
            " 'Gaspart' 'ha' 'contribuido' 'a' '\"' 'sumar' '\"' ',' 'y' '*0*' 'ha'\n",
            " 'argumentado' 'que' 'el' 'encuentro' 'con' 'el' 'presidente' 'significa'\n",
            " 'que' 'en' 'el' 'Barcelona' '\"' 'todos' 'van' 'en' 'la' 'misma'\n",
            " 'dirección' '\"' '.']\n",
            "['Lo_suyo' ',' 'lo' 'de' 'las' 'ratas' ',' 'no' 'es' 'la' 'carroña' 'pura'\n",
            " 'y' 'dura' 'sino' 'la' 'vida' 'regalada' ',' 'el' 'eterno' 'banquete'\n",
            " 'de' 'sobras' 'y' 'residuos' ',' 'el' 'festín' 'organizado' 'a' 'la'\n",
            " 'sobra' 'de' 'la' 'abundancia' 'y' 'el' 'hartazgo' '.']\n",
            "\n",
            "training_tags:4824\n",
            "train_tags: 3618\n",
            "test_tags: 1206\n",
            "eval_tags: 1206\n",
            "\n",
            "['Fz' 'da0ms0' 'np0000l' 'vmip3s0' 'cs' 'da0ms0' 'np0000o' 'vmsp3s0'\n",
            " 'da0fs0' 'np0000a' 'Fc' 'cs' 'da0mp0' 'ncmp000' 'rn' 'vsip3p0' 'vmp00pm'\n",
            " 'di0mp0' 'ncmp000' 'Fc' 'cc' 'di0mp0' 'ncmp000' 'pr0cn000' 'p0000000'\n",
            " 'vmip3s0' 'aq0cp0' 'Fc' 'pr0cn000' 'vmip3p0' 'sps00' 'da0fs0' 'ncfs000'\n",
            " 'rg' 'aq0fs0' 'cc' 'rn' 'sps00' 'da0fs0' 'ncfs000' 'rg' 'aq0fsp' 'Fp']\n",
            "['da0ms0' 'ncms000' 'aq0cs0' 'vaip3s0' 'vmp00sm' 'cs' 'da0fs0' 'ncfs000'\n",
            " 'sps00' 'np00000' 'vaip3s0' 'vmp00sm' 'sps00' 'Fe' 'vmn0000' 'Fe' 'Fc'\n",
            " 'cc' 'sn.e-SUJ' 'vaip3s0' 'vmp00sm' 'cs' 'da0ms0' 'ncms000' 'sps00'\n",
            " 'da0ms0' 'ncms000' 'vmip3s0' 'cs' 'sps00' 'da0ms0' 'np00000' 'Fe'\n",
            " 'pi0mp000' 'vmip3p0' 'sps00' 'da0fs0' 'di0fs0' 'ncfs000' 'Fe' 'Fp']\n",
            "['px3ns000' 'Fc' 'da0ns0' 'sps00' 'da0fp0' 'ncfp000' 'Fc' 'rn' 'vsip3s0'\n",
            " 'da0fs0' 'ncfs000' 'aq0fs0' 'cc' 'aq0fs0' 'cc' 'da0fs0' 'ncfs000'\n",
            " 'aq0fsp' 'Fc' 'da0ms0' 'aq0ms0' 'ncms000' 'sps00' 'ncfp000' 'cc'\n",
            " 'ncmp000' 'Fc' 'da0ms0' 'ncms000' 'aq0msp' 'sps00' 'da0fs0' 'ncfs000'\n",
            " 'sps00' 'da0fs0' 'ncfs000' 'cc' 'da0ms0' 'ncms000' 'Fp']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "Jd-i6q85Quho"
      },
      "cell_type": "markdown",
      "source": [
        "### Ahora creamos una array con todas las palabras y los tags presentes en el corpus, adicionalmente se crea un diccionario que contiene las palabras unicas y los tags unicos de tal forma que no se repitan y que contienen un indice o llave"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "qdCNulCoQuhr",
        "outputId": "5b5af5ee-f55a-46ee-8f82-28d4633ce29c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "words, tagsss = set([]), set([])\n",
        " \n",
        "for s in (train_sentences + eval_sentences + test_sentences):\n",
        "    for w in s:\n",
        "        words.add(w.lower())\n",
        "\n",
        "for ts in (train_tags + eval_tags + test_tags):\n",
        "    for t in ts:\n",
        "        tagsss.add(t)\n",
        "\n",
        "word2index = {w: i + 2 for i, w in enumerate(list(words))}\n",
        "word2index['-PAD-'] = 0  # The special value used for padding\n",
        "word2index['-OOV-'] = 1  # The special value used for OOVs\n",
        " \n",
        "tag2index = {t: i + 2 for i, t in enumerate(list(tagsss))}\n",
        "tag2index['-PAD-'] = 0  # The special value used to padding\n",
        "tag2index['-OOV-'] = 1  # The special value used to padding\n",
        "\n",
        "print (len(word2index))\n",
        "print (len(tag2index))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "24499\n",
            "291\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "VEA9Ek-GOYOn"
      },
      "cell_type": "markdown",
      "source": [
        "### Ahora procedemos a transformar cada uno de los conjuntos de oraciones y tags en vectores numericos, modificando la palabra o tag en un Valor numerico que corresponde a una llave en el diccionario de palbras o tags"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "69eec13kQuh2",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_sentences_X, eval_sentences_X, test_sentences_X, train_tags_y, eval_tags_y, test_tags_y = [], [], [], [], [], []\n",
        "\n",
        "for s in train_sentences:\n",
        "    s_int = []\n",
        "    for w in s:\n",
        "        try:\n",
        "            s_int.append(word2index[w.lower()])\n",
        "        except KeyError:\n",
        "            s_int.append(word2index['-OOV-'])\n",
        " \n",
        "    train_sentences_X.append(s_int)\n",
        "\n",
        "for s in eval_sentences:\n",
        "    s_int = []\n",
        "    for w in s:\n",
        "        try:\n",
        "            s_int.append(word2index[w.lower()])\n",
        "        except KeyError:\n",
        "            s_int.append(word2index['-OOV-'])\n",
        " \n",
        "    eval_sentences_X.append(s_int)\n",
        "\n",
        "for s in test_sentences:\n",
        "    s_int = []\n",
        "    for w in s:\n",
        "        try:\n",
        "            s_int.append(word2index[w.lower()])\n",
        "        except KeyError:\n",
        "            s_int.append(word2index['-OOV-'])\n",
        " \n",
        "    test_sentences_X.append(s_int)\n",
        "\n",
        "for s in train_tags:\n",
        "    s_int = []\n",
        "    for w in s:\n",
        "        try:\n",
        "            s_int.append(tag2index[w])\n",
        "        except KeyError:\n",
        "            s_int.append(tag2index['-OOV-'])\n",
        "            \n",
        "    train_tags_y.append(s_int)\n",
        "\n",
        "for s in eval_tags:\n",
        "    s_int = []\n",
        "    for w in s:\n",
        "        try:\n",
        "            s_int.append(tag2index[w])\n",
        "        except KeyError:\n",
        "            s_int.append(tag2index['-OOV-'])\n",
        "            \n",
        "    eval_tags_y.append(s_int)\n",
        "\n",
        "for s in test_tags:\n",
        "    s_int = []\n",
        "    for w in s:\n",
        "        try:\n",
        "            s_int.append(tag2index[w])\n",
        "        except KeyError:\n",
        "            s_int.append(tag2index['-OOV-'])\n",
        "            \n",
        "    test_tags_y.append(s_int)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "d_lXW1mBPNkf"
      },
      "cell_type": "markdown",
      "source": [
        "### Se imprime la longitud de las matrices y una muesta de cada una de las matrices creadas"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Y5A4d_dzQuh6",
        "outputId": "7244eb28-0ddf-401e-88dd-c18607f312ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        }
      },
      "cell_type": "code",
      "source": [
        "print(\"Longitudes de las Matrices:\")\n",
        "print(len(train_sentences_X))\n",
        "print(len(eval_sentences_X))\n",
        "print(len(test_sentences_X))\n",
        "print(len(train_tags_y))\n",
        "print(len(eval_tags_y))\n",
        "print(len(test_tags_y))\n",
        "\n",
        "print(\"\\nMuestra de Datos presentes en las Matrices con las transformaciones:\")\n",
        "\n",
        "print(train_sentences_X[0])\n",
        "print(eval_sentences_X[0])\n",
        "print(test_sentences_X[0])\n",
        "print(train_tags_y[0])\n",
        "print(eval_tags_y[0])\n",
        "print(test_tags_y[0])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Longitudes de las Matrices:\n",
            "3618\n",
            "1206\n",
            "1206\n",
            "3618\n",
            "1206\n",
            "1206\n",
            "\n",
            "Muestra de Datos presentes en las Matrices con las transformaciones:\n",
            "[7140, 22154, 22597, 4768, 253, 22154, 21323, 16231, 2205, 7212, 13437, 12947, 19817, 14970, 8570, 23902, 19129, 17409, 19460, 13437, 19869, 17409, 22974, 253, 13196, 10122, 9862, 13437, 253, 15598, 258, 2205, 24407, 21534, 3546, 11306, 8570, 258, 2205, 5589, 21534, 923, 14782]\n",
            "[6468, 13437, 13893, 9065, 17508, 8661, 13437, 8570, 4849, 2205, 22397, 1433, 11306, 16358, 19869, 2205, 9557, 14865, 13437, 22154, 7282, 12253, 9065, 9021, 11306, 12226, 13437, 22154, 23573, 7571, 258, 2205, 10451, 9065, 2205, 20775, 11306, 22154, 1864, 14782]\n",
            "[22154, 20097, 1854, 12836, 8439, 253, 2205, 18310, 9065, 12680, 12836, 24008, 258, 18224, 8297, 18224, 13437, 11306, 11386, 12836, 12110, 253, 22154, 2152, 14120, 22154, 4593, 22882, 253, 20492, 22154, 20256, 18224, 23745, 17075, 20492, 2205, 20488, 4880, 18224, 14782]\n",
            "[258, 243, 56, 249, 46, 243, 142, 196, 205, 274, 210, 46, 52, 260, 201, 72, 127, 155, 260, 210, 133, 155, 260, 195, 147, 249, 88, 210, 195, 194, 174, 205, 197, 182, 117, 133, 201, 174, 205, 197, 182, 132, 250]\n",
            "[77, 210, 145, 174, 162, 215, 210, 201, 22, 205, 197, 117, 133, 117, 133, 205, 197, 132, 210, 243, 273, 225, 174, 215, 133, 260, 210, 243, 225, 186, 174, 205, 197, 174, 205, 197, 133, 243, 225, 250]\n",
            "[243, 225, 191, 45, 146, 46, 205, 197, 174, 198, 45, 146, 174, 212, 55, 212, 210, 133, 280, 45, 146, 46, 243, 225, 174, 243, 225, 249, 46, 174, 243, 198, 212, 6, 194, 174, 205, 289, 197, 212, 250]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "kWLspkzfQ513"
      },
      "cell_type": "markdown",
      "source": [
        "### Se calcula cual es la oracion que mayor cantidad de Palabras contiene"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Gif6KsESQuh_",
        "outputId": "4fe6272a-384f-48c7-edb6-b32495093c7a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "MAX_LENGTH1 = len(max(train_sentences_X, key=len))\n",
        "MAX_LENGTH2 = len(max(eval_sentences_X, key=len))\n",
        "MAX_LENGTH3 = len(max(test_sentences_X, key=len))\n",
        "\n",
        "l = [MAX_LENGTH1, MAX_LENGTH2, MAX_LENGTH3]\n",
        "MAX_LENGTH = max(l)\n",
        "\n",
        "print(MAX_LENGTH)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "149\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "e4ffWaDqRA1_"
      },
      "cell_type": "markdown",
      "source": [
        "### Se procede a Normalizar las matrices para que todas contengan el mismo numero de columans, con la longitud maxima de palabras encontradas anteriormente, esto se logra agregando ceros a la derecha en las posiciones que hacen falta en el vector"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "mn7iuMIOQuiI",
        "outputId": "3342c109-76d8-46b4-a43d-2d585b8b20d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1156
        }
      },
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.sequence import pad_sequences\n",
        " \n",
        "train_sentences_X = pad_sequences(train_sentences_X, maxlen=MAX_LENGTH, padding='post')\n",
        "eval_sentences_X = pad_sequences(eval_sentences_X, maxlen=MAX_LENGTH, padding='post')\n",
        "test_sentences_X = pad_sequences(test_sentences_X, maxlen=MAX_LENGTH, padding='post')\n",
        "train_tags_y = pad_sequences(train_tags_y, maxlen=MAX_LENGTH, padding='post')\n",
        "eval_tags_y = pad_sequences(eval_tags_y, maxlen=MAX_LENGTH, padding='post')\n",
        "test_tags_y = pad_sequences(test_tags_y, maxlen=MAX_LENGTH, padding='post')\n",
        " \n",
        "print(train_sentences_X[0])\n",
        "print(eval_sentences_X[0])\n",
        "print(test_sentences_X[0])\n",
        "print(train_tags_y[0])\n",
        "print(eval_tags_y[0])\n",
        "print(test_tags_y[0])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[ 7140 22154 22597  4768   253 22154 21323 16231  2205  7212 13437 12947\n",
            " 19817 14970  8570 23902 19129 17409 19460 13437 19869 17409 22974   253\n",
            " 13196 10122  9862 13437   253 15598   258  2205 24407 21534  3546 11306\n",
            "  8570   258  2205  5589 21534   923 14782     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0]\n",
            "[ 6468 13437 13893  9065 17508  8661 13437  8570  4849  2205 22397  1433\n",
            " 11306 16358 19869  2205  9557 14865 13437 22154  7282 12253  9065  9021\n",
            " 11306 12226 13437 22154 23573  7571   258  2205 10451  9065  2205 20775\n",
            " 11306 22154  1864 14782     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0]\n",
            "[22154 20097  1854 12836  8439   253  2205 18310  9065 12680 12836 24008\n",
            "   258 18224  8297 18224 13437 11306 11386 12836 12110   253 22154  2152\n",
            " 14120 22154  4593 22882   253 20492 22154 20256 18224 23745 17075 20492\n",
            "  2205 20488  4880 18224 14782     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0]\n",
            "[258 243  56 249  46 243 142 196 205 274 210  46  52 260 201  72 127 155\n",
            " 260 210 133 155 260 195 147 249  88 210 195 194 174 205 197 182 117 133\n",
            " 201 174 205 197 182 132 250   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0]\n",
            "[ 77 210 145 174 162 215 210 201  22 205 197 117 133 117 133 205 197 132\n",
            " 210 243 273 225 174 215 133 260 210 243 225 186 174 205 197 174 205 197\n",
            " 133 243 225 250   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0]\n",
            "[243 225 191  45 146  46 205 197 174 198  45 146 174 212  55 212 210 133\n",
            " 280  45 146  46 243 225 174 243 225 249  46 174 243 198 212   6 194 174\n",
            " 205 289 197 212 250   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "elkKsVbBNrYO"
      },
      "cell_type": "markdown",
      "source": [
        "### Definimos la funcion con la cual categorizaremos los tags y los covertiremos un vector One-hot"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "qGw5_dPX5xc0",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def to_categorical(sequences, categories):\n",
        "    cat_sequences = []\n",
        "    for s in sequences:\n",
        "        cats = []\n",
        "        for item in s:\n",
        "            cats.append(np.zeros(categories))\n",
        "            cats[-1][item] = 1.0\n",
        "        cat_sequences.append(cats)\n",
        "    return np.array(cat_sequences)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "GOmqn-5ZNg23"
      },
      "cell_type": "markdown",
      "source": [
        "### Desarrollamos una prueba de la categorisacion de los tags"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "lepVNGK5bgc1",
        "outputId": "16119460-9cb3-4662-98e2-9279c6e8d137",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "cell_type": "code",
      "source": [
        "cat_train_tags_y = to_categorical(train_tags_y, len(tag2index))\n",
        "print(cat_train_tags_y[0])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [1. 0. 0. ... 0. 0. 0.]\n",
            " [1. 0. 0. ... 0. 0. 0.]\n",
            " [1. 0. 0. ... 0. 0. 0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "9-_gAQ7qrWTQ"
      },
      "cell_type": "markdown",
      "source": [
        "## PARTE 2  -  Entrenamiento"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "odDOhtO4NZDd"
      },
      "cell_type": "markdown",
      "source": [
        "### Definimos el Modelo Base con el cual se procedera a desarrollar la fase de Entrenamiento"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "x31rRt8PQuiW",
        "outputId": "88a5c441-7697-42cb-e0b5-8218f4e9e43f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        }
      },
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, LSTM, InputLayer, Bidirectional, TimeDistributed, Embedding, Activation, Dropout\n",
        "from keras.optimizers import Adam\n",
        "from keras.utils import plot_model\n",
        "\n",
        "model = Sequential()\n",
        "model.add(InputLayer(input_shape=(MAX_LENGTH, )))\n",
        "model.add(Embedding(len(word2index), 128))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Bidirectional(LSTM(256, return_sequences=True)))\n",
        "model.add(TimeDistributed(Dense(len(tag2index))))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer=Adam(0.001), metrics=['accuracy'])\n",
        " \n",
        "model.summary()\n",
        "\n",
        "plot_model(model, to_file='model-mb01.png', show_shapes=True)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 149, 128)          3135872   \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 149, 128)          0         \n",
            "_________________________________________________________________\n",
            "bidirectional_1 (Bidirection (None, 149, 512)          788480    \n",
            "_________________________________________________________________\n",
            "time_distributed_1 (TimeDist (None, 149, 291)          149283    \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 149, 291)          0         \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 149, 291)          0         \n",
            "=================================================================\n",
            "Total params: 4,073,635\n",
            "Trainable params: 4,073,635\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "3qRKXZmm2S3Y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('model-mb01.png')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "4XghotI4NG9G"
      },
      "cell_type": "markdown",
      "source": [
        "### Se dedarrolla el entrenamiento del modelo"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "C0gOhZznbg6V",
        "outputId": "1451c2c6-4f97-4127-86e6-6d6ec5382ded",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1516
        }
      },
      "cell_type": "code",
      "source": [
        "model_hist = model.fit(train_sentences_X, to_categorical(train_tags_y, len(tag2index)),\n",
        "                       validation_data=(eval_sentences_X, to_categorical(eval_tags_y, len(tag2index))),\n",
        "                       batch_size=128, \n",
        "                       epochs=40,\n",
        "                       validation_split=0.2)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Deprecated in favor of operator or tf.math.divide.\n",
            "Train on 3618 samples, validate on 1206 samples\n",
            "Epoch 1/40\n",
            "3618/3618 [==============================] - 31s 8ms/step - loss: 3.6311 - acc: 0.5413 - val_loss: 1.0419 - val_acc: 0.7979\n",
            "Epoch 2/40\n",
            "3618/3618 [==============================] - 21s 6ms/step - loss: 3.0053 - acc: 0.7790 - val_loss: 0.9676 - val_acc: 0.8128\n",
            "Epoch 3/40\n",
            "3618/3618 [==============================] - 21s 6ms/step - loss: 2.9810 - acc: 0.7953 - val_loss: 0.9292 - val_acc: 0.8128\n",
            "Epoch 4/40\n",
            "3618/3618 [==============================] - 30s 8ms/step - loss: 2.9609 - acc: 0.7994 - val_loss: 0.9020 - val_acc: 0.8186\n",
            "Epoch 5/40\n",
            "3618/3618 [==============================] - 33s 9ms/step - loss: 2.9468 - acc: 0.8066 - val_loss: 0.8718 - val_acc: 0.8318\n",
            "Epoch 6/40\n",
            "3618/3618 [==============================] - 33s 9ms/step - loss: 2.9287 - acc: 0.8152 - val_loss: 0.8169 - val_acc: 0.8539\n",
            "Epoch 7/40\n",
            "3618/3618 [==============================] - 33s 9ms/step - loss: 2.8831 - acc: 0.8294 - val_loss: 0.7241 - val_acc: 0.8884\n",
            "Epoch 8/40\n",
            "3618/3618 [==============================] - 32s 9ms/step - loss: 2.8133 - acc: 0.8422 - val_loss: 0.6202 - val_acc: 0.9060\n",
            "Epoch 9/40\n",
            "3618/3618 [==============================] - 33s 9ms/step - loss: 2.7587 - acc: 0.8531 - val_loss: 0.5415 - val_acc: 0.9247\n",
            "Epoch 10/40\n",
            "3618/3618 [==============================] - 33s 9ms/step - loss: 2.7183 - acc: 0.8608 - val_loss: 0.4718 - val_acc: 0.9337\n",
            "Epoch 11/40\n",
            "3618/3618 [==============================] - 32s 9ms/step - loss: 2.6918 - acc: 0.8654 - val_loss: 0.4222 - val_acc: 0.9421\n",
            "Epoch 12/40\n",
            "3618/3618 [==============================] - 33s 9ms/step - loss: 2.6703 - acc: 0.8695 - val_loss: 0.3751 - val_acc: 0.9488\n",
            "Epoch 13/40\n",
            "3618/3618 [==============================] - 33s 9ms/step - loss: 2.6416 - acc: 0.8738 - val_loss: 0.3362 - val_acc: 0.9555\n",
            "Epoch 14/40\n",
            "3618/3618 [==============================] - 23s 6ms/step - loss: 2.6231 - acc: 0.8769 - val_loss: 0.3030 - val_acc: 0.9605\n",
            "Epoch 15/40\n",
            "3618/3618 [==============================] - 21s 6ms/step - loss: 2.6106 - acc: 0.8793 - val_loss: 0.2781 - val_acc: 0.9644\n",
            "Epoch 16/40\n",
            "3618/3618 [==============================] - 21s 6ms/step - loss: 2.5975 - acc: 0.8817 - val_loss: 0.2525 - val_acc: 0.9674\n",
            "Epoch 17/40\n",
            "3618/3618 [==============================] - 21s 6ms/step - loss: 2.5857 - acc: 0.8837 - val_loss: 0.2323 - val_acc: 0.9704\n",
            "Epoch 18/40\n",
            "3618/3618 [==============================] - 21s 6ms/step - loss: 2.5716 - acc: 0.8851 - val_loss: 0.2155 - val_acc: 0.9725\n",
            "Epoch 19/40\n",
            "3618/3618 [==============================] - 21s 6ms/step - loss: 2.5592 - acc: 0.8859 - val_loss: 0.2011 - val_acc: 0.9740\n",
            "Epoch 20/40\n",
            "3618/3618 [==============================] - 32s 9ms/step - loss: 2.5584 - acc: 0.8866 - val_loss: 0.1859 - val_acc: 0.9755\n",
            "Epoch 21/40\n",
            "3618/3618 [==============================] - 32s 9ms/step - loss: 2.5525 - acc: 0.8882 - val_loss: 0.1740 - val_acc: 0.9764\n",
            "Epoch 22/40\n",
            "3618/3618 [==============================] - 33s 9ms/step - loss: 2.5490 - acc: 0.8890 - val_loss: 0.1659 - val_acc: 0.9771\n",
            "Epoch 23/40\n",
            "3618/3618 [==============================] - 32s 9ms/step - loss: 2.5405 - acc: 0.8893 - val_loss: 0.1580 - val_acc: 0.9774\n",
            "Epoch 24/40\n",
            "3618/3618 [==============================] - 33s 9ms/step - loss: 2.5420 - acc: 0.8891 - val_loss: 0.1493 - val_acc: 0.9781\n",
            "Epoch 25/40\n",
            "3618/3618 [==============================] - 33s 9ms/step - loss: 2.5354 - acc: 0.8894 - val_loss: 0.1413 - val_acc: 0.9785\n",
            "Epoch 26/40\n",
            "3618/3618 [==============================] - 32s 9ms/step - loss: 2.5347 - acc: 0.8905 - val_loss: 0.1359 - val_acc: 0.9790\n",
            "Epoch 27/40\n",
            "3618/3618 [==============================] - 32s 9ms/step - loss: 2.5243 - acc: 0.8908 - val_loss: 0.1327 - val_acc: 0.9790\n",
            "Epoch 28/40\n",
            "3618/3618 [==============================] - 32s 9ms/step - loss: 2.5190 - acc: 0.8912 - val_loss: 0.1274 - val_acc: 0.9793\n",
            "Epoch 29/40\n",
            "3618/3618 [==============================] - 31s 9ms/step - loss: 2.5183 - acc: 0.8911 - val_loss: 0.1249 - val_acc: 0.9798\n",
            "Epoch 30/40\n",
            "3618/3618 [==============================] - 22s 6ms/step - loss: 2.5147 - acc: 0.8917 - val_loss: 0.1217 - val_acc: 0.9796\n",
            "Epoch 31/40\n",
            "3618/3618 [==============================] - 21s 6ms/step - loss: 2.5116 - acc: 0.8917 - val_loss: 0.1169 - val_acc: 0.9798\n",
            "Epoch 32/40\n",
            "3618/3618 [==============================] - 21s 6ms/step - loss: 2.5166 - acc: 0.8916 - val_loss: 0.1149 - val_acc: 0.9799\n",
            "Epoch 33/40\n",
            "3618/3618 [==============================] - 21s 6ms/step - loss: 2.5146 - acc: 0.8913 - val_loss: 0.1101 - val_acc: 0.9803\n",
            "Epoch 34/40\n",
            "3618/3618 [==============================] - 21s 6ms/step - loss: 2.5122 - acc: 0.8919 - val_loss: 0.1097 - val_acc: 0.9805\n",
            "Epoch 35/40\n",
            "3618/3618 [==============================] - 21s 6ms/step - loss: 2.5146 - acc: 0.8925 - val_loss: 0.1088 - val_acc: 0.9798\n",
            "Epoch 36/40\n",
            "3618/3618 [==============================] - 21s 6ms/step - loss: 2.5114 - acc: 0.8915 - val_loss: 0.1059 - val_acc: 0.9806\n",
            "Epoch 37/40\n",
            "3618/3618 [==============================] - 21s 6ms/step - loss: 2.5041 - acc: 0.8925 - val_loss: 0.1025 - val_acc: 0.9807\n",
            "Epoch 38/40\n",
            "3618/3618 [==============================] - 21s 6ms/step - loss: 2.5059 - acc: 0.8917 - val_loss: 0.1047 - val_acc: 0.9805\n",
            "Epoch 39/40\n",
            "3618/3618 [==============================] - 21s 6ms/step - loss: 2.5053 - acc: 0.8918 - val_loss: 0.1008 - val_acc: 0.9806\n",
            "Epoch 40/40\n",
            "3618/3618 [==============================] - 21s 6ms/step - loss: 2.5082 - acc: 0.8924 - val_loss: 0.0994 - val_acc: 0.9806\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "9hTDgQb2rWTa"
      },
      "cell_type": "markdown",
      "source": [
        "## PARTE 3  -  Evaluación del Modelo"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "LdSkk8mzM1KN"
      },
      "cell_type": "markdown",
      "source": [
        "### Evaluamos el modelo y calculamos el valor de precision con respecto a los datos de prueba"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "cD-YI5Fgb3Kt",
        "outputId": "6315aa9b-27ea-45cf-bdb2-2f732ca01b1e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "scores = model.evaluate(test_sentences_X, to_categorical(test_tags_y, len(tag2index)))\n",
        "print(f\"{model.metrics_names[1]}: {scores[1] * 100}\")   # acc: 97.38805993872496"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1206/1206 [==============================] - 9s 8ms/step\n",
            "acc: 97.9253620551791\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "sAhkgtWHQuij"
      },
      "cell_type": "markdown",
      "source": [
        "### Definimos la funcion que nos servira para graficar el comportamiento del modelo en cada epoca del entrenamiento"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "JaBUkInNQuik",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_model_performance(train_loss, train_acc, train_val_loss, train_val_acc):\n",
        "    \"\"\" Plot model loss and accuracy through epochs. \"\"\"\n",
        "    blue= '#34495E'\n",
        "    green = '#2ECC71'\n",
        "    orange = '#E23B13'\n",
        "    # plot model loss\n",
        "    fig, (ax1, ax2) = plt.subplots(2, figsize=(10, 8))\n",
        "    ax1.plot(range(1, len(train_loss) + 1), train_loss, blue, linewidth=5, label='training')\n",
        "    ax1.plot(range(1, len(train_val_loss) + 1), train_val_loss, green, linewidth=5, label='validation')\n",
        "    ax1.set_xlabel('# epoch')\n",
        "    ax1.set_ylabel('loss')\n",
        "    ax1.tick_params('y')\n",
        "    ax1.legend(loc='upper right', shadow=False)\n",
        "    ax1.set_title('Model loss through #epochs', color=orange, fontweight='bold')\n",
        "    # plot model accuracy\n",
        "    ax2.plot(range(1, len(train_acc) + 1), train_acc, blue, linewidth=5, label='training')\n",
        "    ax2.plot(range(1, len(train_val_acc) + 1), train_val_acc, green, linewidth=5, label='validation')\n",
        "    ax2.set_xlabel('# epoch')\n",
        "    ax2.set_ylabel('accuracy')\n",
        "    ax2.tick_params('y')\n",
        "    ax2.legend(loc='lower right', shadow=False)\n",
        "    ax2.set_title('Model accuracy through #epochs', color=orange, fontweight='bold')\n",
        "    \n",
        "    fig.savefig('/training-mb-01.png', bbox_inches='tight')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "TxQh1AtuQuis"
      },
      "cell_type": "markdown",
      "source": [
        "### Procedemos a Graficar el comportamiento del Entrenamiento, tanto del conjunto de entrenamiento como el de validación con respecto a la cantidad de epocas"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Gs5f3U1nQuit",
        "outputId": "50877177-3805-4865-a8d3-73e2d2736ce6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 512
        }
      },
      "cell_type": "code",
      "source": [
        "plot_model_performance(\n",
        "    train_loss=model_hist.history.get('loss', []),\n",
        "    train_acc=model_hist.history.get('acc', []),\n",
        "    train_val_loss=model_hist.history.get('val_loss', []),\n",
        "    train_val_acc=model_hist.history.get('val_acc', [])\n",
        ")"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAl8AAAHvCAYAAABqnbr1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niInUfImIiIiYSM2XiIiIiIn+D6uoe+TbdLXnAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 720x576 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "cketRShF2fJ4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('/training-mb-01.png')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "pqiuy8q4GYjF"
      },
      "cell_type": "markdown",
      "source": [
        "### Función que Permite convertir Indices en Tags"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "YJ6GaLot9yZR",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def logits_to_tokens(sequences, index):\n",
        "    token_sequences = []\n",
        "    for categorical_sequence in sequences:\n",
        "        token_sequence = []\n",
        "        for categorical in categorical_sequence:\n",
        "            token_sequence.append(index[np.argmax(categorical)])\n",
        " \n",
        "        token_sequences.append(token_sequence)\n",
        " \n",
        "    return token_sequences"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "W-1GH3ZYuLc-"
      },
      "cell_type": "markdown",
      "source": [
        "### Hacemos la prediccion sobre el conjunto de pruebas "
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "6HgbDqqsR4a7",
        "outputId": "bb4214ce-5fc4-4d19-d6f3-4f0f85944757",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "prediction = model.predict(test_sentences_X)\n",
        "log_tokens = logits_to_tokens(prediction, {i: t for t, i in tag2index.items()})\n",
        "\n",
        "print(log_tokens[0])"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['da0ms0', 'ncms000', 'aq0cs0', 'vaip3s0', 'vmp00sm', 'cs', 'da0fs0', 'ncfs000', 'sps00', 'vmn0000', 'vaip3s0', 'vmp00sm', 'sps00', 'Fe', 'vmn0000', 'Fe', 'Fc', 'cc', 'sn.e-SUJ', 'vaip3s0', 'vmp00sm', 'cs', 'da0ms0', 'ncms000', 'sps00', 'da0ms0', 'ncms000', 'vmip3s0', 'cs', 'sps00', 'da0ms0', 'np0000l', 'Fe', 'pi0mp000', 'vmip3p0', 'sps00', 'da0fs0', 'di0fs0', 'ncfs000', 'Fe', 'Fp', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "uT6IIQXrQuix"
      },
      "cell_type": "markdown",
      "source": [
        "### Hallamos los valores de F1 score, recall, precision"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "GqTuNxppFNu-",
        "outputId": "80bfafc5-324c-44e3-acc2-65a4b2e92908",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 4236
        }
      },
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "results = pd.DataFrame(columns=['Expected', 'Predicted'])\n",
        "k = 0\n",
        "for i, lista_etiquetas_oracion in enumerate(test_tags):\n",
        "    for j, etiquetas in enumerate(lista_etiquetas_oracion):\n",
        "        k = k + 1\n",
        "        results.loc[k, 'Expected'] = etiquetas\n",
        "        results.loc[k, 'Predicted'] = log_tokens[i][j]\n",
        "\n",
        "# print(results)\n",
        "\n",
        "\n",
        "print('\\nclassification_report:\\n', classification_report(results['Expected'], results['Predicted']))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
            "  'recall', 'true', average, warn_for)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "classification_report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "       -PAD-       0.00      0.00      0.00         0\n",
            "         Faa       1.00      1.00      1.00         2\n",
            "         Fat       1.00      1.00      1.00         5\n",
            "          Fc       1.00      1.00      1.00      2291\n",
            "          Fd       1.00      1.00      1.00        87\n",
            "          Fe       1.00      1.00      1.00       631\n",
            "          Fg       1.00      1.00      1.00       226\n",
            "          Fh       0.00      0.00      0.00         3\n",
            "         Fia       0.86      1.00      0.92         6\n",
            "         Fit       1.00      1.00      1.00        19\n",
            "          Fp       1.00      1.00      1.00      1178\n",
            "         Fpa       1.00      1.00      1.00       156\n",
            "         Fpt       1.00      1.00      1.00       160\n",
            "          Fs       1.00      1.00      1.00        13\n",
            "          Fx       1.00      1.00      1.00        41\n",
            "          Fz       0.00      0.00      0.00         2\n",
            "           W       0.98      0.61      0.76       194\n",
            "           Z       0.94      0.68      0.79       320\n",
            "          Zm       0.94      0.94      0.94        35\n",
            "          Zp       0.75      0.40      0.52        45\n",
            "      ao0fp0       1.00      1.00      1.00        17\n",
            "      ao0fs0       0.97      0.95      0.96        66\n",
            "      ao0mp0       0.95      0.91      0.93        23\n",
            "      ao0ms0       0.95      0.95      0.95        59\n",
            "     aq00000       0.00      0.00      0.00         2\n",
            "      aq0cn0       0.33      0.25      0.29         4\n",
            "      aq0cp0       0.90      0.73      0.80       228\n",
            "      aq0cs0       0.71      0.86      0.78       590\n",
            "      aq0fp0       0.73      0.76      0.74       128\n",
            "      aq0fpp       0.27      0.54      0.36        52\n",
            "      aq0fs0       0.85      0.76      0.80       355\n",
            "      aq0fsp       0.44      0.56      0.49       140\n",
            "      aq0mp0       0.62      0.75      0.68       202\n",
            "      aq0mpp       0.60      0.47      0.53        96\n",
            "      aq0ms0       0.79      0.78      0.78       491\n",
            "      aq0msp       0.88      0.63      0.73       222\n",
            "          cc       0.98      0.99      0.99      1222\n",
            "          cs       0.94      0.90      0.92       927\n",
            "      da0fp0       0.98      1.00      0.99       374\n",
            "      da0fs0       0.99      1.00      0.99      1324\n",
            "      da0mp0       0.99      1.00      1.00       637\n",
            "      da0ms0       1.00      1.00      1.00      1275\n",
            "      da0ns0       0.95      0.96      0.96       110\n",
            "      dd0cp0       1.00      1.00      1.00         2\n",
            "      dd0cs0       1.00      0.75      0.86         4\n",
            "      dd0fp0       0.95      1.00      0.97        18\n",
            "      dd0fs0       0.97      1.00      0.99        67\n",
            "      dd0mp0       0.88      1.00      0.94        30\n",
            "      dd0ms0       0.94      1.00      0.97       101\n",
            "      di0cp0       1.00      0.60      0.75         5\n",
            "      di0cs0       1.00      0.88      0.94        26\n",
            "      di0fp0       0.97      0.97      0.97        71\n",
            "      di0fs0       0.97      1.00      0.98       335\n",
            "      di0mp0       0.95      0.96      0.95       112\n",
            "      di0ms0       0.97      0.96      0.96       482\n",
            "      dn0cp0       0.97      0.99      0.98       149\n",
            "      dn0cs0       0.00      0.00      0.00         1\n",
            "      dn0fp0       1.00      1.00      1.00         4\n",
            "      dn0fs0       0.00      0.00      0.00         2\n",
            "      dn0mp0       0.80      0.80      0.80         5\n",
            "      dn0ms0       1.00      0.22      0.36         9\n",
            "      dp1cps       1.00      1.00      1.00         1\n",
            "      dp1css       0.80      1.00      0.89         8\n",
            "      dp1fpp       1.00      1.00      1.00         1\n",
            "      dp1fsp       1.00      1.00      1.00         6\n",
            "      dp1mpp       1.00      0.86      0.92         7\n",
            "      dp1msp       1.00      1.00      1.00         8\n",
            "      dp2css       1.00      0.33      0.50         3\n",
            "      dp3cp0       1.00      1.00      1.00       107\n",
            "      dp3cs0       1.00      1.00      1.00       275\n",
            "      dp3fs0       0.00      0.00      0.00         1\n",
            "      dt0cn0       1.00      0.33      0.50         3\n",
            "           i       0.38      0.75      0.50         4\n",
            "     nc00000       0.04      0.12      0.06        26\n",
            "     nccn000       0.00      0.00      0.00         5\n",
            "     nccp000       0.94      0.87      0.90       103\n",
            "     nccs000       0.85      0.75      0.80       146\n",
            "     ncfn000       1.00      0.67      0.80        15\n",
            "     ncfp000       0.93      0.88      0.91       788\n",
            "     ncfs000       0.91      0.94      0.92      2132\n",
            "     ncmn000       0.93      0.54      0.68        24\n",
            "     ncmp000       0.90      0.87      0.88      1166\n",
            "     ncms000       0.79      0.94      0.86      2365\n",
            "     np00000       0.17      0.14      0.15        51\n",
            "     np0000a       0.74      0.33      0.45       202\n",
            "     np0000l       0.63      0.72      0.67       412\n",
            "     np0000o       0.78      0.62      0.69       656\n",
            "     np0000p       0.70      0.69      0.70       720\n",
            "    p0000000       0.65      0.59      0.62       193\n",
            "    p010p000       0.00      0.00      0.00         2\n",
            "    p010s000       0.25      0.33      0.29         3\n",
            "    p020s000       1.00      1.00      1.00         1\n",
            "    p0300000       0.66      0.74      0.69       217\n",
            "    pd0fp000       0.00      0.00      0.00         3\n",
            "    pd0fs000       0.75      0.60      0.67         5\n",
            "    pd0mp000       1.00      0.17      0.29         6\n",
            "    pd0ms000       1.00      0.62      0.77         8\n",
            "    pd0ns000       1.00      1.00      1.00        22\n",
            "    pi0cp000       1.00      1.00      1.00         2\n",
            "    pi0cs000       0.97      0.97      0.97        40\n",
            "    pi0fp000       0.80      0.57      0.67         7\n",
            "    pi0fs000       0.75      0.55      0.63        11\n",
            "    pi0mp000       0.81      0.83      0.82        35\n",
            "    pi0ms000       0.84      0.76      0.80        54\n",
            "    pn0cp000       0.88      0.85      0.87        27\n",
            "    pn0mp000       1.00      0.67      0.80         3\n",
            "    pn0ms000       0.00      0.00      0.00         2\n",
            "    pp1cp000       0.93      1.00      0.96        27\n",
            "    pp1cs000       0.92      0.89      0.91        27\n",
            "    pp1csn00       1.00      1.00      1.00        16\n",
            "    pp1cso00       1.00      1.00      1.00         5\n",
            "    pp1mp000       1.00      1.00      1.00         9\n",
            "    pp2cs000       1.00      1.00      1.00         4\n",
            "    pp2cs00p       1.00      0.75      0.86         4\n",
            "    pp2csn00       0.00      0.00      0.00         2\n",
            "    pp2cso00       0.00      0.00      0.00         1\n",
            "    pp3cn000       0.00      0.00      0.00        10\n",
            "    pp3cna00       0.00      0.00      0.00         2\n",
            "    pp3cno00       1.00      0.80      0.89         5\n",
            "    pp3cpa00       0.00      0.00      0.00         2\n",
            "    pp3cpd00       0.85      1.00      0.92        11\n",
            "    pp3csa00       0.00      0.00      0.00         1\n",
            "    pp3csd00       0.98      1.00      0.99        63\n",
            "    pp3fp000       1.00      1.00      1.00         6\n",
            "    pp3fpa00       1.00      0.20      0.33        10\n",
            "    pp3fs000       1.00      1.00      1.00        13\n",
            "    pp3fsa00       0.00      0.00      0.00        17\n",
            "    pp3mp000       1.00      1.00      1.00        26\n",
            "    pp3mpa00       0.00      0.00      0.00         4\n",
            "    pp3ms000       1.00      1.00      1.00        23\n",
            "    pp3msa00       0.85      0.88      0.87        33\n",
            "    pp3ns000       1.00      1.00      1.00        15\n",
            "    pr000000       0.95      0.77      0.85        26\n",
            "    pr0cn000       0.89      0.94      0.91       616\n",
            "    pr0cp000       1.00      1.00      1.00        10\n",
            "    pr0cs000       0.94      1.00      0.97        32\n",
            "    pr0fp000       1.00      1.00      1.00         1\n",
            "    pr0fs000       1.00      1.00      1.00         5\n",
            "    pr0ms000       1.00      0.33      0.50         3\n",
            "    pt000000       1.00      0.83      0.91        12\n",
            "    pt0cp000       0.00      0.00      0.00         1\n",
            "    pt0cs000       0.89      0.94      0.92        18\n",
            "    pt0mp000       0.00      0.00      0.00         2\n",
            "    px1fs0p0       0.00      0.00      0.00         1\n",
            "    px1mp0p0       0.00      0.00      0.00         0\n",
            "    px3ns000       1.00      1.00      1.00         1\n",
            "          rg       0.91      0.89      0.90      1208\n",
            "          rn       0.97      0.99      0.98       265\n",
            "      sn-SUJ       0.00      0.00      0.00         1\n",
            "        sn.e       0.00      0.00      0.00         4\n",
            "    sn.e-SUJ       0.99      1.00      0.99       818\n",
            " sn.e.1n-SUJ       0.00      0.00      0.00         6\n",
            "       spcms       1.00      0.99      0.99       692\n",
            "       sps00       1.00      0.99      1.00      5056\n",
            "     vaic3p0       0.00      0.00      0.00         1\n",
            "     vaic3s0       1.00      1.00      1.00         4\n",
            "     vaif1p0       0.00      0.00      0.00         1\n",
            "     vaif3s0       1.00      1.00      1.00         3\n",
            "     vaii1s0       0.00      0.00      0.00         1\n",
            "     vaii3p0       0.93      1.00      0.96        13\n",
            "     vaii3s0       0.98      1.00      0.99        41\n",
            "     vaip1p0       1.00      1.00      1.00         8\n",
            "     vaip1s0       1.00      1.00      1.00         9\n",
            "     vaip3p0       1.00      1.00      1.00        48\n",
            "     vaip3s0       1.00      0.99      1.00       185\n",
            "     vais3s0       1.00      1.00      1.00         5\n",
            "     van0000       0.95      1.00      0.98        21\n",
            "     vap00sm       1.00      1.00      1.00         1\n",
            "     vasi1p0       0.00      0.00      0.00         1\n",
            "     vasi3p0       1.00      1.00      1.00         2\n",
            "     vasi3s0       1.00      0.91      0.95        11\n",
            "     vasp1s0       0.00      0.00      0.00         1\n",
            "     vasp3p0       1.00      1.00      1.00         1\n",
            "     vasp3s0       0.89      1.00      0.94         8\n",
            "     vmg0000       0.27      0.57      0.37        92\n",
            "     vmic1p0       0.00      0.00      0.00         2\n",
            "     vmic1s0       0.00      0.00      0.00         0\n",
            "     vmic3p0       1.00      0.55      0.71        11\n",
            "     vmic3s0       0.95      0.70      0.81        30\n",
            "     vmif1p0       0.00      0.00      0.00         7\n",
            "     vmif1s0       0.00      0.00      0.00         3\n",
            "     vmif2s0       0.00      0.00      0.00         1\n",
            "     vmif3p0       0.76      0.55      0.64        40\n",
            "     vmif3s0       0.84      0.60      0.70       114\n",
            "     vmii1p0       0.29      0.22      0.25         9\n",
            "     vmii1s0       0.00      0.00      0.00         7\n",
            "     vmii3p0       0.68      0.42      0.52        67\n",
            "     vmii3s0       0.82      0.65      0.72       143\n",
            "     vmip1p0       0.91      0.68      0.78        60\n",
            "     vmip1s0       0.64      0.78      0.70        60\n",
            "     vmip2s0       0.43      0.50      0.46         6\n",
            "     vmip3p0       0.92      0.70      0.79       279\n",
            "     vmip3s0       0.82      0.91      0.87       599\n",
            "     vmis1p0       0.00      0.00      0.00         5\n",
            "     vmis1s0       0.60      0.25      0.35        12\n",
            "     vmis2s0       0.00      0.00      0.00         0\n",
            "     vmis3p0       0.99      0.59      0.74       148\n",
            "     vmis3s0       0.92      0.88      0.90       606\n",
            "     vmm02s0       0.00      0.00      0.00         3\n",
            "     vmm03p0       0.00      0.00      0.00         1\n",
            "     vmm03s0       0.00      0.00      0.00         7\n",
            "     vmn0000       0.87      0.85      0.86       849\n",
            "     vmp00pf       0.00      0.00      0.00         5\n",
            "     vmp00pm       0.42      0.50      0.46        16\n",
            "     vmp00sf       0.67      0.21      0.32        19\n",
            "     vmp00sm       0.91      0.94      0.93       311\n",
            "     vmsi1p0       0.00      0.00      0.00         2\n",
            "     vmsi1s0       0.00      0.00      0.00         2\n",
            "     vmsi3p0       0.09      0.08      0.09        12\n",
            "     vmsi3s0       0.22      0.38      0.28        26\n",
            "     vmsp1p0       0.17      0.22      0.19         9\n",
            "     vmsp1s0       0.50      0.14      0.22         7\n",
            "     vmsp3p0       0.29      0.44      0.35        45\n",
            "     vmsp3s0       0.53      0.55      0.54        66\n",
            "     vsg0000       1.00      1.00      1.00         7\n",
            "     vsic1s0       0.00      0.00      0.00         1\n",
            "     vsic3p0       0.00      0.00      0.00         2\n",
            "     vsic3s0       0.89      1.00      0.94         8\n",
            "     vsif3s0       1.00      1.00      1.00        13\n",
            "     vsii3p0       1.00      1.00      1.00        13\n",
            "     vsii3s0       0.90      1.00      0.95        26\n",
            "     vsip1p0       1.00      1.00      1.00         1\n",
            "     vsip1s0       1.00      1.00      1.00         3\n",
            "     vsip2s0       0.00      0.00      0.00         2\n",
            "     vsip3p0       1.00      1.00      1.00        48\n",
            "     vsip3s0       1.00      1.00      1.00       190\n",
            "     vsis3p0       0.95      1.00      0.97        18\n",
            "     vsis3s0       1.00      1.00      1.00        39\n",
            "     vsn0000       0.92      1.00      0.96        35\n",
            "     vsp00sm       1.00      1.00      1.00        32\n",
            "     vssi3p0       0.00      0.00      0.00         1\n",
            "     vssi3s0       0.00      0.00      0.00         3\n",
            "     vssp3p0       1.00      1.00      1.00         5\n",
            "     vssp3s0       1.00      1.00      1.00        12\n",
            "\n",
            "   micro avg       0.90      0.90      0.90     38876\n",
            "   macro avg       0.69      0.64      0.65     38876\n",
            "weighted avg       0.91      0.90      0.90     38876\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "nrAAFx0XrWT1"
      },
      "cell_type": "markdown",
      "source": [
        "## PARTE 4  -  Testing"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "uvOz-IShFzRR"
      },
      "cell_type": "markdown",
      "source": [
        "### Creamos un pequeño Ejemplo"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "_WT1PtS_Qui0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "a6eb7e40-3e44-4553-e2e8-8a19bc290c71"
      },
      "cell_type": "code",
      "source": [
        "test_samples = [\n",
        "    \"Correr es importante para mi .\".split(),\n",
        "    \"El hombre bajo corre bajo el puente con bajo índice de adrenalina .\".split()\n",
        "]\n",
        "print(test_samples)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['Correr', 'es', 'importante', 'para', 'mi', '.'], ['El', 'hombre', 'bajo', 'corre', 'bajo', 'el', 'puente', 'con', 'bajo', 'índice', 'de', 'adrenalina', '.']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "X5E7-zZdGCjY"
      },
      "cell_type": "markdown",
      "source": [
        "### Convertimos el texto en Una entrada para el Modelo"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "BApB6ScZ9jU8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "outputId": "212792b1-d818-4092-a6d9-40c15c62f5a2"
      },
      "cell_type": "code",
      "source": [
        "test_samples_X = []\n",
        "for s in test_samples:\n",
        "    s_int = []\n",
        "    for w in s:\n",
        "        try:\n",
        "            s_int.append(word2index[w.lower()])\n",
        "        except KeyError:\n",
        "            s_int.append(word2index['-OOV-'])\n",
        "    test_samples_X.append(s_int)\n",
        "\n",
        "test_samples_X = pad_sequences(test_samples_X, maxlen=MAX_LENGTH, padding='post')\n",
        "print(test_samples_X)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 7012  4849 14434  2069  8704 14782     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0]\n",
            " [22154  9204 23771 19490 23771 22154  6046 14120 23771 10456  9065     1\n",
            "  14782     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "trNZCjTWGLp-"
      },
      "cell_type": "markdown",
      "source": [
        "### Se Ejecuta la predicion con la Entrada del modelo entrenado"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "OX6Bd2Rz9oha",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        },
        "outputId": "85f1a07c-c120-46fa-c317-8876755dfced"
      },
      "cell_type": "code",
      "source": [
        "predictions = model.predict(test_samples_X)\n",
        "print(predictions, predictions.shape)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[[5.8158170e-03 2.5324748e-04 2.2709826e-03 ... 1.6241602e-04\n",
            "   7.4876274e-04 4.1314145e-04]\n",
            "  [3.1185491e-04 1.3111155e-04 9.0715736e-07 ... 5.6350545e-05\n",
            "   1.2912080e-03 7.2988354e-05]\n",
            "  [4.3521414e-04 4.1731852e-05 5.7387977e-05 ... 1.4069552e-05\n",
            "   8.0415477e-05 4.3913275e-05]\n",
            "  ...\n",
            "  [9.9998093e-01 9.8772048e-08 2.0065650e-08 ... 8.6858670e-08\n",
            "   5.6102603e-09 4.6878366e-08]\n",
            "  [9.9996698e-01 1.9451741e-07 3.0217322e-08 ... 1.7112882e-07\n",
            "   8.7355829e-09 7.6136494e-08]\n",
            "  [9.9994218e-01 3.6297553e-07 4.1500073e-08 ... 3.1847824e-07\n",
            "   1.4177168e-08 1.2405926e-07]]\n",
            "\n",
            " [[2.5832630e-04 1.8380011e-05 1.2066690e-06 ... 1.1637899e-05\n",
            "   9.8273325e-05 5.3123604e-05]\n",
            "  [3.1667302e-04 2.3348744e-05 1.6632507e-04 ... 1.6737327e-05\n",
            "   4.3288937e-06 1.3028189e-04]\n",
            "  [4.1382955e-03 1.6215675e-04 4.2014297e-05 ... 1.1260091e-04\n",
            "   2.4529043e-04 6.9548381e-03]\n",
            "  ...\n",
            "  [9.9998093e-01 9.8710842e-08 2.0029514e-08 ... 8.6205247e-08\n",
            "   5.6064842e-09 4.6646644e-08]\n",
            "  [9.9996710e-01 1.9440265e-07 3.0166881e-08 ... 1.6986480e-07\n",
            "   8.7304208e-09 7.5758422e-08]\n",
            "  [9.9994230e-01 3.6277345e-07 4.1436088e-08 ... 3.1616958e-07\n",
            "   1.4169952e-08 1.2344086e-07]]] (2, 149, 291)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "l-XS5z-NGiM-"
      },
      "cell_type": "markdown",
      "source": [
        "### Conversion de la Salida del Modelo a un lista de Indices de Tags"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "IgIutMjq92cp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "f21c5320-abcb-48f6-d360-f89984b5f2a6"
      },
      "cell_type": "code",
      "source": [
        "#print(len(predictions))\n",
        "log_tokens = logits_to_tokens(predictions, {i: t for t, i in tag2index.items()})\n",
        "print(log_tokens)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['vmn0000', 'vsip3s0', 'aq0cs0', 'sps00', 'dp1css', 'Fp', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-'], ['da0ms0', 'ncms000', 'sps00', 'vmip3s0', 'sps00', 'da0ms0', 'ncms000', 'sps00', 'sps00', 'ncms000', 'sps00', 'np0000l', 'Fp', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "VmWp09kyGrQC"
      },
      "cell_type": "markdown",
      "source": [
        "### Presentacion de los Resultados"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "wNMCM8_jSdCL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "6754f230-f7ee-40aa-edeb-c27b8a921ab9"
      },
      "cell_type": "code",
      "source": [
        "#!pip install tabulate\n",
        "from tabulate import tabulate\n",
        "\n",
        "heads1 = test_samples[0]\n",
        "body1 = [log_tokens[0][:len(test_samples[0])]]\n",
        "\n",
        "heads2 = test_samples[1]\n",
        "body2 = [log_tokens[1][:len(test_samples[1])]]\n",
        "\n",
        "print(tabulate(body1, headers=heads1))\n",
        "\n",
        "print (\"\\n\")\n",
        "\n",
        "print(tabulate(body2, headers=heads2))\n",
        "\n",
        "\n",
        "## postagging Freeling 4.1\n",
        "\n",
        "## El      hombre   bajo     corre    bajo  el      puente   con  bajo  índice   de  adrenalina  .\n",
        "## DA0MS0  NCMS000  AQ0MS00  VMIP3S0  SP    DA0MS0  NCMS000  SP   SP    NCMS000  SP  NCFS000     Fp\n",
        "\n",
        "\n",
        "## pos tagger Stanford NLP\n",
        "\n",
        "## El      hombre   bajo     corre    bajo  el      puente   con    bajo   índice  de    adrenalina  .\n",
        "## da0000  nc0s000  aq0000   vmip000  sp000 da0000  nc0s000  sp000  aq0000 nc0s000 sp000 nc0s000     fp"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Correr    es       importante    para    mi      .\n",
            "--------  -------  ------------  ------  ------  ---\n",
            "vmn0000   vsip3s0  aq0cs0        sps00   dp1css  Fp\n",
            "\n",
            "\n",
            "El      hombre    bajo    corre    bajo    el      puente    con    bajo    índice    de     adrenalina    .\n",
            "------  --------  ------  -------  ------  ------  --------  -----  ------  --------  -----  ------------  ---\n",
            "da0ms0  ncms000   sps00   vmip3s0  sps00   da0ms0  ncms000   sps00  sps00   ncms000   sps00  np0000l       Fp\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "zEqVaw-HSPiu"
      },
      "cell_type": "markdown",
      "source": [
        "## PARTE 5  -  Mejorando la Precision y Exactitud del Modelo"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "1gR8kcV0GwFS"
      },
      "cell_type": "markdown",
      "source": [
        "### Definimos una clase que permita ignorar los Valores de Relleno"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "QwNvdZiE956Y",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras import backend as K\n",
        " \n",
        "def ignore_class_accuracy(to_ignore=0):\n",
        "    def ignore_accuracy(y_true, y_pred):\n",
        "        y_true_class = K.argmax(y_true, axis=-1)\n",
        "        y_pred_class = K.argmax(y_pred, axis=-1)\n",
        " \n",
        "        ignore_mask = K.cast(K.not_equal(y_pred_class, to_ignore), 'int32')\n",
        "        matches = K.cast(K.equal(y_true_class, y_pred_class), 'int32') * ignore_mask\n",
        "        accuracy = K.sum(matches) / K.maximum(K.sum(ignore_mask), 1)\n",
        "        return accuracy\n",
        "    return ignore_accuracy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "AxT3F3pHIGHk"
      },
      "cell_type": "markdown",
      "source": [
        "### Definimos nuevamente nuestro modelo, agregado la clase Creada"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "KO4DTAAE-BaS",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, LSTM, InputLayer, Bidirectional, TimeDistributed, Embedding, Activation\n",
        "from keras.optimizers import Adam\n",
        " \n",
        "\n",
        "model = Sequential()\n",
        "model.add(InputLayer(input_shape=(MAX_LENGTH, )))\n",
        "model.add(Embedding(len(word2index), 128))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Bidirectional(LSTM(256, return_sequences=True)))\n",
        "model.add(TimeDistributed(Dense(len(tag2index))))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Activation('softmax'))\n",
        " \n",
        "model.compile(loss='categorical_crossentropy', optimizer=Adam(0.001),  metrics=['accuracy', ignore_class_accuracy(0)]) \n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "Z8AiPXp8IVOu"
      },
      "cell_type": "markdown",
      "source": [
        "### Procedemos a Entrenar Nuevamente"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "CwgZVEIW-ECo",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.fit(train_sentences_X, to_categorical(train_tags_y, len(tag2index)), batch_size=128, epochs=40, validation_split=0.2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "LnExWbEmIa5U"
      },
      "cell_type": "markdown",
      "source": [
        "### Calculamos nuevamente la Precisión"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "FKOa73gRNMm7",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "scores2 = model.evaluate(test_sentences_X, to_categorical(test_tags_y, len(tag2index)))\n",
        "print(f\"{model.metrics_names[1]}: {scores2[1] * 100}\")   # acc: 99.09751977804825"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "ZzeCdasrIkuN"
      },
      "cell_type": "markdown",
      "source": [
        "### Relaizamos nuevamente el calculo de F1-score, recall, y precision"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "VbqNJa0pIvVT",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "Nri9gFnwIxcN"
      },
      "cell_type": "markdown",
      "source": [
        "### Realizamos nuevamente una prueba con el Ejemplo de Prueba"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "xruHro6L-LT2",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "predictions1 = model.predict(test_samples_X)\n",
        "log_tokens1  = logits_to_tokens(predictions1, {i: t for t, i in tag2index.items()})\n",
        "print(log_tokens1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "VL9taLbrI641"
      },
      "cell_type": "markdown",
      "source": [
        "### Presentamos los Resultados"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "QeRx8eSThbuq",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from tabulate import tabulate\n",
        "\n",
        "heads1 = test_samples[0]\n",
        "body1 = [log_tokens[0][:len(test_samples[0])]]\n",
        "\n",
        "heads2 = test_samples[1]\n",
        "body2 = [log_tokens[1][:len(test_samples[1])]]\n",
        "\n",
        "print(tabulate(body1, headers=heads1))\n",
        "\n",
        "print (\"\\n\")\n",
        "\n",
        "print(tabulate(body2, headers=heads2))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}