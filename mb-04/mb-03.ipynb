{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mb-00.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "colab_type": "text",
        "id": "3nXS4RUQQugV"
      },
      "cell_type": "markdown",
      "source": [
        "# Tutorial Part-of-Speech tagging  Con Deep Learning\n",
        "\n",
        "### En este tutorial, veremos cómo puede usar un modelo simple en Keras, para entrenar y evaluar una red neuronal artificial para problemas de clasificación de múltiples clases."
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "WIheRrq2Quga"
      },
      "cell_type": "markdown",
      "source": [
        "## PARTE 1  -  Pre-Procesamiento"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "lw10qukzQuge",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Asegurar reproducibilidad\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "CUSTOM_SEED = 42\n",
        "np.random.seed(CUSTOM_SEED)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "CxOcxDUmJcvL"
      },
      "cell_type": "markdown",
      "source": [
        "### Descargamos el Corpus Ancora - Cess_esp del nltk"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "NILevBJxQugr",
        "outputId": "05db9f45-57c6-4420-f290-fd9be6a8978b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('cess_esp')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package cess_esp to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/cess_esp.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "eqdUvUCEJjgc"
      },
      "cell_type": "markdown",
      "source": [
        "### Extraemos las oraciones tageadas del Corpus"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "ss3RHo4LQugx",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import random\n",
        "from nltk.corpus import cess_esp\n",
        "\n",
        "tagged_sentences = cess_esp.tagged_sents()\n",
        "#print('a random sentence: \\n-> {}'.format(random.choice(sentences)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "gCW_ENdLJudC"
      },
      "cell_type": "markdown",
      "source": [
        "### Extraemos los datos de la cantidad de oraciones a ser usadas y un ejemplo de una oracion presente en el corpus"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "2clQUNdtQug4",
        "outputId": "4182f009-50e2-40fb-fe42-bf52158c94f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "cell_type": "code",
      "source": [
        "print(tagged_sentences[0])\n",
        "print(\"Tagged sentences: \", len(tagged_sentences))\n",
        "print(\"Tagged words:\", len(cess_esp.tagged_words()))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('El', 'da0ms0'), ('grupo', 'ncms000'), ('estatal', 'aq0cs0'), ('Electricité_de_France', 'np00000'), ('-Fpa-', 'Fpa'), ('EDF', 'np00000'), ('-Fpt-', 'Fpt'), ('anunció', 'vmis3s0'), ('hoy', 'rg'), (',', 'Fc'), ('jueves', 'W'), (',', 'Fc'), ('la', 'da0fs0'), ('compra', 'ncfs000'), ('del', 'spcms'), ('51_por_ciento', 'Zp'), ('de', 'sps00'), ('la', 'da0fs0'), ('empresa', 'ncfs000'), ('mexicana', 'aq0fs0'), ('Electricidad_Águila_de_Altamira', 'np00000'), ('-Fpa-', 'Fpa'), ('EAA', 'np00000'), ('-Fpt-', 'Fpt'), (',', 'Fc'), ('creada', 'aq0fsp'), ('por', 'sps00'), ('el', 'da0ms0'), ('japonés', 'aq0ms0'), ('Mitsubishi_Corporation', 'np00000'), ('para', 'sps00'), ('poner_en_marcha', 'vmn0000'), ('una', 'di0fs0'), ('central', 'ncfs000'), ('de', 'sps00'), ('gas', 'ncms000'), ('de', 'sps00'), ('495', 'Z'), ('megavatios', 'ncmp000'), ('.', 'Fp')]\n",
            "Tagged sentences:  6030\n",
            "Tagged words: 192685\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "i_aFjuCQKG1O"
      },
      "cell_type": "markdown",
      "source": [
        "### Se procede a Dividir en una lista de Oraciones dividida en lista de palabras y cada palabra con un correspondiente tag en un alista diferente"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "516a_v5vQuhC",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        " \n",
        "sentences, tagss =[], [] \n",
        "for tagged_sentence in tagged_sentences:\n",
        "    sentence, tags = zip(*tagged_sentence)\n",
        "    sentences.append(np.array(sentence))\n",
        "    tagss.append(np.array(tags))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "UN_E4ePpKhvy"
      },
      "cell_type": "markdown",
      "source": [
        "### Imprimimos una posicion de la lista como ejemplo"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "l6uGGSqZQuhM",
        "outputId": "f4addf11-656f-4a02-91c5-83828c445797",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "cell_type": "code",
      "source": [
        "print(sentences[5])\n",
        "print(tagss[5])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['EDF' 'tiene' 'previsto' 'invertir' '194' 'millones' 'de' 'euros' '-Fpa-'\n",
            " '186' 'millones' 'de' 'dólares' '-Fpt-' 'en' 'la' 'central' 'de'\n",
            " 'Río_Bravo' ',' 'con' 'una' 'potencia' 'de' '495' 'megavatios' ',' 'y'\n",
            " '134' 'millones' 'de' 'euros' '-Fpa-' '28' 'millones' 'de' 'dólares'\n",
            " '-Fpt-' 'en' 'Saltillo' ',' 'que' 'como' 'la' 'primera' 'funcionará'\n",
            " 'con' 'gas' 'natural' 'y' 'cuya' 'potencia' 'prevista' 'es' 'de' '247'\n",
            " 'megavatios' '.']\n",
            "['np00000' 'vmip3s0' 'aq0msp' 'vmn0000' 'Z' 'ncmp000' 'sps00' 'Zm' 'Fpa'\n",
            " 'Z' 'ncmp000' 'sps00' 'Zm' 'Fpt' 'sps00' 'da0fs0' 'ncfs000' 'sps00'\n",
            " 'np00000' 'Fc' 'sps00' 'di0fs0' 'ncfs000' 'sps00' 'Z' 'ncmp000' 'Fc' 'cc'\n",
            " 'Z' 'ncmp000' 'sps00' 'Zm' 'Fpa' 'Z' 'ncmp000' 'sps00' 'Zm' 'Fpt' 'sps00'\n",
            " 'np00000' 'Fc' 'pr0cn000' 'cs' 'da0fs0' 'ao0fs0' 'vmif3s0' 'sps00'\n",
            " 'ncms000' 'aq0cs0' 'cc' 'pr0fs000' 'ncfs000' 'aq0fsp' 'vsip3s0' 'sps00'\n",
            " 'Z' 'ncmp000' 'Fp']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "WFQrAblFQuhT"
      },
      "cell_type": "markdown",
      "source": [
        "### Dividimos el corpus de la siguiente manera, Utilizamos aproximadamente el 60% de las oraciones etiquetadas para el entrenamiento, el 20% como conjunto de validación y el 20% para evaluar nuestro modelo."
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "ZtLulrEOQuhU",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        " \n",
        "(training_sentences, \n",
        " test_sentences, \n",
        " training_tags, \n",
        " test_tags) = train_test_split(sentences, tagss, test_size=0.2)\n",
        "\n",
        "(train_sentences, \n",
        " eval_sentences, \n",
        " train_tags, \n",
        " eval_tags) = train_test_split(training_sentences, training_tags, test_size=0.25)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "_Mk0scnsK1OE"
      },
      "cell_type": "markdown",
      "source": [
        "### Imprimimos los tamaños de las listas que nos indicaran el tamaño de filas de las matrices con las que estaremos trabajando"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "7HkjbP_IQuhZ",
        "outputId": "239b3106-9172-4dae-99ee-6400d2c9333e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 697
        }
      },
      "cell_type": "code",
      "source": [
        "print(\"training_sentences:\" + str(len(training_sentences)))\n",
        "print(\"train_sentences: \" + str(len(train_sentences)))\n",
        "print(\"test_sentences: \" + str(len(test_sentences)))\n",
        "print(\"eval_sentences: \" + str(len(eval_sentences)) + \"\\n\")\n",
        "\n",
        "print(train_sentences[0])\n",
        "print(test_sentences[0])\n",
        "print(eval_sentences[0])\n",
        "\n",
        "print(\"\\ntraining_tags:\" + str(len(training_sentences)))\n",
        "print(\"train_tags: \" + str(len(train_tags)))\n",
        "print(\"test_tags: \" + str(len(test_tags)))\n",
        "print(\"eval_tags: \" + str(len(eval_tags)) + \"\\n\")\n",
        "\n",
        "print(train_tags[0])\n",
        "print(test_tags[0])\n",
        "print(eval_tags[0])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training_sentences:4824\n",
            "train_sentences: 3618\n",
            "test_sentences: 1206\n",
            "eval_sentences: 1206\n",
            "\n",
            "['*' 'El' 'Madrid' 'precisa' 'que' 'el' 'Deportivo' 'gane' 'la' 'Liga' ','\n",
            " 'porque' 'los' 'gallegos' 'no' 'son' 'considerados' 'unos' 'herederos'\n",
            " ',' 'sino' 'unos' 'entrometidos' 'que' 'se' 'supone' 'temporales' ','\n",
            " 'que' 'pertenecen' 'a' 'la' 'actualidad' 'más' 'rabiosa' 'y' 'no' 'a'\n",
            " 'la' 'historia' 'más' 'enrabietada' '.']\n",
            "['El' 'técnico' 'barcelonista' 'ha' 'asegurado' 'que' 'la' 'visita' 'de'\n",
            " 'Gaspart' 'ha' 'contribuido' 'a' '\"' 'sumar' '\"' ',' 'y' '*0*' 'ha'\n",
            " 'argumentado' 'que' 'el' 'encuentro' 'con' 'el' 'presidente' 'significa'\n",
            " 'que' 'en' 'el' 'Barcelona' '\"' 'todos' 'van' 'en' 'la' 'misma'\n",
            " 'dirección' '\"' '.']\n",
            "['Lo_suyo' ',' 'lo' 'de' 'las' 'ratas' ',' 'no' 'es' 'la' 'carroña' 'pura'\n",
            " 'y' 'dura' 'sino' 'la' 'vida' 'regalada' ',' 'el' 'eterno' 'banquete'\n",
            " 'de' 'sobras' 'y' 'residuos' ',' 'el' 'festín' 'organizado' 'a' 'la'\n",
            " 'sobra' 'de' 'la' 'abundancia' 'y' 'el' 'hartazgo' '.']\n",
            "\n",
            "training_tags:4824\n",
            "train_tags: 3618\n",
            "test_tags: 1206\n",
            "eval_tags: 1206\n",
            "\n",
            "['Fz' 'da0ms0' 'np0000l' 'vmip3s0' 'cs' 'da0ms0' 'np0000o' 'vmsp3s0'\n",
            " 'da0fs0' 'np0000a' 'Fc' 'cs' 'da0mp0' 'ncmp000' 'rn' 'vsip3p0' 'vmp00pm'\n",
            " 'di0mp0' 'ncmp000' 'Fc' 'cc' 'di0mp0' 'ncmp000' 'pr0cn000' 'p0000000'\n",
            " 'vmip3s0' 'aq0cp0' 'Fc' 'pr0cn000' 'vmip3p0' 'sps00' 'da0fs0' 'ncfs000'\n",
            " 'rg' 'aq0fs0' 'cc' 'rn' 'sps00' 'da0fs0' 'ncfs000' 'rg' 'aq0fsp' 'Fp']\n",
            "['da0ms0' 'ncms000' 'aq0cs0' 'vaip3s0' 'vmp00sm' 'cs' 'da0fs0' 'ncfs000'\n",
            " 'sps00' 'np00000' 'vaip3s0' 'vmp00sm' 'sps00' 'Fe' 'vmn0000' 'Fe' 'Fc'\n",
            " 'cc' 'sn.e-SUJ' 'vaip3s0' 'vmp00sm' 'cs' 'da0ms0' 'ncms000' 'sps00'\n",
            " 'da0ms0' 'ncms000' 'vmip3s0' 'cs' 'sps00' 'da0ms0' 'np00000' 'Fe'\n",
            " 'pi0mp000' 'vmip3p0' 'sps00' 'da0fs0' 'di0fs0' 'ncfs000' 'Fe' 'Fp']\n",
            "['px3ns000' 'Fc' 'da0ns0' 'sps00' 'da0fp0' 'ncfp000' 'Fc' 'rn' 'vsip3s0'\n",
            " 'da0fs0' 'ncfs000' 'aq0fs0' 'cc' 'aq0fs0' 'cc' 'da0fs0' 'ncfs000'\n",
            " 'aq0fsp' 'Fc' 'da0ms0' 'aq0ms0' 'ncms000' 'sps00' 'ncfp000' 'cc'\n",
            " 'ncmp000' 'Fc' 'da0ms0' 'ncms000' 'aq0msp' 'sps00' 'da0fs0' 'ncfs000'\n",
            " 'sps00' 'da0fs0' 'ncfs000' 'cc' 'da0ms0' 'ncms000' 'Fp']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "Jd-i6q85Quho"
      },
      "cell_type": "markdown",
      "source": [
        "### Ahora creamos una array con todas las palabras y los tags presentes en el corpus, adicionalmente se crea un diccionario que contiene las palabras unicas y los tags unicos de tal forma que no se repitan y que contienen un indice o llave"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "qdCNulCoQuhr",
        "outputId": "98ef44f4-7d36-440d-eefd-f3571040f747",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "words, tagsss = set([]), set([])\n",
        " \n",
        "for s in (train_sentences + eval_sentences + test_sentences):\n",
        "    for w in s:\n",
        "        words.add(w.lower())\n",
        "\n",
        "for ts in (train_tags + eval_tags + test_tags):\n",
        "    for t in ts:\n",
        "        tagsss.add(t)\n",
        "\n",
        "word2index = {w: i + 2 for i, w in enumerate(list(words))}\n",
        "word2index['-PAD-'] = 0  # The special value used for padding\n",
        "word2index['-OOV-'] = 1  # The special value used for OOVs\n",
        " \n",
        "tag2index = {t: i + 2 for i, t in enumerate(list(tagsss))}\n",
        "tag2index['-PAD-'] = 0  # The special value used to padding\n",
        "tag2index['-OOV-'] = 1  # The special value used to padding\n",
        "\n",
        "print (len(word2index))\n",
        "print (len(tag2index))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "24499\n",
            "291\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "VEA9Ek-GOYOn"
      },
      "cell_type": "markdown",
      "source": [
        "### Ahora procedemos a transformar cada uno de los conjuntos de oraciones y tags en vectores numericos, modificando la palabra o tag en un Valor numerico que corresponde a una llave en el diccionario de palbras o tags"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "69eec13kQuh2",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_sentences_X, eval_sentences_X, test_sentences_X, train_tags_y, eval_tags_y, test_tags_y = [], [], [], [], [], []\n",
        "\n",
        "for s in train_sentences:\n",
        "    s_int = []\n",
        "    for w in s:\n",
        "        try:\n",
        "            s_int.append(word2index[w.lower()])\n",
        "        except KeyError:\n",
        "            s_int.append(word2index['-OOV-'])\n",
        " \n",
        "    train_sentences_X.append(s_int)\n",
        "\n",
        "for s in eval_sentences:\n",
        "    s_int = []\n",
        "    for w in s:\n",
        "        try:\n",
        "            s_int.append(word2index[w.lower()])\n",
        "        except KeyError:\n",
        "            s_int.append(word2index['-OOV-'])\n",
        " \n",
        "    eval_sentences_X.append(s_int)\n",
        "\n",
        "for s in test_sentences:\n",
        "    s_int = []\n",
        "    for w in s:\n",
        "        try:\n",
        "            s_int.append(word2index[w.lower()])\n",
        "        except KeyError:\n",
        "            s_int.append(word2index['-OOV-'])\n",
        " \n",
        "    test_sentences_X.append(s_int)\n",
        "\n",
        "for s in train_tags:\n",
        "    s_int = []\n",
        "    for w in s:\n",
        "        try:\n",
        "            s_int.append(tag2index[w])\n",
        "        except KeyError:\n",
        "            s_int.append(tag2index['-OOV-'])\n",
        "            \n",
        "    train_tags_y.append(s_int)\n",
        "\n",
        "for s in eval_tags:\n",
        "    s_int = []\n",
        "    for w in s:\n",
        "        try:\n",
        "            s_int.append(tag2index[w])\n",
        "        except KeyError:\n",
        "            s_int.append(tag2index['-OOV-'])\n",
        "            \n",
        "    eval_tags_y.append(s_int)\n",
        "\n",
        "for s in test_tags:\n",
        "    s_int = []\n",
        "    for w in s:\n",
        "        try:\n",
        "            s_int.append(tag2index[w])\n",
        "        except KeyError:\n",
        "            s_int.append(tag2index['-OOV-'])\n",
        "            \n",
        "    test_tags_y.append(s_int)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "d_lXW1mBPNkf"
      },
      "cell_type": "markdown",
      "source": [
        "### Se imprime la longitud de las matrices y una muesta de cada una de las matrices creadas"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Y5A4d_dzQuh6",
        "outputId": "a87e29fe-80b1-4e0c-bb1d-0655cd6e1d73",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        }
      },
      "cell_type": "code",
      "source": [
        "print(\"Longitudes de las Matrices:\")\n",
        "print(len(train_sentences_X))\n",
        "print(len(eval_sentences_X))\n",
        "print(len(test_sentences_X))\n",
        "print(len(train_tags_y))\n",
        "print(len(eval_tags_y))\n",
        "print(len(test_tags_y))\n",
        "\n",
        "print(\"\\nMuestra de Datos presentes en las Matrices con las transformaciones:\\n\")\n",
        "\n",
        "print(train_sentences_X[0])\n",
        "print(eval_sentences_X[0])\n",
        "print(test_sentences_X[0])\n",
        "print(train_tags_y[0])\n",
        "print(eval_tags_y[0])\n",
        "print(test_tags_y[0])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Longitudes de las Matrices:\n",
            "3618\n",
            "1206\n",
            "1206\n",
            "3618\n",
            "1206\n",
            "1206\n",
            "\n",
            "Muestra de Datos presentes en las Matrices con las transformaciones:\n",
            "\n",
            "[11645, 17992, 16805, 10818, 17609, 17992, 8642, 13716, 15972, 11084, 20144, 4400, 3495, 13166, 62, 21336, 5354, 5219, 16543, 20144, 22642, 5219, 14958, 17609, 10115, 15811, 22340, 20144, 17609, 7410, 19390, 15972, 14660, 5773, 23799, 14489, 62, 19390, 15972, 12903, 5773, 10615, 5906]\n",
            "[17267, 20144, 13434, 483, 16520, 17864, 20144, 62, 23818, 15972, 15976, 5478, 14489, 10190, 22642, 15972, 20127, 19063, 20144, 17992, 12619, 16947, 483, 2670, 14489, 4433, 20144, 17992, 3655, 6492, 19390, 15972, 10536, 483, 15972, 1808, 14489, 17992, 9212, 5906]\n",
            "[17992, 23368, 23138, 458, 883, 17609, 15972, 20863, 483, 11497, 458, 5274, 19390, 3573, 22578, 3573, 20144, 14489, 11211, 458, 9853, 17609, 17992, 5059, 12946, 17992, 16652, 13631, 17609, 20961, 17992, 2880, 3573, 10881, 19315, 20961, 15972, 8388, 6883, 3573, 5906]\n",
            "[7, 163, 139, 196, 5, 163, 202, 37, 137, 108, 235, 5, 11, 65, 12, 155, 8, 200, 65, 235, 57, 200, 65, 188, 255, 196, 181, 235, 188, 262, 177, 137, 214, 28, 99, 57, 12, 177, 137, 214, 28, 218, 103]\n",
            "[290, 235, 183, 177, 164, 122, 235, 12, 67, 137, 214, 99, 57, 99, 57, 137, 214, 218, 235, 163, 272, 112, 177, 122, 57, 65, 235, 163, 112, 190, 177, 137, 214, 177, 137, 214, 57, 163, 112, 103]\n",
            "[163, 112, 33, 113, 146, 5, 137, 214, 177, 25, 113, 146, 177, 17, 19, 17, 235, 57, 205, 113, 146, 5, 163, 112, 177, 163, 112, 196, 5, 177, 163, 25, 17, 168, 262, 177, 137, 4, 214, 17, 103]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "kWLspkzfQ513"
      },
      "cell_type": "markdown",
      "source": [
        "### Se calcula cual es la oracion que mayor cantidad de Palabras contiene"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Gif6KsESQuh_",
        "outputId": "a0be4dd9-13fc-473f-c608-7334de984a52",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "MAX_LENGTH1 = len(max(train_sentences_X, key=len))\n",
        "MAX_LENGTH2 = len(max(eval_sentences_X, key=len))\n",
        "MAX_LENGTH3 = len(max(test_sentences_X, key=len))\n",
        "\n",
        "l = [MAX_LENGTH1, MAX_LENGTH2, MAX_LENGTH3]\n",
        "MAX_LENGTH = max(l)\n",
        "\n",
        "print(MAX_LENGTH)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "149\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "e4ffWaDqRA1_"
      },
      "cell_type": "markdown",
      "source": [
        "### Se procede a Normalizar las matrices para que todas contengan el mismo numero de columans, con la longitud maxima de palabras encontradas anteriormente, esto se logra agregando ceros a la derecha en las posiciones que hacen falta en el vector"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "mn7iuMIOQuiI",
        "outputId": "8a6f3032-ab8b-426c-f45a-d182bd5e7cb3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1156
        }
      },
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.sequence import pad_sequences\n",
        " \n",
        "train_sentences_X = pad_sequences(train_sentences_X, maxlen=MAX_LENGTH, padding='post')\n",
        "eval_sentences_X = pad_sequences(eval_sentences_X, maxlen=MAX_LENGTH, padding='post')\n",
        "test_sentences_X = pad_sequences(test_sentences_X, maxlen=MAX_LENGTH, padding='post')\n",
        "train_tags_y = pad_sequences(train_tags_y, maxlen=MAX_LENGTH, padding='post')\n",
        "eval_tags_y = pad_sequences(eval_tags_y, maxlen=MAX_LENGTH, padding='post')\n",
        "test_tags_y = pad_sequences(test_tags_y, maxlen=MAX_LENGTH, padding='post')\n",
        " \n",
        "print(train_sentences_X[0])\n",
        "print(eval_sentences_X[0])\n",
        "print(test_sentences_X[0])\n",
        "print(train_tags_y[0])\n",
        "print(eval_tags_y[0])\n",
        "print(test_tags_y[0])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[11645 17992 16805 10818 17609 17992  8642 13716 15972 11084 20144  4400\n",
            "  3495 13166    62 21336  5354  5219 16543 20144 22642  5219 14958 17609\n",
            " 10115 15811 22340 20144 17609  7410 19390 15972 14660  5773 23799 14489\n",
            "    62 19390 15972 12903  5773 10615  5906     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0]\n",
            "[17267 20144 13434   483 16520 17864 20144    62 23818 15972 15976  5478\n",
            " 14489 10190 22642 15972 20127 19063 20144 17992 12619 16947   483  2670\n",
            " 14489  4433 20144 17992  3655  6492 19390 15972 10536   483 15972  1808\n",
            " 14489 17992  9212  5906     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0]\n",
            "[17992 23368 23138   458   883 17609 15972 20863   483 11497   458  5274\n",
            " 19390  3573 22578  3573 20144 14489 11211   458  9853 17609 17992  5059\n",
            " 12946 17992 16652 13631 17609 20961 17992  2880  3573 10881 19315 20961\n",
            " 15972  8388  6883  3573  5906     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0]\n",
            "[  7 163 139 196   5 163 202  37 137 108 235   5  11  65  12 155   8 200\n",
            "  65 235  57 200  65 188 255 196 181 235 188 262 177 137 214  28  99  57\n",
            "  12 177 137 214  28 218 103   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0]\n",
            "[290 235 183 177 164 122 235  12  67 137 214  99  57  99  57 137 214 218\n",
            " 235 163 272 112 177 122  57  65 235 163 112 190 177 137 214 177 137 214\n",
            "  57 163 112 103   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0]\n",
            "[163 112  33 113 146   5 137 214 177  25 113 146 177  17  19  17 235  57\n",
            " 205 113 146   5 163 112 177 163 112 196   5 177 163  25  17 168 262 177\n",
            " 137   4 214  17 103   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "elkKsVbBNrYO"
      },
      "cell_type": "markdown",
      "source": [
        "### Definimos la funcion con la cual categorizaremos los tags y los covertiremos un vector One-hot"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "qGw5_dPX5xc0",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def to_categorical(sequences, categories):\n",
        "    cat_sequences = []\n",
        "    for s in sequences:\n",
        "        cats = []\n",
        "        for item in s:\n",
        "            cats.append(np.zeros(categories))\n",
        "            cats[-1][item] = 1.0\n",
        "        cat_sequences.append(cats)\n",
        "    return np.array(cat_sequences)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "GOmqn-5ZNg23"
      },
      "cell_type": "markdown",
      "source": [
        "### Desarrollamos una prueba de la categorisacion de los tags"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "lepVNGK5bgc1",
        "outputId": "375e1509-c0a0-4d2b-a28e-a24fcfc59aa2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "cell_type": "code",
      "source": [
        "cat_train_tags_y = to_categorical(train_tags_y, len(tag2index))\n",
        "print(cat_train_tags_y[0])"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [1. 0. 0. ... 0. 0. 0.]\n",
            " [1. 0. 0. ... 0. 0. 0.]\n",
            " [1. 0. 0. ... 0. 0. 0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "9-_gAQ7qrWTQ"
      },
      "cell_type": "markdown",
      "source": [
        "## PARTE 2  -  Entrenamiento"
      ]
    },
    {
      "metadata": {
        "id": "ORyC-422jaD9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "odDOhtO4NZDd"
      },
      "cell_type": "markdown",
      "source": [
        "### Definimos el Modelo Base con el cual se procedera a desarrollar la fase de Entrenamiento"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "x31rRt8PQuiW",
        "outputId": "eb0c9647-849c-4697-b151-802f88de7e2e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, LSTM, InputLayer, Bidirectional, TimeDistributed, Embedding, Activation\n",
        "from keras.optimizers import Adam\n",
        "from keras.utils import plot_model\n",
        "#from keras.utils import multi_gpu_model\n",
        "\n",
        "model = Sequential()\n",
        "model.add(InputLayer(input_shape=(MAX_LENGTH, )))\n",
        "model.add(Embedding(len(word2index), 128))\n",
        "model.add(Bidirectional(LSTM(256, return_sequences=True)))\n",
        "model.add(TimeDistributed(Dense(len(tag2index))))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "#parallel_model = multi_gpu_model(model, gpus=2)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=Adam(0.001), metrics=['accuracy'])\n",
        " \n",
        "model.summary()\n",
        "#parallel_model.summary()\n",
        "\n",
        "plot_model(model, to_file='model-mb00.png', show_shapes=True)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_4 (Embedding)      (None, 149, 128)          3135872   \n",
            "_________________________________________________________________\n",
            "bidirectional_4 (Bidirection (None, 149, 512)          788480    \n",
            "_________________________________________________________________\n",
            "time_distributed_4 (TimeDist (None, 149, 291)          149283    \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 149, 291)          0         \n",
            "=================================================================\n",
            "Total params: 4,073,635\n",
            "Trainable params: 4,073,635\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Bt3IrAt-1c_C",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('model-mb00.png')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "4XghotI4NG9G"
      },
      "cell_type": "markdown",
      "source": [
        "### Se dedarrolla el entrenamiento del modelo"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "C0gOhZznbg6V",
        "outputId": "cfb9376e-230d-40ea-ffb8-ace34c8234b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1516
        }
      },
      "cell_type": "code",
      "source": [
        "model_hist = model.fit(train_sentences_X, to_categorical(train_tags_y, len(tag2index)),\n",
        "                       validation_data=(eval_sentences_X, to_categorical(eval_tags_y, len(tag2index))),\n",
        "                       batch_size=128, \n",
        "                       epochs=40,\n",
        "                       validation_split=0.2)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Deprecated in favor of operator or tf.math.divide.\n",
            "Train on 3618 samples, validate on 1206 samples\n",
            "Epoch 1/40\n",
            "3618/3618 [==============================] - 23s 6ms/step - loss: 2.1020 - acc: 0.7597 - val_loss: 0.9308 - val_acc: 0.7845\n",
            "Epoch 2/40\n",
            "3618/3618 [==============================] - 21s 6ms/step - loss: 0.8931 - acc: 0.7957 - val_loss: 0.8762 - val_acc: 0.8127\n",
            "Epoch 3/40\n",
            "3618/3618 [==============================] - 21s 6ms/step - loss: 0.8554 - acc: 0.8145 - val_loss: 0.8520 - val_acc: 0.8127\n",
            "Epoch 4/40\n",
            "3618/3618 [==============================] - 21s 6ms/step - loss: 0.8305 - acc: 0.8146 - val_loss: 0.8281 - val_acc: 0.8135\n",
            "Epoch 5/40\n",
            "3618/3618 [==============================] - 21s 6ms/step - loss: 0.8068 - acc: 0.8173 - val_loss: 0.8082 - val_acc: 0.8189\n",
            "Epoch 6/40\n",
            "3618/3618 [==============================] - 21s 6ms/step - loss: 0.7869 - acc: 0.8231 - val_loss: 0.7876 - val_acc: 0.8300\n",
            "Epoch 7/40\n",
            "3618/3618 [==============================] - 21s 6ms/step - loss: 0.7612 - acc: 0.8332 - val_loss: 0.7539 - val_acc: 0.8320\n",
            "Epoch 8/40\n",
            "3618/3618 [==============================] - 21s 6ms/step - loss: 0.7171 - acc: 0.8354 - val_loss: 0.6938 - val_acc: 0.8409\n",
            "Epoch 9/40\n",
            "3618/3618 [==============================] - 21s 6ms/step - loss: 0.6535 - acc: 0.8598 - val_loss: 0.6246 - val_acc: 0.8709\n",
            "Epoch 10/40\n",
            "3618/3618 [==============================] - 21s 6ms/step - loss: 0.5746 - acc: 0.8807 - val_loss: 0.5368 - val_acc: 0.8891\n",
            "Epoch 11/40\n",
            "3618/3618 [==============================] - 21s 6ms/step - loss: 0.4808 - acc: 0.8980 - val_loss: 0.4425 - val_acc: 0.9063\n",
            "Epoch 12/40\n",
            "3618/3618 [==============================] - 21s 6ms/step - loss: 0.3876 - acc: 0.9152 - val_loss: 0.3581 - val_acc: 0.9210\n",
            "Epoch 13/40\n",
            "3618/3618 [==============================] - 21s 6ms/step - loss: 0.3081 - acc: 0.9321 - val_loss: 0.2928 - val_acc: 0.9356\n",
            "Epoch 14/40\n",
            "3618/3618 [==============================] - 21s 6ms/step - loss: 0.2452 - acc: 0.9473 - val_loss: 0.2438 - val_acc: 0.9459\n",
            "Epoch 15/40\n",
            "3618/3618 [==============================] - 21s 6ms/step - loss: 0.1955 - acc: 0.9583 - val_loss: 0.2075 - val_acc: 0.9538\n",
            "Epoch 16/40\n",
            "3618/3618 [==============================] - 21s 6ms/step - loss: 0.1563 - acc: 0.9682 - val_loss: 0.1794 - val_acc: 0.9608\n",
            "Epoch 17/40\n",
            "3618/3618 [==============================] - 21s 6ms/step - loss: 0.1253 - acc: 0.9760 - val_loss: 0.1589 - val_acc: 0.9655\n",
            "Epoch 18/40\n",
            "3618/3618 [==============================] - 21s 6ms/step - loss: 0.1014 - acc: 0.9814 - val_loss: 0.1440 - val_acc: 0.9684\n",
            "Epoch 19/40\n",
            "3618/3618 [==============================] - 21s 6ms/step - loss: 0.0834 - acc: 0.9849 - val_loss: 0.1318 - val_acc: 0.9713\n",
            "Epoch 20/40\n",
            "3618/3618 [==============================] - 21s 6ms/step - loss: 0.0697 - acc: 0.9875 - val_loss: 0.1243 - val_acc: 0.9723\n",
            "Epoch 21/40\n",
            "3618/3618 [==============================] - 21s 6ms/step - loss: 0.0590 - acc: 0.9895 - val_loss: 0.1179 - val_acc: 0.9738\n",
            "Epoch 22/40\n",
            "3618/3618 [==============================] - 21s 6ms/step - loss: 0.0509 - acc: 0.9910 - val_loss: 0.1131 - val_acc: 0.9750\n",
            "Epoch 23/40\n",
            "3618/3618 [==============================] - 21s 6ms/step - loss: 0.0442 - acc: 0.9921 - val_loss: 0.1092 - val_acc: 0.9761\n",
            "Epoch 24/40\n",
            "3618/3618 [==============================] - 21s 6ms/step - loss: 0.0387 - acc: 0.9931 - val_loss: 0.1074 - val_acc: 0.9762\n",
            "Epoch 25/40\n",
            "3618/3618 [==============================] - 21s 6ms/step - loss: 0.0344 - acc: 0.9937 - val_loss: 0.1055 - val_acc: 0.9764\n",
            "Epoch 26/40\n",
            "3618/3618 [==============================] - 21s 6ms/step - loss: 0.0307 - acc: 0.9943 - val_loss: 0.1040 - val_acc: 0.9770\n",
            "Epoch 27/40\n",
            "3618/3618 [==============================] - 21s 6ms/step - loss: 0.0276 - acc: 0.9948 - val_loss: 0.1030 - val_acc: 0.9773\n",
            "Epoch 28/40\n",
            "3618/3618 [==============================] - 21s 6ms/step - loss: 0.0248 - acc: 0.9954 - val_loss: 0.1017 - val_acc: 0.9774\n",
            "Epoch 29/40\n",
            "3618/3618 [==============================] - 21s 6ms/step - loss: 0.0225 - acc: 0.9958 - val_loss: 0.1022 - val_acc: 0.9773\n",
            "Epoch 30/40\n",
            "3618/3618 [==============================] - 21s 6ms/step - loss: 0.0204 - acc: 0.9961 - val_loss: 0.1000 - val_acc: 0.9779\n",
            "Epoch 31/40\n",
            "3618/3618 [==============================] - 21s 6ms/step - loss: 0.0186 - acc: 0.9966 - val_loss: 0.1005 - val_acc: 0.9778\n",
            "Epoch 32/40\n",
            "3618/3618 [==============================] - 21s 6ms/step - loss: 0.0170 - acc: 0.9969 - val_loss: 0.1016 - val_acc: 0.9779\n",
            "Epoch 33/40\n",
            "3618/3618 [==============================] - 21s 6ms/step - loss: 0.0157 - acc: 0.9972 - val_loss: 0.1019 - val_acc: 0.9777\n",
            "Epoch 34/40\n",
            "3618/3618 [==============================] - 21s 6ms/step - loss: 0.0143 - acc: 0.9975 - val_loss: 0.1022 - val_acc: 0.9776\n",
            "Epoch 35/40\n",
            "3618/3618 [==============================] - 21s 6ms/step - loss: 0.0132 - acc: 0.9976 - val_loss: 0.1011 - val_acc: 0.9779\n",
            "Epoch 36/40\n",
            "3618/3618 [==============================] - 21s 6ms/step - loss: 0.0121 - acc: 0.9979 - val_loss: 0.1022 - val_acc: 0.9778\n",
            "Epoch 37/40\n",
            "3618/3618 [==============================] - 21s 6ms/step - loss: 0.0111 - acc: 0.9981 - val_loss: 0.1024 - val_acc: 0.9779\n",
            "Epoch 38/40\n",
            "3618/3618 [==============================] - 21s 6ms/step - loss: 0.0102 - acc: 0.9984 - val_loss: 0.1026 - val_acc: 0.9778\n",
            "Epoch 39/40\n",
            "3618/3618 [==============================] - 21s 6ms/step - loss: 0.0094 - acc: 0.9985 - val_loss: 0.1038 - val_acc: 0.9777\n",
            "Epoch 40/40\n",
            "3618/3618 [==============================] - 21s 6ms/step - loss: 0.0087 - acc: 0.9987 - val_loss: 0.1040 - val_acc: 0.9775\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "9hTDgQb2rWTa"
      },
      "cell_type": "markdown",
      "source": [
        "## PARTE 3  -  Evaluación del Modelo"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "LdSkk8mzM1KN"
      },
      "cell_type": "markdown",
      "source": [
        "### Evaluamos el modelo y calculamos el valor de precision con respecto a los datos de prueba"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "cD-YI5Fgb3Kt",
        "outputId": "98cb9946-4f38-4176-c5ad-5932d07962b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "scores = model.evaluate(test_sentences_X, to_categorical(test_tags_y, len(tag2index)))\n",
        "print(f\"{model.metrics_names[1]}: {scores[1] * 100}\")   # acc: 97.38805993872496"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1206/1206 [==============================] - 9s 8ms/step\n",
            "acc: 97.66269326210022\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "sAhkgtWHQuij"
      },
      "cell_type": "markdown",
      "source": [
        "### Definimos la funcion que nos servira para graficar el comportamiento del modelo en cada epoca del entrenamiento"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "JaBUkInNQuik",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_model_performance(train_loss, train_acc, train_val_loss, train_val_acc):\n",
        "    \"\"\" Plot model loss and accuracy through epochs. \"\"\"\n",
        "    blue= '#34495E'\n",
        "    green = '#2ECC71'\n",
        "    orange = '#E23B13'\n",
        "    # plot model loss\n",
        "    fig, (ax1, ax2) = plt.subplots(2, figsize=(10, 8))\n",
        "    ax1.plot(range(1, len(train_loss) + 1), train_loss, blue, linewidth=5, label='training')\n",
        "    ax1.plot(range(1, len(train_val_loss) + 1), train_val_loss, green, linewidth=5, label='validation')\n",
        "    ax1.set_xlabel('# epoch')\n",
        "    ax1.set_ylabel('loss')\n",
        "    ax1.tick_params('y')\n",
        "    ax1.legend(loc='upper right', shadow=False)\n",
        "    ax1.set_title('Model loss through #epochs', color=orange, fontweight='bold')\n",
        "    # plot model accuracy\n",
        "    ax2.plot(range(1, len(train_acc) + 1), train_acc, blue, linewidth=5, label='training')\n",
        "    ax2.plot(range(1, len(train_val_acc) + 1), train_val_acc, green, linewidth=5, label='validation')\n",
        "    ax2.set_xlabel('# epoch')\n",
        "    ax2.set_ylabel('accuracy')\n",
        "    ax2.tick_params('y')\n",
        "    ax2.legend(loc='lower right', shadow=False)\n",
        "    ax2.set_title('Model accuracy through #epochs', color=orange, fontweight='bold')\n",
        "    \n",
        "    fig.savefig('/training-mb-00.png', bbox_inches='tight')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "TxQh1AtuQuis"
      },
      "cell_type": "markdown",
      "source": [
        "### Procedemos a Graficar el comportamiento del Entrenamiento, tanto del conjunto de entrenamiento como el de validación con respecto a la cantidad de epocas"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Gs5f3U1nQuit",
        "outputId": "4c4ad746-3bbc-4325-9356-8045506b33a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 512
        }
      },
      "cell_type": "code",
      "source": [
        "plot_model_performance(\n",
        "    train_loss=model_hist.history.get('loss', []),\n",
        "    train_acc=model_hist.history.get('acc', []),\n",
        "    train_val_loss=model_hist.history.get('val_loss', []),\n",
        "    train_val_acc=model_hist.history.get('val_acc', [])\n",
        ")"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmUAAAHvCAYAAAAVTKgEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nERFxAGrKRERERBzA/wLdlTjblIg9ugAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 720x576 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "FQMZz9no22CJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('/training-mb-00.png')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "pqiuy8q4GYjF"
      },
      "cell_type": "markdown",
      "source": [
        "### Función que Permite convertir Indices en Tags"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "YJ6GaLot9yZR",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def logits_to_tokens(sequences, index):\n",
        "    token_sequences = []\n",
        "    for categorical_sequence in sequences:\n",
        "        token_sequence = []\n",
        "        for categorical in categorical_sequence:\n",
        "            token_sequence.append(index[np.argmax(categorical)])\n",
        " \n",
        "        token_sequences.append(token_sequence)\n",
        " \n",
        "    return token_sequences"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "W-1GH3ZYuLc-"
      },
      "cell_type": "markdown",
      "source": [
        "### Hacemos la prediccion sobre el conjunto de pruebas "
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "6HgbDqqsR4a7",
        "outputId": "63275f95-19ca-41f0-db78-e79ece5e6317",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "prediction = model.predict(test_sentences_X)\n",
        "log_tokens = logits_to_tokens(prediction, {i: t for t, i in tag2index.items()})\n",
        "\n",
        "print(log_tokens[0])"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['da0ms0', 'ncms000', 'aq0cs0', 'vaip3s0', 'vmp00sm', 'cs', 'da0fs0', 'ncfs000', 'sps00', 'np00000', 'vaip3s0', 'vmp00sm', 'sps00', 'Fe', 'vmn0000', 'Fe', 'Fc', 'cc', 'sn.e-SUJ', 'vaip3s0', 'vmp00sm', 'cs', 'da0ms0', 'ncms000', 'sps00', 'da0ms0', 'ncms000', 'vmip3s0', 'cs', 'sps00', 'da0ms0', 'np0000l', 'Fe', 'pi0mp000', 'vmip3p0', 'sps00', 'da0fs0', 'di0fs0', 'ncfs000', 'Fe', 'Fp', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "uT6IIQXrQuix"
      },
      "cell_type": "markdown",
      "source": [
        "### Hallamos los valores de F1 score, recall, precision"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "GqTuNxppFNu-",
        "outputId": "ce0f608a-171e-411d-f5d1-88666b57cd19",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 4219
        }
      },
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "results = pd.DataFrame(columns=['Expected', 'Predicted'])\n",
        "k = 0\n",
        "for i, lista_etiquetas_oracion in enumerate(test_tags):\n",
        "    for j, etiquetas in enumerate(lista_etiquetas_oracion):\n",
        "        k = k + 1\n",
        "        results.loc[k, 'Expected'] = etiquetas\n",
        "        results.loc[k, 'Predicted'] = log_tokens[i][j]\n",
        "\n",
        "# print(results)\n",
        "\n",
        "\n",
        "print('\\nclassification_report:\\n', classification_report(results['Expected'], results['Predicted']))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
            "  'recall', 'true', average, warn_for)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "classification_report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "       -PAD-       0.00      0.00      0.00         0\n",
            "         Faa       1.00      1.00      1.00         2\n",
            "         Fat       1.00      0.80      0.89         5\n",
            "          Fc       1.00      1.00      1.00      2291\n",
            "          Fd       1.00      1.00      1.00        87\n",
            "          Fe       1.00      1.00      1.00       631\n",
            "          Fg       0.98      1.00      0.99       226\n",
            "          Fh       0.00      0.00      0.00         3\n",
            "         Fia       1.00      1.00      1.00         6\n",
            "         Fit       1.00      1.00      1.00        19\n",
            "          Fp       1.00      1.00      1.00      1178\n",
            "         Fpa       1.00      1.00      1.00       156\n",
            "         Fpt       1.00      1.00      1.00       160\n",
            "          Fs       1.00      1.00      1.00        13\n",
            "          Fx       1.00      1.00      1.00        41\n",
            "          Fz       0.00      0.00      0.00         2\n",
            "           W       0.98      0.61      0.76       194\n",
            "           Z       0.89      0.57      0.70       320\n",
            "          Zm       0.72      0.94      0.81        35\n",
            "          Zp       0.94      0.38      0.54        45\n",
            "      ao0fp0       1.00      1.00      1.00        17\n",
            "      ao0fs0       0.95      0.92      0.94        66\n",
            "      ao0mp0       0.81      0.96      0.88        23\n",
            "      ao0ms0       0.93      0.93      0.93        59\n",
            "     aq00000       0.00      0.00      0.00         2\n",
            "      aq0cn0       0.00      0.00      0.00         4\n",
            "      aq0cp0       0.91      0.70      0.79       228\n",
            "      aq0cs0       0.93      0.84      0.88       590\n",
            "      aq0fp0       0.61      0.78      0.68       128\n",
            "      aq0fpp       0.50      0.33      0.40        52\n",
            "      aq0fs0       0.82      0.73      0.77       355\n",
            "      aq0fsp       0.63      0.43      0.51       140\n",
            "      aq0mp0       0.68      0.69      0.69       202\n",
            "      aq0mpp       0.59      0.40      0.48        96\n",
            "      aq0ms0       0.79      0.74      0.76       491\n",
            "      aq0msp       0.87      0.59      0.71       222\n",
            "          cc       0.99      0.99      0.99      1222\n",
            "          cs       0.89      0.88      0.88       927\n",
            "      da0fp0       0.98      1.00      0.99       374\n",
            "      da0fs0       0.99      1.00      0.99      1324\n",
            "      da0mp0       1.00      1.00      1.00       637\n",
            "      da0ms0       1.00      1.00      1.00      1275\n",
            "      da0ns0       0.87      0.98      0.92       110\n",
            "      dd0cp0       1.00      0.50      0.67         2\n",
            "      dd0cs0       1.00      0.75      0.86         4\n",
            "      dd0fp0       0.90      1.00      0.95        18\n",
            "      dd0fs0       0.97      1.00      0.99        67\n",
            "      dd0mp0       0.88      1.00      0.94        30\n",
            "      dd0ms0       0.95      1.00      0.98       101\n",
            "      di0cp0       0.75      0.60      0.67         5\n",
            "      di0cs0       0.96      0.88      0.92        26\n",
            "      di0fp0       0.95      0.99      0.97        71\n",
            "      di0fs0       0.98      0.99      0.98       335\n",
            "      di0mp0       0.92      0.92      0.92       112\n",
            "      di0ms0       0.96      0.94      0.95       482\n",
            "      dn0cp0       0.96      0.93      0.95       149\n",
            "      dn0cs0       0.00      0.00      0.00         1\n",
            "      dn0fp0       1.00      1.00      1.00         4\n",
            "      dn0fs0       0.33      0.50      0.40         2\n",
            "      dn0mp0       1.00      0.40      0.57         5\n",
            "      dn0ms0       0.50      0.22      0.31         9\n",
            "      dp1cps       0.50      1.00      0.67         1\n",
            "      dp1css       1.00      1.00      1.00         8\n",
            "      dp1fpp       1.00      1.00      1.00         1\n",
            "      dp1fsp       1.00      1.00      1.00         6\n",
            "      dp1mpp       1.00      0.71      0.83         7\n",
            "      dp1msp       1.00      1.00      1.00         8\n",
            "      dp2css       1.00      0.33      0.50         3\n",
            "      dp3cp0       1.00      1.00      1.00       107\n",
            "      dp3cs0       1.00      1.00      1.00       275\n",
            "      dp3fs0       0.00      0.00      0.00         1\n",
            "      dt0cn0       1.00      0.33      0.50         3\n",
            "           i       0.04      0.50      0.07         4\n",
            "     nc00000       0.07      0.15      0.10        26\n",
            "     nccn000       0.00      0.00      0.00         5\n",
            "     nccp000       0.83      0.88      0.85       103\n",
            "     nccs000       0.90      0.65      0.76       146\n",
            "     ncfn000       1.00      0.67      0.80        15\n",
            "     ncfp000       0.92      0.87      0.89       788\n",
            "     ncfs000       0.94      0.90      0.92      2132\n",
            "     ncmn000       0.87      0.54      0.67        24\n",
            "     ncmp000       0.95      0.83      0.89      1166\n",
            "     ncms000       0.84      0.92      0.88      2365\n",
            "     np00000       0.03      0.18      0.05        51\n",
            "     np0000a       0.29      0.35      0.31       202\n",
            "     np0000l       0.71      0.64      0.67       412\n",
            "     np0000o       0.61      0.64      0.62       656\n",
            "     np0000p       0.57      0.75      0.65       720\n",
            "    p0000000       0.66      0.69      0.67       193\n",
            "    p010p000       0.00      0.00      0.00         2\n",
            "    p010s000       0.00      0.00      0.00         3\n",
            "    p020s000       0.50      1.00      0.67         1\n",
            "    p0300000       0.69      0.69      0.69       217\n",
            "    pd0fp000       0.00      0.00      0.00         3\n",
            "    pd0fs000       1.00      0.60      0.75         5\n",
            "    pd0mp000       0.67      0.33      0.44         6\n",
            "    pd0ms000       1.00      0.75      0.86         8\n",
            "    pd0ns000       1.00      1.00      1.00        22\n",
            "    pi0cp000       0.33      1.00      0.50         2\n",
            "    pi0cs000       1.00      0.95      0.97        40\n",
            "    pi0fp000       1.00      0.43      0.60         7\n",
            "    pi0fs000       0.78      0.64      0.70        11\n",
            "    pi0mp000       0.76      0.74      0.75        35\n",
            "    pi0ms000       0.76      0.65      0.70        54\n",
            "    pn0cp000       0.86      0.89      0.87        27\n",
            "    pn0mp000       0.50      1.00      0.67         3\n",
            "    pn0ms000       0.00      0.00      0.00         2\n",
            "    pp1cp000       0.93      1.00      0.96        27\n",
            "    pp1cs000       0.90      0.96      0.93        27\n",
            "    pp1csn00       1.00      0.88      0.93        16\n",
            "    pp1cso00       1.00      1.00      1.00         5\n",
            "    pp1mp000       1.00      1.00      1.00         9\n",
            "    pp2cs000       1.00      0.75      0.86         4\n",
            "    pp2cs00p       0.33      0.25      0.29         4\n",
            "    pp2csn00       0.00      0.00      0.00         2\n",
            "    pp2cso00       0.00      0.00      0.00         1\n",
            "    pp3cn000       0.00      0.00      0.00        10\n",
            "    pp3cna00       0.00      0.00      0.00         2\n",
            "    pp3cno00       1.00      1.00      1.00         5\n",
            "    pp3cpa00       0.00      0.00      0.00         2\n",
            "    pp3cpd00       0.85      1.00      0.92        11\n",
            "    pp3csa00       0.00      0.00      0.00         1\n",
            "    pp3csd00       0.98      0.98      0.98        63\n",
            "    pp3fp000       1.00      1.00      1.00         6\n",
            "    pp3fpa00       1.00      0.30      0.46        10\n",
            "    pp3fs000       1.00      1.00      1.00        13\n",
            "    pp3fsa00       0.57      0.24      0.33        17\n",
            "    pp3mp000       1.00      1.00      1.00        26\n",
            "    pp3mpa00       1.00      0.25      0.40         4\n",
            "    pp3ms000       1.00      1.00      1.00        23\n",
            "    pp3msa00       0.90      0.58      0.70        33\n",
            "    pp3ns000       1.00      1.00      1.00        15\n",
            "    pr000000       0.83      0.77      0.80        26\n",
            "    pr0cn000       0.86      0.87      0.87       616\n",
            "    pr0cp000       1.00      1.00      1.00        10\n",
            "    pr0cs000       0.94      1.00      0.97        32\n",
            "    pr0fp000       0.00      0.00      0.00         1\n",
            "    pr0fs000       1.00      1.00      1.00         5\n",
            "    pr0ms000       0.50      0.33      0.40         3\n",
            "    pt000000       1.00      0.75      0.86        12\n",
            "    pt0cp000       0.00      0.00      0.00         1\n",
            "    pt0cs000       0.89      0.94      0.92        18\n",
            "    pt0mp000       0.00      0.00      0.00         2\n",
            "    px1fs0p0       1.00      1.00      1.00         1\n",
            "    px3ns000       0.00      0.00      0.00         1\n",
            "          rg       0.95      0.89      0.92      1208\n",
            "          rn       0.97      0.99      0.98       265\n",
            "      sn-SUJ       0.00      0.00      0.00         1\n",
            "        sn.e       0.00      0.00      0.00         4\n",
            "    sn.e-SUJ       0.99      1.00      0.99       818\n",
            " sn.e.1n-SUJ       0.00      0.00      0.00         6\n",
            "       spcms       1.00      0.99      0.99       692\n",
            "       sps00       0.99      0.99      0.99      5056\n",
            "     vaic3p0       0.00      0.00      0.00         1\n",
            "     vaic3s0       1.00      1.00      1.00         4\n",
            "     vaif1p0       0.00      0.00      0.00         1\n",
            "     vaif3s0       1.00      1.00      1.00         3\n",
            "     vaii1s0       0.00      0.00      0.00         1\n",
            "     vaii3p0       1.00      1.00      1.00        13\n",
            "     vaii3s0       0.98      1.00      0.99        41\n",
            "     vaip1p0       1.00      1.00      1.00         8\n",
            "     vaip1s0       1.00      0.89      0.94         9\n",
            "     vaip3p0       1.00      1.00      1.00        48\n",
            "     vaip3s0       1.00      0.99      1.00       185\n",
            "     vais3s0       1.00      1.00      1.00         5\n",
            "     van0000       0.95      1.00      0.98        21\n",
            "     vap00sm       1.00      1.00      1.00         1\n",
            "     vasi1p0       0.00      0.00      0.00         1\n",
            "     vasi3p0       0.00      0.00      0.00         2\n",
            "     vasi3s0       1.00      1.00      1.00        11\n",
            "     vasp1s0       0.00      0.00      0.00         1\n",
            "     vasp3p0       1.00      1.00      1.00         1\n",
            "     vasp3s0       0.89      1.00      0.94         8\n",
            "     vmg0000       0.48      0.42      0.45        92\n",
            "     vmic1p0       0.00      0.00      0.00         2\n",
            "     vmic1s0       0.00      0.00      0.00         0\n",
            "     vmic3p0       1.00      0.55      0.71        11\n",
            "     vmic3s0       1.00      0.70      0.82        30\n",
            "     vmif1p0       0.00      0.00      0.00         7\n",
            "     vmif1s0       1.00      0.33      0.50         3\n",
            "     vmif2s0       0.00      0.00      0.00         1\n",
            "     vmif3p0       0.74      0.42      0.54        40\n",
            "     vmif3s0       1.00      0.55      0.71       114\n",
            "     vmii1p0       0.50      0.22      0.31         9\n",
            "     vmii1s0       0.00      0.00      0.00         7\n",
            "     vmii3p0       0.87      0.39      0.54        67\n",
            "     vmii3s0       0.91      0.63      0.74       143\n",
            "     vmip1p0       1.00      0.67      0.80        60\n",
            "     vmip1s0       0.57      0.78      0.66        60\n",
            "     vmip2s0       0.08      0.67      0.14         6\n",
            "     vmip3p0       0.98      0.67      0.79       279\n",
            "     vmip3s0       0.67      0.92      0.78       599\n",
            "     vmis1p0       0.00      0.00      0.00         5\n",
            "     vmis1s0       0.75      0.25      0.38        12\n",
            "     vmis2s0       0.00      0.00      0.00         0\n",
            "     vmis3p0       1.00      0.55      0.71       148\n",
            "     vmis3s0       0.99      0.85      0.92       606\n",
            "     vmm02s0       0.00      0.00      0.00         3\n",
            "     vmm03p0       0.00      0.00      0.00         1\n",
            "     vmm03s0       0.00      0.00      0.00         7\n",
            "     vmn0000       0.76      0.86      0.81       849\n",
            "     vmp00pf       0.00      0.00      0.00         5\n",
            "     vmp00pm       0.23      0.38      0.29        16\n",
            "     vmp00sf       0.29      0.47      0.36        19\n",
            "     vmp00sm       0.90      0.91      0.91       311\n",
            "     vmsi1p0       0.00      0.00      0.00         2\n",
            "     vmsi1s0       0.00      0.00      0.00         2\n",
            "     vmsi3p0       1.00      0.08      0.15        12\n",
            "     vmsi3s0       0.90      0.35      0.50        26\n",
            "     vmsp1p0       0.05      0.22      0.09         9\n",
            "     vmsp1s0       0.25      0.14      0.18         7\n",
            "     vmsp3p0       0.35      0.49      0.41        45\n",
            "     vmsp3s0       0.62      0.56      0.59        66\n",
            "     vsg0000       1.00      1.00      1.00         7\n",
            "     vsic1s0       1.00      1.00      1.00         1\n",
            "     vsic3p0       0.00      0.00      0.00         2\n",
            "     vsic3s0       1.00      1.00      1.00         8\n",
            "     vsif3s0       1.00      1.00      1.00        13\n",
            "     vsii3p0       1.00      1.00      1.00        13\n",
            "     vsii3s0       0.90      1.00      0.95        26\n",
            "     vsip1p0       0.25      1.00      0.40         1\n",
            "     vsip1s0       1.00      1.00      1.00         3\n",
            "     vsip2s0       0.00      0.00      0.00         2\n",
            "     vsip3p0       1.00      1.00      1.00        48\n",
            "     vsip3s0       1.00      1.00      1.00       190\n",
            "     vsis3p0       0.95      1.00      0.97        18\n",
            "     vsis3s0       1.00      1.00      1.00        39\n",
            "     vsn0000       1.00      1.00      1.00        35\n",
            "     vsp00sm       1.00      1.00      1.00        32\n",
            "     vssi3p0       0.00      0.00      0.00         1\n",
            "     vssi3s0       1.00      1.00      1.00         3\n",
            "     vssp3p0       1.00      1.00      1.00         5\n",
            "     vssp3s0       1.00      1.00      1.00        12\n",
            "\n",
            "   micro avg       0.89      0.89      0.89     38876\n",
            "   macro avg       0.68      0.63      0.64     38876\n",
            "weighted avg       0.91      0.89      0.90     38876\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "nrAAFx0XrWT1"
      },
      "cell_type": "markdown",
      "source": [
        "## PARTE 4  -  Testing"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "uvOz-IShFzRR"
      },
      "cell_type": "markdown",
      "source": [
        "### Creamos un pequeño Ejemplo"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "_WT1PtS_Qui0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "2b4924f5-440f-4d52-8378-9c0adc54155a"
      },
      "cell_type": "code",
      "source": [
        "test_samples = [\n",
        "    \"Correr es importante para mi .\".split(),\n",
        "    \"El hombre bajo corre bajo el puente con bajo índice de adrenalina .\".split()\n",
        "]\n",
        "print(test_samples)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['Correr', 'es', 'importante', 'para', 'mi', '.'], ['El', 'hombre', 'bajo', 'corre', 'bajo', 'el', 'puente', 'con', 'bajo', 'índice', 'de', 'adrenalina', '.']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "X5E7-zZdGCjY"
      },
      "cell_type": "markdown",
      "source": [
        "### Convertimos el texto en Una entrada para el Modelo"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "BApB6ScZ9jU8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "outputId": "cc225d1f-7182-4ab1-d327-b5cb265f4c63"
      },
      "cell_type": "code",
      "source": [
        "test_samples_X = []\n",
        "for s in test_samples:\n",
        "    s_int = []\n",
        "    for w in s:\n",
        "        try:\n",
        "            s_int.append(word2index[w.lower()])\n",
        "        except KeyError:\n",
        "            s_int.append(word2index['-OOV-'])\n",
        "    test_samples_X.append(s_int)\n",
        "\n",
        "test_samples_X = pad_sequences(test_samples_X, maxlen=MAX_LENGTH, padding='post')\n",
        "print(test_samples_X)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[10597 23818   494 20525  8354  5906     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0]\n",
            " [17992 11842  7909 11446  7909 17992   676 12946  7909  9723   483     1\n",
            "   5906     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "trNZCjTWGLp-"
      },
      "cell_type": "markdown",
      "source": [
        "### Se Ejecuta la predicion con la Entrada del modelo entrenado"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "OX6Bd2Rz9oha",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        },
        "outputId": "60f05bcd-7fe3-4fe2-f169-f95d48b386f7"
      },
      "cell_type": "code",
      "source": [
        "predictions = model.predict(test_samples_X)\n",
        "print(predictions, predictions.shape)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[[1.2200224e-03 1.0107079e-06 9.0371206e-05 ... 4.8912945e-08\n",
            "   9.2098540e-05 6.9522770e-04]\n",
            "  [2.2434401e-07 1.1772408e-08 3.6358599e-06 ... 9.1116352e-05\n",
            "   1.1758530e-06 6.5434751e-06]\n",
            "  [2.0470955e-07 5.5658183e-11 4.7138009e-08 ... 1.7761405e-09\n",
            "   9.2934505e-09 3.1560880e-08]\n",
            "  ...\n",
            "  [9.9996054e-01 3.1575270e-10 3.8673345e-09 ... 3.0470645e-18\n",
            "   2.6549731e-09 4.8045717e-10]\n",
            "  [9.9995184e-01 1.3445730e-09 8.4364320e-09 ... 1.8695157e-17\n",
            "   5.9764869e-09 1.0366676e-09]\n",
            "  [9.9994171e-01 4.0243622e-09 1.5845782e-08 ... 8.0142744e-17\n",
            "   1.1341243e-08 1.9487807e-09]]\n",
            "\n",
            " [[5.6681099e-08 1.4691852e-09 2.7641568e-07 ... 1.8747427e-08\n",
            "   2.2692079e-07 4.9413546e-07]\n",
            "  [2.0487100e-06 9.3668906e-10 3.0396404e-07 ... 2.0974106e-11\n",
            "   4.0484093e-07 4.6879055e-07]\n",
            "  [4.2412415e-05 4.1437236e-09 3.0354217e-06 ... 7.1194925e-11\n",
            "   1.2766928e-06 1.4211455e-06]\n",
            "  ...\n",
            "  [9.9996209e-01 2.7338987e-10 3.4309169e-09 ... 2.2988731e-18\n",
            "   2.4138549e-09 4.3863502e-10]\n",
            "  [9.9995410e-01 1.1673837e-09 7.5023614e-09 ... 1.4141462e-17\n",
            "   5.4472316e-09 9.4739427e-10]\n",
            "  [9.9994540e-01 3.5035024e-09 1.4124529e-08 ... 6.0776639e-17\n",
            "   1.0361574e-08 1.7826925e-09]]] (2, 149, 291)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "l-XS5z-NGiM-"
      },
      "cell_type": "markdown",
      "source": [
        "### Conversion de la Salida del Modelo a un lista de Indices de Tags"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "IgIutMjq92cp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "be1b6bc1-1783-47fd-e971-4a496ba89247"
      },
      "cell_type": "code",
      "source": [
        "#print(len(predictions))\n",
        "log_tokens = logits_to_tokens(predictions, {i: t for t, i in tag2index.items()})\n",
        "print(log_tokens)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['vmn0000', 'vsip3s0', 'aq0cs0', 'sps00', 'dp1css', 'Fp', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-'], ['da0ms0', 'ncms000', 'aq0ms0', 'vmip3s0', 'sps00', 'da0ms0', 'ncms000', 'sps00', 'sps00', 'ncms000', 'sps00', 'Z', 'Fp', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "VmWp09kyGrQC"
      },
      "cell_type": "markdown",
      "source": [
        "### Presentacion de los Resultados"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "wNMCM8_jSdCL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "127dade3-c5da-4163-fbe6-d68839d1fe02"
      },
      "cell_type": "code",
      "source": [
        "#!pip install tabulate\n",
        "from tabulate import tabulate\n",
        "\n",
        "heads1 = test_samples[0]\n",
        "body1 = [log_tokens[0][:len(test_samples[0])]]\n",
        "\n",
        "heads2 = test_samples[1]\n",
        "body2 = [log_tokens[1][:len(test_samples[1])]]\n",
        "\n",
        "print(tabulate(body1, headers=heads1))\n",
        "\n",
        "print (\"\\n\")\n",
        "\n",
        "print(tabulate(body2, headers=heads2))\n",
        "\n",
        "\n",
        "## postagging Freeling 4.1\n",
        "\n",
        "## El      hombre   bajo     corre    bajo  el      puente   con  bajo  índice   de  adrenalina  .\n",
        "## DA0MS0  NCMS000  AQ0MS00  VMIP3S0  SP    DA0MS0  NCMS000  SP   SP    NCMS000  SP  NCFS000     Fp\n",
        "\n",
        "\n",
        "## pos tagger Stanford NLP\n",
        "\n",
        "## El      hombre   bajo     corre    bajo  el      puente   con    bajo   índice  de    adrenalina  .\n",
        "## da0000  nc0s000  aq0000   vmip000  sp000 da0000  nc0s000  sp000  aq0000 nc0s000 sp000 nc0s000     fp"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Correr    es       importante    para    mi      .\n",
            "--------  -------  ------------  ------  ------  ---\n",
            "vmn0000   vsip3s0  aq0cs0        sps00   dp1css  Fp\n",
            "\n",
            "\n",
            "El      hombre    bajo    corre    bajo    el      puente    con    bajo    índice    de     adrenalina    .\n",
            "------  --------  ------  -------  ------  ------  --------  -----  ------  --------  -----  ------------  ---\n",
            "da0ms0  ncms000   aq0ms0  vmip3s0  sps00   da0ms0  ncms000   sps00  sps00   ncms000   sps00  Z             Fp\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "zEqVaw-HSPiu"
      },
      "cell_type": "markdown",
      "source": [
        "## PARTE 5  -  Mejorando la Precision y Exactitud del Modelo"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "1gR8kcV0GwFS"
      },
      "cell_type": "markdown",
      "source": [
        "### Definimos una clase que permita ignorar los Valores de Relleno"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "QwNvdZiE956Y",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras import backend as K\n",
        " \n",
        "def ignore_class_accuracy(to_ignore=0):\n",
        "    def ignore_accuracy(y_true, y_pred):\n",
        "        y_true_class = K.argmax(y_true, axis=-1)\n",
        "        y_pred_class = K.argmax(y_pred, axis=-1)\n",
        " \n",
        "        ignore_mask = K.cast(K.not_equal(y_pred_class, to_ignore), 'int32')\n",
        "        matches = K.cast(K.equal(y_true_class, y_pred_class), 'int32') * ignore_mask\n",
        "        accuracy = K.sum(matches) / K.maximum(K.sum(ignore_mask), 1)\n",
        "        return accuracy\n",
        "    return ignore_accuracy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "AxT3F3pHIGHk"
      },
      "cell_type": "markdown",
      "source": [
        "### Definimos nuevamente nuestro modelo, agregado la clase Creada"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "KO4DTAAE-BaS",
        "colab": {},
        "outputId": "4c4eddaa-d0d6-40d8-ef92-0b9417237268"
      },
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, LSTM, InputLayer, Bidirectional, TimeDistributed, Embedding, Activation\n",
        "from keras.optimizers import Adam\n",
        " \n",
        "\n",
        "model = Sequential()\n",
        "model.add(InputLayer(input_shape=(MAX_LENGTH, )))\n",
        "model.add(Embedding(len(word2index), 128))\n",
        "model.add(Bidirectional(LSTM(256, return_sequences=True)))\n",
        "model.add(TimeDistributed(Dense(len(tag2index))))\n",
        "model.add(Activation('softmax'))\n",
        " \n",
        "model.compile(loss='categorical_crossentropy', optimizer=Adam(0.001),  metrics=['accuracy', ignore_class_accuracy(0)]) \n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_5 (Embedding)      (None, 149, 128)          3135872   \n",
            "_________________________________________________________________\n",
            "bidirectional_5 (Bidirection (None, 149, 512)          788480    \n",
            "_________________________________________________________________\n",
            "time_distributed_5 (TimeDist (None, 149, 291)          149283    \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 149, 291)          0         \n",
            "=================================================================\n",
            "Total params: 4,073,635\n",
            "Trainable params: 4,073,635\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "Z8AiPXp8IVOu"
      },
      "cell_type": "markdown",
      "source": [
        "### Procedemos a Entrenar Nuevamente"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "CwgZVEIW-ECo",
        "colab": {},
        "outputId": "65d7b8b0-d485-4cd7-8af2-2aa4f0acc201"
      },
      "cell_type": "code",
      "source": [
        "model.fit(train_sentences_X, to_categorical(train_tags_y, len(tag2index)), batch_size=128, epochs=40, validation_split=0.2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 2894 samples, validate on 724 samples\n",
            "Epoch 1/40\n",
            "2894/2894 [==============================] - 13s 4ms/step - loss: 2.4904 - acc: 0.7510 - ignore_accuracy: 0.0131 - val_loss: 1.0565 - val_acc: 0.7849 - val_ignore_accuracy: 0.0000e+00\n",
            "Epoch 2/40\n",
            "2894/2894 [==============================] - 11s 4ms/step - loss: 0.9301 - acc: 0.7871 - ignore_accuracy: 0.0645 - val_loss: 0.8984 - val_acc: 0.7863 - val_ignore_accuracy: 0.2207\n",
            "Epoch 3/40\n",
            "2894/2894 [==============================] - 11s 4ms/step - loss: 0.8729 - acc: 0.8085 - ignore_accuracy: 0.1650 - val_loss: 0.8709 - val_acc: 0.8131 - val_ignore_accuracy: 0.1354\n",
            "Epoch 4/40\n",
            "2894/2894 [==============================] - 11s 4ms/step - loss: 0.8492 - acc: 0.8149 - ignore_accuracy: 0.1361 - val_loss: 0.8525 - val_acc: 0.8130 - val_ignore_accuracy: 0.1355\n",
            "Epoch 5/40\n",
            "2894/2894 [==============================] - 11s 4ms/step - loss: 0.8297 - acc: 0.8149 - ignore_accuracy: 0.1361 - val_loss: 0.8345 - val_acc: 0.8130 - val_ignore_accuracy: 0.1353\n",
            "Epoch 6/40\n",
            "2894/2894 [==============================] - 11s 4ms/step - loss: 0.8118 - acc: 0.8154 - ignore_accuracy: 0.1378 - val_loss: 0.8174 - val_acc: 0.8182 - val_ignore_accuracy: 0.1565\n",
            "Epoch 7/40\n",
            "2894/2894 [==============================] - 11s 4ms/step - loss: 0.7956 - acc: 0.8196 - ignore_accuracy: 0.1552 - val_loss: 0.8028 - val_acc: 0.8193 - val_ignore_accuracy: 0.1612\n",
            "Epoch 8/40\n",
            "2894/2894 [==============================] - 11s 4ms/step - loss: 0.7792 - acc: 0.8230 - ignore_accuracy: 0.1697 - val_loss: 0.7858 - val_acc: 0.8308 - val_ignore_accuracy: 0.2147\n",
            "Epoch 9/40\n",
            "2894/2894 [==============================] - 11s 4ms/step - loss: 0.7578 - acc: 0.8334 - ignore_accuracy: 0.2186 - val_loss: 0.7571 - val_acc: 0.8319 - val_ignore_accuracy: 0.2198\n",
            "Epoch 10/40\n",
            "2894/2894 [==============================] - 11s 4ms/step - loss: 0.7217 - acc: 0.8361 - ignore_accuracy: 0.2314 - val_loss: 0.7154 - val_acc: 0.8383 - val_ignore_accuracy: 0.2502\n",
            "Epoch 11/40\n",
            "2894/2894 [==============================] - 11s 4ms/step - loss: 0.6681 - acc: 0.8560 - ignore_accuracy: 0.3251 - val_loss: 0.6503 - val_acc: 0.8677 - val_ignore_accuracy: 0.3859\n",
            "Epoch 12/40\n",
            "2894/2894 [==============================] - 11s 4ms/step - loss: 0.6031 - acc: 0.8786 - ignore_accuracy: 0.4306 - val_loss: 0.5822 - val_acc: 0.8787 - val_ignore_accuracy: 0.4373\n",
            "Epoch 13/40\n",
            "2894/2894 [==============================] - 11s 4ms/step - loss: 0.5330 - acc: 0.8868 - ignore_accuracy: 0.4690 - val_loss: 0.5139 - val_acc: 0.8894 - val_ignore_accuracy: 0.4873\n",
            "Epoch 14/40\n",
            "2894/2894 [==============================] - 11s 4ms/step - loss: 0.4625 - acc: 0.8980 - ignore_accuracy: 0.5220 - val_loss: 0.4467 - val_acc: 0.9029 - val_ignore_accuracy: 0.5498\n",
            "Epoch 15/40\n",
            "2894/2894 [==============================] - 11s 4ms/step - loss: 0.3945 - acc: 0.9133 - ignore_accuracy: 0.5943 - val_loss: 0.3842 - val_acc: 0.9177 - val_ignore_accuracy: 0.6191\n",
            "Epoch 16/40\n",
            "2894/2894 [==============================] - 11s 4ms/step - loss: 0.3310 - acc: 0.9282 - ignore_accuracy: 0.6635 - val_loss: 0.3297 - val_acc: 0.9302 - val_ignore_accuracy: 0.6769\n",
            "Epoch 17/40\n",
            "2894/2894 [==============================] - 11s 4ms/step - loss: 0.2758 - acc: 0.9410 - ignore_accuracy: 0.7236 - val_loss: 0.2844 - val_acc: 0.9385 - val_ignore_accuracy: 0.7157\n",
            "Epoch 18/40\n",
            "2894/2894 [==============================] - 11s 4ms/step - loss: 0.2290 - acc: 0.9504 - ignore_accuracy: 0.7676 - val_loss: 0.2496 - val_acc: 0.9459 - val_ignore_accuracy: 0.7499\n",
            "Epoch 19/40\n",
            "2894/2894 [==============================] - 11s 4ms/step - loss: 0.1911 - acc: 0.9593 - ignore_accuracy: 0.8097 - val_loss: 0.2219 - val_acc: 0.9520 - val_ignore_accuracy: 0.7781\n",
            "Epoch 20/40\n",
            "2894/2894 [==============================] - 11s 4ms/step - loss: 0.1596 - acc: 0.9668 - ignore_accuracy: 0.8447 - val_loss: 0.2009 - val_acc: 0.9566 - val_ignore_accuracy: 0.7995\n",
            "Epoch 21/40\n",
            "2894/2894 [==============================] - 11s 4ms/step - loss: 0.1337 - acc: 0.9732 - ignore_accuracy: 0.8745 - val_loss: 0.1833 - val_acc: 0.9608 - val_ignore_accuracy: 0.8194\n",
            "Epoch 22/40\n",
            "2894/2894 [==============================] - 11s 4ms/step - loss: 0.1125 - acc: 0.9784 - ignore_accuracy: 0.8991 - val_loss: 0.1701 - val_acc: 0.9639 - val_ignore_accuracy: 0.8339\n",
            "Epoch 23/40\n",
            "2894/2894 [==============================] - 11s 4ms/step - loss: 0.0953 - acc: 0.9821 - ignore_accuracy: 0.9164 - val_loss: 0.1600 - val_acc: 0.9659 - val_ignore_accuracy: 0.8430\n",
            "Epoch 24/40\n",
            "2894/2894 [==============================] - 11s 4ms/step - loss: 0.0815 - acc: 0.9850 - ignore_accuracy: 0.9298 - val_loss: 0.1515 - val_acc: 0.9675 - val_ignore_accuracy: 0.8503\n",
            "Epoch 25/40\n",
            "2894/2894 [==============================] - 11s 4ms/step - loss: 0.0701 - acc: 0.9873 - ignore_accuracy: 0.9405 - val_loss: 0.1449 - val_acc: 0.9688 - val_ignore_accuracy: 0.8565\n",
            "Epoch 26/40\n",
            "2894/2894 [==============================] - 11s 4ms/step - loss: 0.0610 - acc: 0.9890 - ignore_accuracy: 0.9485 - val_loss: 0.1396 - val_acc: 0.9699 - val_ignore_accuracy: 0.8619\n",
            "Epoch 27/40\n",
            "2894/2894 [==============================] - 11s 4ms/step - loss: 0.0534 - acc: 0.9904 - ignore_accuracy: 0.9553 - val_loss: 0.1349 - val_acc: 0.9707 - val_ignore_accuracy: 0.8654\n",
            "Epoch 28/40\n",
            "2894/2894 [==============================] - 11s 4ms/step - loss: 0.0472 - acc: 0.9915 - ignore_accuracy: 0.9602 - val_loss: 0.1329 - val_acc: 0.9713 - val_ignore_accuracy: 0.8683\n",
            "Epoch 29/40\n",
            "2894/2894 [==============================] - 11s 4ms/step - loss: 0.0421 - acc: 0.9924 - ignore_accuracy: 0.9643 - val_loss: 0.1296 - val_acc: 0.9721 - val_ignore_accuracy: 0.8721\n",
            "Epoch 30/40\n",
            "2894/2894 [==============================] - 11s 4ms/step - loss: 0.0377 - acc: 0.9931 - ignore_accuracy: 0.9678 - val_loss: 0.1279 - val_acc: 0.9722 - val_ignore_accuracy: 0.8730\n",
            "Epoch 31/40\n",
            "2894/2894 [==============================] - 11s 4ms/step - loss: 0.0341 - acc: 0.9937 - ignore_accuracy: 0.9706 - val_loss: 0.1259 - val_acc: 0.9724 - val_ignore_accuracy: 0.8742\n",
            "Epoch 32/40\n",
            "2894/2894 [==============================] - 11s 4ms/step - loss: 0.0309 - acc: 0.9942 - ignore_accuracy: 0.9729 - val_loss: 0.1247 - val_acc: 0.9730 - val_ignore_accuracy: 0.8772\n",
            "Epoch 33/40\n",
            "2894/2894 [==============================] - 11s 4ms/step - loss: 0.0281 - acc: 0.9948 - ignore_accuracy: 0.9757 - val_loss: 0.1236 - val_acc: 0.9732 - val_ignore_accuracy: 0.8788\n",
            "Epoch 34/40\n",
            "2894/2894 [==============================] - 11s 4ms/step - loss: 0.0257 - acc: 0.9952 - ignore_accuracy: 0.9775 - val_loss: 0.1231 - val_acc: 0.9731 - val_ignore_accuracy: 0.8780\n",
            "Epoch 35/40\n",
            "2894/2894 [==============================] - 11s 4ms/step - loss: 0.0236 - acc: 0.9956 - ignore_accuracy: 0.9792 - val_loss: 0.1210 - val_acc: 0.9735 - val_ignore_accuracy: 0.8789\n",
            "Epoch 36/40\n",
            "2894/2894 [==============================] - 11s 4ms/step - loss: 0.0217 - acc: 0.9959 - ignore_accuracy: 0.9809 - val_loss: 0.1217 - val_acc: 0.9735 - val_ignore_accuracy: 0.8785\n",
            "Epoch 37/40\n",
            "2894/2894 [==============================] - 11s 4ms/step - loss: 0.0201 - acc: 0.9963 - ignore_accuracy: 0.9827 - val_loss: 0.1210 - val_acc: 0.9737 - val_ignore_accuracy: 0.8804\n",
            "Epoch 38/40\n",
            "2894/2894 [==============================] - 11s 4ms/step - loss: 0.0185 - acc: 0.9966 - ignore_accuracy: 0.9840 - val_loss: 0.1212 - val_acc: 0.9736 - val_ignore_accuracy: 0.8800\n",
            "Epoch 39/40\n",
            "2894/2894 [==============================] - 11s 4ms/step - loss: 0.0171 - acc: 0.9969 - ignore_accuracy: 0.9855 - val_loss: 0.1216 - val_acc: 0.9735 - val_ignore_accuracy: 0.8792\n",
            "Epoch 40/40\n",
            "2894/2894 [==============================] - 11s 4ms/step - loss: 0.0159 - acc: 0.9971 - ignore_accuracy: 0.9865 - val_loss: 0.1207 - val_acc: 0.9737 - val_ignore_accuracy: 0.8802\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f611615dc50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "LnExWbEmIa5U"
      },
      "cell_type": "markdown",
      "source": [
        "### Calculamos nuevamente la Precisión"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "FKOa73gRNMm7",
        "colab": {},
        "outputId": "8b1af35c-cd82-4661-a6b3-c08b762110f4"
      },
      "cell_type": "code",
      "source": [
        "scores2 = model.evaluate(test_sentences_X, to_categorical(test_tags_y, len(tag2index)))\n",
        "print(f\"{model.metrics_names[1]}: {scores2[1] * 100}\")   # acc: 99.09751977804825"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1206/1206 [==============================] - 5s 4ms/step\n",
            "acc: 97.29261903422784\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "ZzeCdasrIkuN"
      },
      "cell_type": "markdown",
      "source": [
        "### Relaizamos nuevamente el calculo de F1-score, recall, y precision"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "VbqNJa0pIvVT",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "Nri9gFnwIxcN"
      },
      "cell_type": "markdown",
      "source": [
        "### Realizamos nuevamente una prueba con el Ejemplo de Prueba"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "xruHro6L-LT2",
        "colab": {},
        "outputId": "74203fce-aee7-4e2e-ae06-d90ffa0dc3be"
      },
      "cell_type": "code",
      "source": [
        "predictions1 = model.predict(test_samples_X)\n",
        "log_tokens1  = logits_to_tokens(predictions1, {i: t for t, i in tag2index.items()})\n",
        "print(log_tokens1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['vmn0000', 'vsip3s0', 'aq0cs0', 'sps00', 'np0000l', 'Fp', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-'], ['da0ms0', 'ncms000', 'aq0cs0', 'vmip3s0', 'sps00', 'da0ms0', 'ncms000', 'sps00', 'sps00', 'ncms000', 'sps00', 'np0000l', 'Fp', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "VL9taLbrI641"
      },
      "cell_type": "markdown",
      "source": [
        "### Presentamos los Resultados"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "QeRx8eSThbuq",
        "colab": {},
        "outputId": "e77597cc-3b04-4367-80c1-418282147d13"
      },
      "cell_type": "code",
      "source": [
        "from tabulate import tabulate\n",
        "\n",
        "heads1 = test_samples[0]\n",
        "body1 = [log_tokens[0][:len(test_samples[0])]]\n",
        "\n",
        "heads2 = test_samples[1]\n",
        "body2 = [log_tokens[1][:len(test_samples[1])]]\n",
        "\n",
        "print(tabulate(body1, headers=heads1))\n",
        "\n",
        "print (\"\\n\")\n",
        "\n",
        "print(tabulate(body2, headers=heads2))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Correr    es       importante    para    mi      .\n",
            "--------  -------  ------------  ------  ------  ---\n",
            "vmn0000   vsip3s0  aq0cs0        sps00   dp1css  Fp\n",
            "\n",
            "\n",
            "El      hombre    bajo    corre    bajo    el      puente    con    bajo    índice    de     adrenalina    .\n",
            "------  --------  ------  -------  ------  ------  --------  -----  ------  --------  -----  ------------  ---\n",
            "da0ms0  ncms000   aq0ms0  vmip3s0  sps00   da0ms0  ncms000   sps00  sps00   ncms000   sps00  np0000l       Fp\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}