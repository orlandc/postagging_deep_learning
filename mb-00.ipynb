{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3nXS4RUQQugV"
   },
   "source": [
    "# Tutorial Part-of-Speech tagging  Con Deep Learning\n",
    "\n",
    "### En este tutorial, veremos cómo puede usar un modelo simple en Keras, para entrenar y evaluar una red neuronal artificial para problemas de clasificación de múltiples clases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WIheRrq2Quga"
   },
   "source": [
    "## PARTE 1  -  Pre-Procesamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lw10qukzQuge"
   },
   "outputs": [],
   "source": [
    "# Asegurar reproducibilidad\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "CUSTOM_SEED = 42\n",
    "np.random.seed(CUSTOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CxOcxDUmJcvL"
   },
   "source": [
    "### Descargamos el Corpus Ancora - Cess_esp del nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "NILevBJxQugr",
    "outputId": "b71b74d4-21a9-4a8e-b184-fcc2b0af12c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package cess_esp to /home/deep-\n",
      "[nltk_data]     learning/miniconda3/envs/tensorflow/lib/nltk_data...\n",
      "[nltk_data]   Package cess_esp is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('cess_esp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eqdUvUCEJjgc"
   },
   "source": [
    "### Extraemos las oraciones tageadas del Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ss3RHo4LQugx"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "from nltk.corpus import cess_esp\n",
    "\n",
    "tagged_sentences = cess_esp.tagged_sents()\n",
    "#print('a random sentence: \\n-> {}'.format(random.choice(sentences)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gCW_ENdLJudC"
   },
   "source": [
    "### Extraemos los datos de la cantidad de oraciones a ser usadas y un ejemplo de una oracion presente en el corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "colab_type": "code",
    "id": "2clQUNdtQug4",
    "outputId": "43ba74e5-5ad6-49da-a84f-288a8e04a64f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('El', 'da0ms0'), ('grupo', 'ncms000'), ('estatal', 'aq0cs0'), ('Electricité_de_France', 'np00000'), ('-Fpa-', 'Fpa'), ('EDF', 'np00000'), ('-Fpt-', 'Fpt'), ('anunció', 'vmis3s0'), ('hoy', 'rg'), (',', 'Fc'), ('jueves', 'W'), (',', 'Fc'), ('la', 'da0fs0'), ('compra', 'ncfs000'), ('del', 'spcms'), ('51_por_ciento', 'Zp'), ('de', 'sps00'), ('la', 'da0fs0'), ('empresa', 'ncfs000'), ('mexicana', 'aq0fs0'), ('Electricidad_Águila_de_Altamira', 'np00000'), ('-Fpa-', 'Fpa'), ('EAA', 'np00000'), ('-Fpt-', 'Fpt'), (',', 'Fc'), ('creada', 'aq0fsp'), ('por', 'sps00'), ('el', 'da0ms0'), ('japonés', 'aq0ms0'), ('Mitsubishi_Corporation', 'np00000'), ('para', 'sps00'), ('poner_en_marcha', 'vmn0000'), ('una', 'di0fs0'), ('central', 'ncfs000'), ('de', 'sps00'), ('gas', 'ncms000'), ('de', 'sps00'), ('495', 'Z'), ('megavatios', 'ncmp000'), ('.', 'Fp')]\n",
      "Tagged sentences:  6030\n",
      "Tagged words: 192685\n"
     ]
    }
   ],
   "source": [
    "print(tagged_sentences[0])\n",
    "print(\"Tagged sentences: \", len(tagged_sentences))\n",
    "print(\"Tagged words:\", len(cess_esp.tagged_words()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "i_aFjuCQKG1O"
   },
   "source": [
    "### Se procede a Dividir en una lista de Oraciones dividida en lista de palabras y cada palabra con un correspondiente tag en un alista diferente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "516a_v5vQuhC"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    " \n",
    "sentences, tagss =[], [] \n",
    "for tagged_sentence in tagged_sentences:\n",
    "    sentence, tags = zip(*tagged_sentence)\n",
    "    sentences.append(np.array(sentence))\n",
    "    tagss.append(np.array(tags))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UN_E4ePpKhvy"
   },
   "source": [
    "### Imprimimos una posicion de la lista como ejemplo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "colab_type": "code",
    "id": "l6uGGSqZQuhM",
    "outputId": "bb432132-d363-46c9-e07c-e24c4e90520a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['EDF' 'tiene' 'previsto' 'invertir' '194' 'millones' 'de' 'euros' '-Fpa-'\n",
      " '186' 'millones' 'de' 'dólares' '-Fpt-' 'en' 'la' 'central' 'de'\n",
      " 'Río_Bravo' ',' 'con' 'una' 'potencia' 'de' '495' 'megavatios' ',' 'y'\n",
      " '134' 'millones' 'de' 'euros' '-Fpa-' '28' 'millones' 'de' 'dólares'\n",
      " '-Fpt-' 'en' 'Saltillo' ',' 'que' 'como' 'la' 'primera' 'funcionará'\n",
      " 'con' 'gas' 'natural' 'y' 'cuya' 'potencia' 'prevista' 'es' 'de' '247'\n",
      " 'megavatios' '.']\n",
      "['np00000' 'vmip3s0' 'aq0msp' 'vmn0000' 'Z' 'ncmp000' 'sps00' 'Zm' 'Fpa'\n",
      " 'Z' 'ncmp000' 'sps00' 'Zm' 'Fpt' 'sps00' 'da0fs0' 'ncfs000' 'sps00'\n",
      " 'np00000' 'Fc' 'sps00' 'di0fs0' 'ncfs000' 'sps00' 'Z' 'ncmp000' 'Fc' 'cc'\n",
      " 'Z' 'ncmp000' 'sps00' 'Zm' 'Fpa' 'Z' 'ncmp000' 'sps00' 'Zm' 'Fpt' 'sps00'\n",
      " 'np00000' 'Fc' 'pr0cn000' 'cs' 'da0fs0' 'ao0fs0' 'vmif3s0' 'sps00'\n",
      " 'ncms000' 'aq0cs0' 'cc' 'pr0fs000' 'ncfs000' 'aq0fsp' 'vsip3s0' 'sps00'\n",
      " 'Z' 'ncmp000' 'Fp']\n"
     ]
    }
   ],
   "source": [
    "print(sentences[5])\n",
    "print(tagss[5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WFQrAblFQuhT"
   },
   "source": [
    "### Dividimos el corpus de la siguiente manera, Utilizamos aproximadamente el 60% de las oraciones etiquetadas para el entrenamiento, el 20% como conjunto de validación y el 20% para evaluar nuestro modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZtLulrEOQuhU"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    " \n",
    "(training_sentences, \n",
    " test_sentences, \n",
    " training_tags, \n",
    " test_tags) = train_test_split(sentences, tagss, test_size=0.2)\n",
    "\n",
    "(train_sentences, \n",
    " eval_sentences, \n",
    " train_tags, \n",
    " eval_tags) = train_test_split(training_sentences, training_tags, test_size=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_Mk0scnsK1OE"
   },
   "source": [
    "### Imprimimos los tamaños de las listas que nos indicaran el tamaño de filas de las matrices con las que estaremos trabajando"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 697
    },
    "colab_type": "code",
    "id": "7HkjbP_IQuhZ",
    "outputId": "70489eac-d99d-4728-b481-2d3bd2faa7e9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_sentences:4824\n",
      "train_sentences: 3618\n",
      "test_sentences: 1206\n",
      "eval_sentences: 1206\n",
      "\n",
      "['*' 'El' 'Madrid' 'precisa' 'que' 'el' 'Deportivo' 'gane' 'la' 'Liga' ','\n",
      " 'porque' 'los' 'gallegos' 'no' 'son' 'considerados' 'unos' 'herederos'\n",
      " ',' 'sino' 'unos' 'entrometidos' 'que' 'se' 'supone' 'temporales' ','\n",
      " 'que' 'pertenecen' 'a' 'la' 'actualidad' 'más' 'rabiosa' 'y' 'no' 'a'\n",
      " 'la' 'historia' 'más' 'enrabietada' '.']\n",
      "['El' 'técnico' 'barcelonista' 'ha' 'asegurado' 'que' 'la' 'visita' 'de'\n",
      " 'Gaspart' 'ha' 'contribuido' 'a' '\"' 'sumar' '\"' ',' 'y' '*0*' 'ha'\n",
      " 'argumentado' 'que' 'el' 'encuentro' 'con' 'el' 'presidente' 'significa'\n",
      " 'que' 'en' 'el' 'Barcelona' '\"' 'todos' 'van' 'en' 'la' 'misma'\n",
      " 'dirección' '\"' '.']\n",
      "['Lo_suyo' ',' 'lo' 'de' 'las' 'ratas' ',' 'no' 'es' 'la' 'carroña' 'pura'\n",
      " 'y' 'dura' 'sino' 'la' 'vida' 'regalada' ',' 'el' 'eterno' 'banquete'\n",
      " 'de' 'sobras' 'y' 'residuos' ',' 'el' 'festín' 'organizado' 'a' 'la'\n",
      " 'sobra' 'de' 'la' 'abundancia' 'y' 'el' 'hartazgo' '.']\n",
      "\n",
      "training_tags:4824\n",
      "train_tags: 3618\n",
      "test_tags: 1206\n",
      "eval_tags: 1206\n",
      "\n",
      "['Fz' 'da0ms0' 'np0000l' 'vmip3s0' 'cs' 'da0ms0' 'np0000o' 'vmsp3s0'\n",
      " 'da0fs0' 'np0000a' 'Fc' 'cs' 'da0mp0' 'ncmp000' 'rn' 'vsip3p0' 'vmp00pm'\n",
      " 'di0mp0' 'ncmp000' 'Fc' 'cc' 'di0mp0' 'ncmp000' 'pr0cn000' 'p0000000'\n",
      " 'vmip3s0' 'aq0cp0' 'Fc' 'pr0cn000' 'vmip3p0' 'sps00' 'da0fs0' 'ncfs000'\n",
      " 'rg' 'aq0fs0' 'cc' 'rn' 'sps00' 'da0fs0' 'ncfs000' 'rg' 'aq0fsp' 'Fp']\n",
      "['da0ms0' 'ncms000' 'aq0cs0' 'vaip3s0' 'vmp00sm' 'cs' 'da0fs0' 'ncfs000'\n",
      " 'sps00' 'np00000' 'vaip3s0' 'vmp00sm' 'sps00' 'Fe' 'vmn0000' 'Fe' 'Fc'\n",
      " 'cc' 'sn.e-SUJ' 'vaip3s0' 'vmp00sm' 'cs' 'da0ms0' 'ncms000' 'sps00'\n",
      " 'da0ms0' 'ncms000' 'vmip3s0' 'cs' 'sps00' 'da0ms0' 'np00000' 'Fe'\n",
      " 'pi0mp000' 'vmip3p0' 'sps00' 'da0fs0' 'di0fs0' 'ncfs000' 'Fe' 'Fp']\n",
      "['px3ns000' 'Fc' 'da0ns0' 'sps00' 'da0fp0' 'ncfp000' 'Fc' 'rn' 'vsip3s0'\n",
      " 'da0fs0' 'ncfs000' 'aq0fs0' 'cc' 'aq0fs0' 'cc' 'da0fs0' 'ncfs000'\n",
      " 'aq0fsp' 'Fc' 'da0ms0' 'aq0ms0' 'ncms000' 'sps00' 'ncfp000' 'cc'\n",
      " 'ncmp000' 'Fc' 'da0ms0' 'ncms000' 'aq0msp' 'sps00' 'da0fs0' 'ncfs000'\n",
      " 'sps00' 'da0fs0' 'ncfs000' 'cc' 'da0ms0' 'ncms000' 'Fp']\n"
     ]
    }
   ],
   "source": [
    "print(\"training_sentences:\" + str(len(training_sentences)))\n",
    "print(\"train_sentences: \" + str(len(train_sentences)))\n",
    "print(\"test_sentences: \" + str(len(test_sentences)))\n",
    "print(\"eval_sentences: \" + str(len(eval_sentences)) + \"\\n\")\n",
    "\n",
    "print(train_sentences[0])\n",
    "print(test_sentences[0])\n",
    "print(eval_sentences[0])\n",
    "\n",
    "print(\"\\ntraining_tags:\" + str(len(training_sentences)))\n",
    "print(\"train_tags: \" + str(len(train_tags)))\n",
    "print(\"test_tags: \" + str(len(test_tags)))\n",
    "print(\"eval_tags: \" + str(len(eval_tags)) + \"\\n\")\n",
    "\n",
    "print(train_tags[0])\n",
    "print(test_tags[0])\n",
    "print(eval_tags[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Jd-i6q85Quho"
   },
   "source": [
    "### Ahora creamos una array con todas las palabras y los tags presentes en el corpus, adicionalmente se crea un diccionario que contiene las palabras unicas y los tags unicos de tal forma que no se repitan y que contienen un indice o llave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "qdCNulCoQuhr",
    "outputId": "a9895d28-f6b4-4a22-9b60-1c397fac3301"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24499\n",
      "291\n"
     ]
    }
   ],
   "source": [
    "words, tagsss = set([]), set([])\n",
    " \n",
    "for s in (train_sentences + eval_sentences + test_sentences):\n",
    "    for w in s:\n",
    "        words.add(w.lower())\n",
    "\n",
    "for ts in (train_tags + eval_tags + test_tags):\n",
    "    for t in ts:\n",
    "        tagsss.add(t)\n",
    "\n",
    "word2index = {w: i + 2 for i, w in enumerate(list(words))}\n",
    "word2index['-PAD-'] = 0  # The special value used for padding\n",
    "word2index['-OOV-'] = 1  # The special value used for OOVs\n",
    " \n",
    "tag2index = {t: i + 2 for i, t in enumerate(list(tagsss))}\n",
    "tag2index['-PAD-'] = 0  # The special value used to padding\n",
    "tag2index['-OOV-'] = 1  # The special value used to padding\n",
    "\n",
    "print (len(word2index))\n",
    "print (len(tag2index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VEA9Ek-GOYOn"
   },
   "source": [
    "### Ahora procedemos a transformar cada uno de los conjuntos de oraciones y tags en vectores numericos, modificando la palabra o tag en un Valor numerico que corresponde a una llave en el diccionario de palbras o tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "69eec13kQuh2"
   },
   "outputs": [],
   "source": [
    "train_sentences_X, eval_sentences_X, test_sentences_X, train_tags_y, eval_tags_y, test_tags_y = [], [], [], [], [], []\n",
    "\n",
    "for s in train_sentences:\n",
    "    s_int = []\n",
    "    for w in s:\n",
    "        try:\n",
    "            s_int.append(word2index[w.lower()])\n",
    "        except KeyError:\n",
    "            s_int.append(word2index['-OOV-'])\n",
    " \n",
    "    train_sentences_X.append(s_int)\n",
    "\n",
    "for s in eval_sentences:\n",
    "    s_int = []\n",
    "    for w in s:\n",
    "        try:\n",
    "            s_int.append(word2index[w.lower()])\n",
    "        except KeyError:\n",
    "            s_int.append(word2index['-OOV-'])\n",
    " \n",
    "    eval_sentences_X.append(s_int)\n",
    "\n",
    "for s in test_sentences:\n",
    "    s_int = []\n",
    "    for w in s:\n",
    "        try:\n",
    "            s_int.append(word2index[w.lower()])\n",
    "        except KeyError:\n",
    "            s_int.append(word2index['-OOV-'])\n",
    " \n",
    "    test_sentences_X.append(s_int)\n",
    "\n",
    "for s in train_tags:\n",
    "    s_int = []\n",
    "    for w in s:\n",
    "        try:\n",
    "            s_int.append(tag2index[w])\n",
    "        except KeyError:\n",
    "            s_int.append(tag2index['-OOV-'])\n",
    "            \n",
    "    train_tags_y.append(s_int)\n",
    "\n",
    "for s in eval_tags:\n",
    "    s_int = []\n",
    "    for w in s:\n",
    "        try:\n",
    "            s_int.append(tag2index[w])\n",
    "        except KeyError:\n",
    "            s_int.append(tag2index['-OOV-'])\n",
    "            \n",
    "    eval_tags_y.append(s_int)\n",
    "\n",
    "for s in test_tags:\n",
    "    s_int = []\n",
    "    for w in s:\n",
    "        try:\n",
    "            s_int.append(tag2index[w])\n",
    "        except KeyError:\n",
    "            s_int.append(tag2index['-OOV-'])\n",
    "            \n",
    "    test_tags_y.append(s_int)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "d_lXW1mBPNkf"
   },
   "source": [
    "### Se imprime la longitud de las matrices y una muesta de cada una de las matrices creadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 292
    },
    "colab_type": "code",
    "id": "Y5A4d_dzQuh6",
    "outputId": "a3d2808b-4ec4-4b5f-e469-eed38caeb48d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Longitudes de las Matrices:\n",
      "3618\n",
      "1206\n",
      "1206\n",
      "3618\n",
      "1206\n",
      "1206\n",
      "\n",
      "Muestra de Datos presentes en las Matrices con las transformaciones:\n",
      "[12388, 10282, 21331, 22506, 11318, 10282, 6690, 12903, 3339, 10218, 9807, 4081, 1175, 724, 10112, 10681, 1924, 17314, 3260, 9807, 21238, 17314, 7110, 11318, 11650, 19352, 18149, 9807, 11318, 6908, 1905, 3339, 10812, 14810, 15276, 12739, 10112, 1905, 3339, 21116, 14810, 17520, 12889]\n",
      "[7620, 9807, 14831, 17148, 18669, 7634, 9807, 10112, 21890, 3339, 14056, 6424, 12739, 1026, 21238, 3339, 15202, 17933, 9807, 10282, 13037, 6674, 17148, 1356, 12739, 4675, 9807, 10282, 4774, 22976, 1905, 3339, 16888, 17148, 3339, 9781, 12739, 10282, 7169, 12889]\n",
      "[10282, 12142, 19092, 4110, 23302, 11318, 3339, 4599, 17148, 189, 4110, 1073, 1905, 17188, 6641, 17188, 9807, 12739, 8372, 4110, 17458, 11318, 10282, 10615, 22163, 10282, 6275, 17479, 11318, 19426, 10282, 11608, 17188, 5214, 10889, 19426, 3339, 23555, 11965, 17188, 12889]\n",
      "[230, 205, 251, 4, 166, 205, 214, 189, 267, 227, 133, 166, 113, 187, 274, 275, 63, 254, 187, 133, 22, 254, 187, 26, 164, 4, 181, 133, 26, 74, 114, 267, 7, 76, 199, 22, 274, 114, 267, 7, 76, 280, 282]\n",
      "[78, 133, 3, 114, 186, 161, 133, 274, 101, 267, 7, 199, 22, 199, 22, 267, 7, 280, 133, 205, 271, 190, 114, 161, 22, 187, 133, 205, 190, 21, 114, 267, 7, 114, 267, 7, 22, 205, 190, 282]\n",
      "[205, 190, 84, 264, 32, 166, 267, 7, 114, 68, 264, 32, 114, 185, 269, 185, 133, 22, 132, 264, 32, 166, 205, 190, 114, 205, 190, 4, 166, 114, 205, 68, 185, 171, 74, 114, 267, 127, 7, 185, 282]\n"
     ]
    }
   ],
   "source": [
    "print(\"Longitudes de las Matrices:\")\n",
    "print(len(train_sentences_X))\n",
    "print(len(eval_sentences_X))\n",
    "print(len(test_sentences_X))\n",
    "print(len(train_tags_y))\n",
    "print(len(eval_tags_y))\n",
    "print(len(test_tags_y))\n",
    "\n",
    "print(\"\\nMuestra de Datos presentes en las Matrices con las transformaciones:\")\n",
    "\n",
    "print(train_sentences_X[0])\n",
    "print(eval_sentences_X[0])\n",
    "print(test_sentences_X[0])\n",
    "print(train_tags_y[0])\n",
    "print(eval_tags_y[0])\n",
    "print(test_tags_y[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kWLspkzfQ513"
   },
   "source": [
    "### Se calcula cual es la oracion que mayor cantidad de Palabras contiene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Gif6KsESQuh_",
    "outputId": "be988786-883f-4a50-af89-78ae8696c26e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "149\n"
     ]
    }
   ],
   "source": [
    "MAX_LENGTH1 = len(max(train_sentences_X, key=len))\n",
    "MAX_LENGTH2 = len(max(eval_sentences_X, key=len))\n",
    "MAX_LENGTH3 = len(max(test_sentences_X, key=len))\n",
    "\n",
    "l = [MAX_LENGTH1, MAX_LENGTH2, MAX_LENGTH3]\n",
    "MAX_LENGTH = max(l)\n",
    "\n",
    "print(MAX_LENGTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "e4ffWaDqRA1_"
   },
   "source": [
    "### Se procede a Normalizar las matrices para que todas contengan el mismo numero de columans, con la longitud maxima de palabras encontradas anteriormente, esto se logra agregando ceros a la derecha en las posiciones que hacen falta en el vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1139
    },
    "colab_type": "code",
    "id": "mn7iuMIOQuiI",
    "outputId": "323f249f-48e1-4b9a-c945-497a47fcb0f7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12388 10282 21331 22506 11318 10282  6690 12903  3339 10218  9807  4081\n",
      "  1175   724 10112 10681  1924 17314  3260  9807 21238 17314  7110 11318\n",
      " 11650 19352 18149  9807 11318  6908  1905  3339 10812 14810 15276 12739\n",
      " 10112  1905  3339 21116 14810 17520 12889     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0]\n",
      "[ 7620  9807 14831 17148 18669  7634  9807 10112 21890  3339 14056  6424\n",
      " 12739  1026 21238  3339 15202 17933  9807 10282 13037  6674 17148  1356\n",
      " 12739  4675  9807 10282  4774 22976  1905  3339 16888 17148  3339  9781\n",
      " 12739 10282  7169 12889     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0]\n",
      "[10282 12142 19092  4110 23302 11318  3339  4599 17148   189  4110  1073\n",
      "  1905 17188  6641 17188  9807 12739  8372  4110 17458 11318 10282 10615\n",
      " 22163 10282  6275 17479 11318 19426 10282 11608 17188  5214 10889 19426\n",
      "  3339 23555 11965 17188 12889     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0]\n",
      "[230 205 251   4 166 205 214 189 267 227 133 166 113 187 274 275  63 254\n",
      " 187 133  22 254 187  26 164   4 181 133  26  74 114 267   7  76 199  22\n",
      " 274 114 267   7  76 280 282   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0]\n",
      "[ 78 133   3 114 186 161 133 274 101 267   7 199  22 199  22 267   7 280\n",
      " 133 205 271 190 114 161  22 187 133 205 190  21 114 267   7 114 267   7\n",
      "  22 205 190 282   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0]\n",
      "[205 190  84 264  32 166 267   7 114  68 264  32 114 185 269 185 133  22\n",
      " 132 264  32 166 205 190 114 205 190   4 166 114 205  68 185 171  74 114\n",
      " 267 127   7 185 282   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0]\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    " \n",
    "train_sentences_X = pad_sequences(train_sentences_X, maxlen=MAX_LENGTH, padding='post')\n",
    "eval_sentences_X = pad_sequences(eval_sentences_X, maxlen=MAX_LENGTH, padding='post')\n",
    "test_sentences_X = pad_sequences(test_sentences_X, maxlen=MAX_LENGTH, padding='post')\n",
    "train_tags_y = pad_sequences(train_tags_y, maxlen=MAX_LENGTH, padding='post')\n",
    "eval_tags_y = pad_sequences(eval_tags_y, maxlen=MAX_LENGTH, padding='post')\n",
    "test_tags_y = pad_sequences(test_tags_y, maxlen=MAX_LENGTH, padding='post')\n",
    " \n",
    "print(train_sentences_X[0])\n",
    "print(eval_sentences_X[0])\n",
    "print(test_sentences_X[0])\n",
    "print(train_tags_y[0])\n",
    "print(eval_tags_y[0])\n",
    "print(test_tags_y[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "elkKsVbBNrYO"
   },
   "source": [
    "### Definimos la funcion con la cual categorizaremos los tags y los covertiremos un vector One-hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qGw5_dPX5xc0"
   },
   "outputs": [],
   "source": [
    "def to_categorical(sequences, categories):\n",
    "    cat_sequences = []\n",
    "    for s in sequences:\n",
    "        cats = []\n",
    "        for item in s:\n",
    "            cats.append(np.zeros(categories))\n",
    "            cats[-1][item] = 1.0\n",
    "        cat_sequences.append(cats)\n",
    "    return np.array(cat_sequences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GOmqn-5ZNg23"
   },
   "source": [
    "### Desarrollamos una prueba de la categorisacion de los tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "lepVNGK5bgc1",
    "outputId": "4ee4647c-0b91-4fb4-8676-1bdf1c52ea30"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "cat_train_tags_y = to_categorical(train_tags_y, len(tag2index))\n",
    "print(cat_train_tags_y[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9-_gAQ7qrWTQ"
   },
   "source": [
    "## PARTE 2  -  Entrenamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "odDOhtO4NZDd"
   },
   "source": [
    "### Definimos el Modelo Base con el cual se procedera a desarrollar la fase de Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 272
    },
    "colab_type": "code",
    "id": "x31rRt8PQuiW",
    "outputId": "90e66266-fb83-4408-ad95-11e3ffeeea98"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'MAX_LENGTH' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-4ea8a23f85b3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mInputLayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMAX_LENGTH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEmbedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword2index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBidirectional\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLSTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_sequences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'MAX_LENGTH' is not defined"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, InputLayer, Bidirectional, TimeDistributed, Embedding, Activation\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import multi_gpu_model\n",
    "\n",
    "model = Sequential()\n",
    "model.add(InputLayer(input_shape=(MAX_LENGTH, )))\n",
    "model.add(Embedding(len(word2index), 128))\n",
    "model.add(Bidirectional(LSTM(256, return_sequences=True)))\n",
    "model.add(TimeDistributed(Dense(len(tag2index))))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "parallel_model = multi_gpu_model(model, gpus=2)\n",
    "parallel_model.compile(loss='categorical_crossentropy', optimizer=Adam(0.001), metrics=['accuracy'])\n",
    " \n",
    "model.summary()\n",
    "parallel_model.summary()\n",
    "\n",
    "plot_model(model, to_file='../Plot/model-mb00.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4XghotI4NG9G"
   },
   "source": [
    "### Se dedarrolla el entrenamiento del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 680
    },
    "colab_type": "code",
    "id": "C0gOhZznbg6V",
    "outputId": "29cf358f-43dd-448e-c1bb-9cb4e12250d3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3618 samples, validate on 1206 samples\n",
      "Epoch 1/40\n",
      "3618/3618 [==============================] - 25s 7ms/step - loss: 2.1316 - acc: 0.7658 - val_loss: 0.9309 - val_acc: 0.8106\n",
      "Epoch 2/40\n",
      "3618/3618 [==============================] - 22s 6ms/step - loss: 0.8910 - acc: 0.7980 - val_loss: 0.8745 - val_acc: 0.8128\n",
      "Epoch 3/40\n",
      "3618/3618 [==============================] - 22s 6ms/step - loss: 0.8527 - acc: 0.8146 - val_loss: 0.8503 - val_acc: 0.8127\n",
      "Epoch 4/40\n",
      "3618/3618 [==============================] - 22s 6ms/step - loss: 0.8304 - acc: 0.8145 - val_loss: 0.8329 - val_acc: 0.8129\n",
      "Epoch 5/40\n",
      "3618/3618 [==============================] - 22s 6ms/step - loss: 0.8099 - acc: 0.8166 - val_loss: 0.8100 - val_acc: 0.8191\n",
      "Epoch 6/40\n",
      "3618/3618 [==============================] - 22s 6ms/step - loss: 0.7907 - acc: 0.8210 - val_loss: 0.7879 - val_acc: 0.8196\n",
      "Epoch 7/40\n",
      "3618/3618 [==============================] - 22s 6ms/step - loss: 0.7665 - acc: 0.8291 - val_loss: 0.7607 - val_acc: 0.8322\n",
      "Epoch 8/40\n",
      "3618/3618 [==============================] - 22s 6ms/step - loss: 0.7246 - acc: 0.8362 - val_loss: 0.6997 - val_acc: 0.8405\n",
      "Epoch 9/40\n",
      "3618/3618 [==============================] - 22s 6ms/step - loss: 0.6432 - acc: 0.8618 - val_loss: 0.6015 - val_acc: 0.8776\n",
      "Epoch 10/40\n",
      "3618/3618 [==============================] - 22s 6ms/step - loss: 0.5405 - acc: 0.8873 - val_loss: 0.4994 - val_acc: 0.8935\n",
      "Epoch 11/40\n",
      "3618/3618 [==============================] - 22s 6ms/step - loss: 0.4418 - acc: 0.9036 - val_loss: 0.4109 - val_acc: 0.9117\n",
      "Epoch 12/40\n",
      "3618/3618 [==============================] - 22s 6ms/step - loss: 0.3564 - acc: 0.9232 - val_loss: 0.3364 - val_acc: 0.9283\n",
      "Epoch 13/40\n",
      "3618/3618 [==============================] - 22s 6ms/step - loss: 0.2844 - acc: 0.9392 - val_loss: 0.2772 - val_acc: 0.9400\n",
      "Epoch 14/40\n",
      "3618/3618 [==============================] - 22s 6ms/step - loss: 0.2265 - acc: 0.9519 - val_loss: 0.2342 - val_acc: 0.9489\n",
      "Epoch 15/40\n",
      "3618/3618 [==============================] - 22s 6ms/step - loss: 0.1810 - acc: 0.9624 - val_loss: 0.2006 - val_acc: 0.9566\n",
      "Epoch 16/40\n",
      "3618/3618 [==============================] - 23s 6ms/step - loss: 0.1449 - acc: 0.9712 - val_loss: 0.1753 - val_acc: 0.9618\n",
      "Epoch 17/40\n",
      "3618/3618 [==============================] - 22s 6ms/step - loss: 0.1165 - acc: 0.9775 - val_loss: 0.1569 - val_acc: 0.9658\n",
      "Epoch 18/40\n",
      "3618/3618 [==============================] - 22s 6ms/step - loss: 0.0948 - acc: 0.9821 - val_loss: 0.1426 - val_acc: 0.9688\n",
      "Epoch 19/40\n",
      "3618/3618 [==============================] - 22s 6ms/step - loss: 0.0780 - acc: 0.9857 - val_loss: 0.1323 - val_acc: 0.9709\n",
      "Epoch 20/40\n",
      "3618/3618 [==============================] - 23s 6ms/step - loss: 0.0650 - acc: 0.9884 - val_loss: 0.1247 - val_acc: 0.9721\n",
      "Epoch 21/40\n",
      "3618/3618 [==============================] - 22s 6ms/step - loss: 0.0550 - acc: 0.9902 - val_loss: 0.1179 - val_acc: 0.9735\n",
      "Epoch 22/40\n",
      "3618/3618 [==============================] - 23s 6ms/step - loss: 0.0471 - acc: 0.9916 - val_loss: 0.1137 - val_acc: 0.9743\n",
      "Epoch 23/40\n",
      "3618/3618 [==============================] - 22s 6ms/step - loss: 0.0407 - acc: 0.9927 - val_loss: 0.1112 - val_acc: 0.9752\n",
      "Epoch 24/40\n",
      "3618/3618 [==============================] - 23s 6ms/step - loss: 0.0356 - acc: 0.9936 - val_loss: 0.1080 - val_acc: 0.9757\n",
      "Epoch 25/40\n",
      "3618/3618 [==============================] - 22s 6ms/step - loss: 0.0312 - acc: 0.9942 - val_loss: 0.1061 - val_acc: 0.9762\n",
      "Epoch 26/40\n",
      "3618/3618 [==============================] - 23s 6ms/step - loss: 0.0278 - acc: 0.9947 - val_loss: 0.1048 - val_acc: 0.9764\n",
      "Epoch 27/40\n",
      "3618/3618 [==============================] - 22s 6ms/step - loss: 0.0250 - acc: 0.9952 - val_loss: 0.1047 - val_acc: 0.9767\n",
      "Epoch 28/40\n",
      "3618/3618 [==============================] - 22s 6ms/step - loss: 0.0225 - acc: 0.9957 - val_loss: 0.1033 - val_acc: 0.9768\n",
      "Epoch 29/40\n",
      "3618/3618 [==============================] - 24s 6ms/step - loss: 0.0203 - acc: 0.9961 - val_loss: 0.1029 - val_acc: 0.9768\n",
      "Epoch 30/40\n",
      "3618/3618 [==============================] - 23s 6ms/step - loss: 0.0185 - acc: 0.9965 - val_loss: 0.1023 - val_acc: 0.9770\n",
      "Epoch 31/40\n",
      "3618/3618 [==============================] - 22s 6ms/step - loss: 0.0169 - acc: 0.9968 - val_loss: 0.1014 - val_acc: 0.9772\n",
      "Epoch 32/40\n",
      "3618/3618 [==============================] - 23s 6ms/step - loss: 0.0153 - acc: 0.9971 - val_loss: 0.1018 - val_acc: 0.9773\n",
      "Epoch 33/40\n",
      "3618/3618 [==============================] - 22s 6ms/step - loss: 0.0139 - acc: 0.9975 - val_loss: 0.1019 - val_acc: 0.9771\n",
      "Epoch 34/40\n",
      "3618/3618 [==============================] - 22s 6ms/step - loss: 0.0129 - acc: 0.9977 - val_loss: 0.1013 - val_acc: 0.9771\n",
      "Epoch 35/40\n",
      "3618/3618 [==============================] - 23s 6ms/step - loss: 0.0117 - acc: 0.9979 - val_loss: 0.1021 - val_acc: 0.9772\n",
      "Epoch 36/40\n",
      "3618/3618 [==============================] - 22s 6ms/step - loss: 0.0107 - acc: 0.9981 - val_loss: 0.1027 - val_acc: 0.9773\n",
      "Epoch 37/40\n",
      "3618/3618 [==============================] - 22s 6ms/step - loss: 0.0098 - acc: 0.9983 - val_loss: 0.1023 - val_acc: 0.9772\n",
      "Epoch 38/40\n",
      "3618/3618 [==============================] - 23s 6ms/step - loss: 0.0090 - acc: 0.9985 - val_loss: 0.1055 - val_acc: 0.9769\n",
      "Epoch 39/40\n",
      "3618/3618 [==============================] - 23s 6ms/step - loss: 0.0083 - acc: 0.9986 - val_loss: 0.1046 - val_acc: 0.9770\n",
      "Epoch 40/40\n",
      "3618/3618 [==============================] - 23s 6ms/step - loss: 0.0076 - acc: 0.9988 - val_loss: 0.1056 - val_acc: 0.9770\n"
     ]
    }
   ],
   "source": [
    "model_hist = parallel_model.fit(train_sentences_X, to_categorical(train_tags_y, len(tag2index)),\n",
    "                       validation_data=(eval_sentences_X, to_categorical(eval_tags_y, len(tag2index))),\n",
    "                       batch_size=128, \n",
    "                       epochs=40,\n",
    "                       validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9hTDgQb2rWTa"
   },
   "source": [
    "## PARTE 3  -  Evaluación del Modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LdSkk8mzM1KN"
   },
   "source": [
    "### Evaluamos el modelo y calculamos el valor de precision con respecto a los datos de prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "cD-YI5Fgb3Kt",
    "outputId": "4a3aa89a-6081-4bb9-a299-8ac9cdbac680"
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "You must compile a model before training/testing. Use `model.compile(optimizer, loss)`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-b00e2bbe9d6e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_sentences_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_categorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_tags_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtag2index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{model.metrics_names[1]}: {scores[1] * 100}\"\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m# acc: 97.38805993872496\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps)\u001b[0m\n\u001b[1;32m   1100\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1101\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1102\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Prepare inputs, delegate logic to `test_loop`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_uses_dynamic_learning_phase\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    679\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 681\u001b[0;31m                 raise RuntimeError('You must compile a model before '\n\u001b[0m\u001b[1;32m    682\u001b[0m                                    \u001b[0;34m'training/testing. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    683\u001b[0m                                    'Use `model.compile(optimizer, loss)`.')\n",
      "\u001b[0;31mRuntimeError\u001b[0m: You must compile a model before training/testing. Use `model.compile(optimizer, loss)`."
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(test_sentences_X, to_categorical(test_tags_y, len(tag2index)))\n",
    "print(f\"{model.metrics_names[1]}: {scores[1] * 100}\")   # acc: 97.38805993872496"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sAhkgtWHQuij"
   },
   "source": [
    "### Definimos la funcion que nos servira para graficar el comportamiento del modelo en cada epoca del entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JaBUkInNQuik"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_model_performance(train_loss, train_acc, train_val_loss, train_val_acc):\n",
    "    \"\"\" Plot model loss and accuracy through epochs. \"\"\"\n",
    "    blue= '#34495E'\n",
    "    green = '#2ECC71'\n",
    "    orange = '#E23B13'\n",
    "    # plot model loss\n",
    "    fig, (ax1, ax2) = plt.subplots(2, figsize=(10, 8))\n",
    "    ax1.plot(range(1, len(train_loss) + 1), train_loss, blue, linewidth=5, label='training')\n",
    "    ax1.plot(range(1, len(train_val_loss) + 1), train_val_loss, green, linewidth=5, label='validation')\n",
    "    ax1.set_xlabel('# epoch')\n",
    "    ax1.set_ylabel('loss')\n",
    "    ax1.tick_params('y')\n",
    "    ax1.legend(loc='upper right', shadow=False)\n",
    "    ax1.set_title('Model loss through #epochs', color=orange, fontweight='bold')\n",
    "    # plot model accuracy\n",
    "    ax2.plot(range(1, len(train_acc) + 1), train_acc, blue, linewidth=5, label='training')\n",
    "    ax2.plot(range(1, len(train_val_acc) + 1), train_val_acc, green, linewidth=5, label='validation')\n",
    "    ax2.set_xlabel('# epoch')\n",
    "    ax2.set_ylabel('accuracy')\n",
    "    ax2.tick_params('y')\n",
    "    ax2.legend(loc='lower right', shadow=False)\n",
    "    ax2.set_title('Model accuracy through #epochs', color=orange, fontweight='bold')\n",
    "    \n",
    "    fig.savefig('../Plot/training-mb-01.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TxQh1AtuQuis"
   },
   "source": [
    "### Procedemos a Graficar el comportamiento del Entrenamiento, tanto del conjunto de entrenamiento como el de validación con respecto a la cantidad de epocas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 512
    },
    "colab_type": "code",
    "id": "Gs5f3U1nQuit",
    "outputId": "86aa7473-9513-40a7-b098-807da720926b"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_model_performance(\n",
    "    train_loss=model_hist.history.get('loss', []),\n",
    "    train_acc=model_hist.history.get('acc', []),\n",
    "    train_val_loss=model_hist.history.get('val_loss', []),\n",
    "    train_val_acc=model_hist.history.get('val_acc', [])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pqiuy8q4GYjF"
   },
   "source": [
    "### Función que Permite convertir Indices en Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YJ6GaLot9yZR"
   },
   "outputs": [],
   "source": [
    "def logits_to_tokens(sequences, index):\n",
    "    token_sequences = []\n",
    "    for categorical_sequence in sequences:\n",
    "        token_sequence = []\n",
    "        for categorical in categorical_sequence:\n",
    "            token_sequence.append(index[np.argmax(categorical)])\n",
    " \n",
    "        token_sequences.append(token_sequence)\n",
    " \n",
    "    return token_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "W-1GH3ZYuLc-"
   },
   "source": [
    "### Hacemos la prediccion sobre el conjunto de pruebas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "6HgbDqqsR4a7",
    "outputId": "8ad10360-dafc-4a75-eeda-b4ed4c5c4e34"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['da0ms0', 'ncms000', 'aq0cs0', 'vaip3s0', 'vmp00sm', 'cs', 'da0fs0', 'ncfs000', 'sps00', 'np00000', 'vaip3s0', 'vmp00sm', 'sps00', 'Fe', 'vmn0000', 'Fe', 'Fc', 'cc', 'sn.e-SUJ', 'vaip3s0', 'vmp00sm', 'cs', 'da0ms0', 'ncms000', 'sps00', 'da0ms0', 'ncms000', 'vmip3s0', 'cs', 'sps00', 'da0ms0', 'np0000l', 'Fe', 'di0mp0', 'vmip3p0', 'sps00', 'da0fs0', 'di0fs0', 'ncfs000', 'Fe', 'Fp', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "prediction = parallel_model.predict(test_sentences_X)\n",
    "log_tokens = logits_to_tokens(prediction, {i: t for t, i in tag2index.items()})\n",
    "\n",
    "print(log_tokens[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uT6IIQXrQuix"
   },
   "source": [
    "### Hallamos los valores de F1 score, recall, precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1142
    },
    "colab_type": "code",
    "id": "GqTuNxppFNu-",
    "outputId": "cc280315-02e5-4be6-d4b3-eccfae561837"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/deep-learning/miniconda3/envs/tensorflow/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/deep-learning/miniconda3/envs/tensorflow/lib/python3.6/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "classification_report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       -PAD-       0.00      0.00      0.00         0\n",
      "         Faa       1.00      1.00      1.00         2\n",
      "         Fat       1.00      0.80      0.89         5\n",
      "          Fc       1.00      1.00      1.00      2291\n",
      "          Fd       1.00      1.00      1.00        87\n",
      "          Fe       1.00      1.00      1.00       631\n",
      "          Fg       0.99      1.00      1.00       226\n",
      "          Fh       0.00      0.00      0.00         3\n",
      "         Fia       1.00      1.00      1.00         6\n",
      "         Fit       1.00      1.00      1.00        19\n",
      "          Fp       1.00      1.00      1.00      1178\n",
      "         Fpa       1.00      1.00      1.00       156\n",
      "         Fpt       0.99      0.99      0.99       160\n",
      "          Fs       1.00      1.00      1.00        13\n",
      "          Fx       0.95      1.00      0.98        41\n",
      "          Fz       0.00      0.00      0.00         2\n",
      "           W       0.97      0.61      0.75       194\n",
      "           Z       0.90      0.54      0.67       320\n",
      "          Zm       0.91      0.89      0.90        35\n",
      "          Zp       0.78      0.40      0.53        45\n",
      "      ao0fp0       1.00      1.00      1.00        17\n",
      "      ao0fs0       0.97      0.95      0.96        66\n",
      "      ao0mp0       1.00      0.91      0.95        23\n",
      "      ao0ms0       0.92      0.95      0.93        59\n",
      "     aq00000       0.00      0.00      0.00         2\n",
      "      aq0cn0       0.05      0.25      0.08         4\n",
      "      aq0cp0       0.88      0.69      0.77       228\n",
      "      aq0cs0       0.62      0.87      0.72       590\n",
      "      aq0fp0       0.72      0.63      0.67       128\n",
      "      aq0fpp       0.25      0.54      0.35        52\n",
      "      aq0fs0       0.88      0.69      0.78       355\n",
      "      aq0fsp       0.58      0.46      0.51       140\n",
      "      aq0mp0       0.73      0.61      0.67       202\n",
      "      aq0mpp       0.51      0.48      0.49        96\n",
      "      aq0ms0       0.81      0.74      0.77       491\n",
      "      aq0msp       0.84      0.59      0.69       222\n",
      "          cc       0.98      0.99      0.99      1222\n",
      "          cs       0.89      0.87      0.88       927\n",
      "      da0fp0       0.98      1.00      0.99       374\n",
      "      da0fs0       0.99      1.00      0.99      1324\n",
      "      da0mp0       1.00      1.00      1.00       637\n",
      "      da0ms0       1.00      1.00      1.00      1275\n",
      "      da0ns0       0.91      0.95      0.93       110\n",
      "      dd0cp0       1.00      0.50      0.67         2\n",
      "      dd0cs0       1.00      0.75      0.86         4\n",
      "      dd0fp0       0.95      1.00      0.97        18\n",
      "      dd0fs0       0.97      1.00      0.99        67\n",
      "      dd0mp0       0.91      1.00      0.95        30\n",
      "      dd0ms0       0.94      1.00      0.97       101\n",
      "      di0cp0       0.50      0.80      0.62         5\n",
      "      di0cs0       0.96      0.85      0.90        26\n",
      "      di0fp0       0.97      0.94      0.96        71\n",
      "      di0fs0       0.98      0.99      0.98       335\n",
      "      di0mp0       0.92      0.96      0.94       112\n",
      "      di0ms0       0.96      0.95      0.96       482\n",
      "      dn0cp0       0.94      0.97      0.96       149\n",
      "      dn0cs0       0.00      0.00      0.00         1\n",
      "      dn0fp0       1.00      0.75      0.86         4\n",
      "      dn0fs0       0.00      0.00      0.00         2\n",
      "      dn0mp0       1.00      0.40      0.57         5\n",
      "      dn0ms0       0.33      0.11      0.17         9\n",
      "      dp1cps       0.00      0.00      0.00         1\n",
      "      dp1css       1.00      1.00      1.00         8\n",
      "      dp1fpp       0.00      0.00      0.00         1\n",
      "      dp1fsp       1.00      0.83      0.91         6\n",
      "      dp1mpp       1.00      0.86      0.92         7\n",
      "      dp1msp       1.00      0.88      0.93         8\n",
      "      dp2css       1.00      0.67      0.80         3\n",
      "      dp3cp0       1.00      1.00      1.00       107\n",
      "      dp3cs0       1.00      1.00      1.00       275\n",
      "      dp3fs0       0.00      0.00      0.00         1\n",
      "      dt0cn0       0.00      0.00      0.00         3\n",
      "           i       0.02      0.25      0.04         4\n",
      "     nc00000       0.08      0.23      0.11        26\n",
      "     nccn000       0.00      0.00      0.00         5\n",
      "     nccp000       0.70      0.84      0.77       103\n",
      "     nccs000       0.85      0.75      0.80       146\n",
      "     ncfn000       1.00      0.60      0.75        15\n",
      "     ncfp000       0.93      0.85      0.89       788\n",
      "     ncfs000       0.89      0.92      0.91      2132\n",
      "     ncmn000       0.93      0.54      0.68        24\n",
      "     ncmp000       0.93      0.83      0.88      1166\n",
      "     ncms000       0.86      0.92      0.89      2365\n",
      "     np00000       0.03      0.22      0.05        51\n",
      "     np0000a       0.61      0.34      0.44       202\n",
      "     np0000l       0.52      0.71      0.60       412\n",
      "     np0000o       0.70      0.63      0.66       656\n",
      "     np0000p       0.75      0.55      0.64       720\n",
      "    p0000000       0.61      0.61      0.61       193\n",
      "    p010p000       1.00      0.50      0.67         2\n",
      "    p010s000       1.00      0.67      0.80         3\n",
      "    p020s000       1.00      1.00      1.00         1\n",
      "    p0300000       0.64      0.67      0.66       217\n",
      "    pd0fp000       1.00      0.67      0.80         3\n",
      "    pd0fs000       1.00      0.60      0.75         5\n",
      "    pd0mp000       1.00      0.50      0.67         6\n",
      "    pd0ms000       1.00      0.50      0.67         8\n",
      "    pd0ns000       1.00      1.00      1.00        22\n",
      "    pi0cp000       1.00      1.00      1.00         2\n",
      "    pi0cs000       1.00      0.97      0.99        40\n",
      "    pi0fp000       0.67      0.57      0.62         7\n",
      "    pi0fs000       0.62      0.73      0.67        11\n",
      "    pi0mp000       0.82      0.77      0.79        35\n",
      "    pi0ms000       0.83      0.74      0.78        54\n",
      "    pn0cp000       0.83      0.74      0.78        27\n",
      "    pn0mp000       0.60      1.00      0.75         3\n",
      "    pn0ms000       0.33      0.50      0.40         2\n",
      "    pp1cp000       0.96      1.00      0.98        27\n",
      "    pp1cs000       0.93      0.96      0.95        27\n",
      "    pp1csn00       1.00      1.00      1.00        16\n",
      "    pp1cso00       1.00      1.00      1.00         5\n",
      "    pp1mp000       1.00      1.00      1.00         9\n",
      "    pp2cs000       1.00      1.00      1.00         4\n",
      "    pp2cs00p       0.60      0.75      0.67         4\n",
      "    pp2csn00       0.00      0.00      0.00         2\n",
      "    pp2cso00       0.00      0.00      0.00         1\n",
      "    pp3cn000       0.00      0.00      0.00        10\n",
      "    pp3cna00       0.00      0.00      0.00         2\n",
      "    pp3cno00       1.00      1.00      1.00         5\n",
      "    pp3cpa00       0.00      0.00      0.00         2\n",
      "    pp3cpd00       0.85      1.00      0.92        11\n",
      "    pp3csa00       0.00      0.00      0.00         1\n",
      "    pp3csd00       0.98      0.97      0.98        63\n",
      "    pp3fp000       1.00      1.00      1.00         6\n",
      "    pp3fpa00       1.00      0.30      0.46        10\n",
      "    pp3fs000       0.92      0.85      0.88        13\n",
      "    pp3fsa00       0.83      0.29      0.43        17\n",
      "    pp3mp000       1.00      1.00      1.00        26\n",
      "    pp3mpa00       1.00      0.25      0.40         4\n",
      "    pp3ms000       1.00      1.00      1.00        23\n",
      "    pp3msa00       0.80      0.73      0.76        33\n",
      "    pp3ns000       1.00      1.00      1.00        15\n",
      "    pr000000       0.88      0.85      0.86        26\n",
      "    pr0cn000       0.86      0.87      0.87       616\n",
      "    pr0cp000       1.00      0.90      0.95        10\n",
      "    pr0cs000       0.94      1.00      0.97        32\n",
      "    pr0fp000       0.00      0.00      0.00         1\n",
      "    pr0fs000       0.83      1.00      0.91         5\n",
      "    pr0mp000       0.00      0.00      0.00         0\n",
      "    pr0ms000       1.00      0.33      0.50         3\n",
      "    pt000000       1.00      0.58      0.74        12\n",
      "    pt0cp000       0.00      0.00      0.00         1\n",
      "    pt0cs000       0.84      0.89      0.86        18\n",
      "    pt0mp000       0.00      0.00      0.00         2\n",
      "    px1fs0p0       0.00      0.00      0.00         1\n",
      "    px3ns000       0.00      0.00      0.00         1\n",
      "          rg       0.89      0.89      0.89      1208\n",
      "          rn       0.97      0.99      0.98       265\n",
      "      sn-SUJ       0.00      0.00      0.00         1\n",
      "        sn.e       0.00      0.00      0.00         4\n",
      "    sn.e-SUJ       0.99      1.00      0.99       818\n",
      " sn.e.1n-SUJ       0.00      0.00      0.00         6\n",
      "       spcms       1.00      0.99      0.99       692\n",
      "       sps00       0.99      0.99      0.99      5056\n",
      "     vaic3p0       0.00      0.00      0.00         1\n",
      "     vaic3s0       1.00      1.00      1.00         4\n",
      "     vaif1p0       0.00      0.00      0.00         1\n",
      "     vaif3s0       1.00      1.00      1.00         3\n",
      "     vaii1s0       0.00      0.00      0.00         1\n",
      "     vaii3p0       1.00      1.00      1.00        13\n",
      "     vaii3s0       0.98      1.00      0.99        41\n",
      "     vaip1p0       1.00      1.00      1.00         8\n",
      "     vaip1s0       1.00      1.00      1.00         9\n",
      "     vaip3p0       1.00      1.00      1.00        48\n",
      "     vaip3s0       1.00      0.99      1.00       185\n",
      "     vais3s0       1.00      0.20      0.33         5\n",
      "     van0000       0.95      1.00      0.98        21\n",
      "     vap00sm       1.00      1.00      1.00         1\n",
      "     vasi1p0       0.00      0.00      0.00         1\n",
      "     vasi3p0       1.00      0.50      0.67         2\n",
      "     vasi3s0       1.00      0.91      0.95        11\n",
      "     vasp1s0       0.00      0.00      0.00         1\n",
      "     vasp3p0       1.00      1.00      1.00         1\n",
      "     vasp3s0       0.89      1.00      0.94         8\n",
      "     vmg0000       0.29      0.42      0.34        92\n",
      "     vmic1p0       0.00      0.00      0.00         2\n",
      "     vmic1s0       0.00      0.00      0.00         0\n",
      "     vmic3p0       0.56      0.45      0.50        11\n",
      "     vmic3s0       0.91      0.70      0.79        30\n",
      "     vmif1p0       0.08      0.71      0.14         7\n",
      "     vmif1s0       0.50      0.33      0.40         3\n",
      "     vmif2s0       0.00      0.00      0.00         1\n",
      "     vmif3p0       1.00      0.50      0.67        40\n",
      "     vmif3s0       0.96      0.58      0.72       114\n",
      "     vmii1p0       0.05      0.44      0.10         9\n",
      "     vmii1s0       0.00      0.00      0.00         7\n",
      "     vmii3p0       0.93      0.39      0.55        67\n",
      "     vmii3s0       0.94      0.62      0.75       143\n",
      "     vmip1p0       1.00      0.67      0.80        60\n",
      "     vmip1s0       1.00      0.75      0.86        60\n",
      "     vmip2s0       0.19      0.50      0.27         6\n",
      "     vmip3p0       0.95      0.67      0.79       279\n",
      "     vmip3s0       0.90      0.88      0.89       599\n",
      "     vmis1p0       0.00      0.00      0.00         5\n",
      "     vmis1s0       0.08      0.25      0.12        12\n",
      "     vmis2s0       0.00      0.00      0.00         0\n",
      "     vmis3p0       0.98      0.55      0.71       148\n",
      "     vmis3s0       0.99      0.86      0.92       606\n",
      "     vmm02s0       0.00      0.00      0.00         3\n",
      "     vmm03p0       0.00      0.00      0.00         1\n",
      "     vmm03s0       0.00      0.00      0.00         7\n",
      "     vmn0000       0.80      0.84      0.82       849\n",
      "     vmp00pf       0.00      0.00      0.00         5\n",
      "     vmp00pm       0.10      0.31      0.15        16\n",
      "     vmp00sf       0.31      0.26      0.29        19\n",
      "     vmp00sm       0.90      0.89      0.89       311\n",
      "     vmsi1p0       0.00      0.00      0.00         2\n",
      "     vmsi1s0       0.00      0.00      0.00         2\n",
      "     vmsi3p0       0.07      0.25      0.11        12\n",
      "     vmsi3s0       0.82      0.35      0.49        26\n",
      "     vmsp1p0       0.67      0.22      0.33         9\n",
      "     vmsp1s0       0.50      0.14      0.22         7\n",
      "     vmsp3p0       0.67      0.36      0.46        45\n",
      "     vmsp3s0       0.54      0.55      0.54        66\n",
      "     vsg0000       1.00      1.00      1.00         7\n",
      "     vsic1s0       1.00      1.00      1.00         1\n",
      "     vsic3p0       0.00      0.00      0.00         2\n",
      "     vsic3s0       1.00      0.88      0.93         8\n",
      "     vsif3s0       1.00      1.00      1.00        13\n",
      "     vsii3p0       1.00      1.00      1.00        13\n",
      "     vsii3s0       0.93      1.00      0.96        26\n",
      "     vsip1p0       0.25      1.00      0.40         1\n",
      "     vsip1s0       1.00      1.00      1.00         3\n",
      "     vsip2s0       0.00      0.00      0.00         2\n",
      "     vsip3p0       1.00      1.00      1.00        48\n",
      "     vsip3s0       1.00      1.00      1.00       190\n",
      "     vsis3p0       0.95      1.00      0.97        18\n",
      "     vsis3s0       1.00      0.97      0.99        39\n",
      "     vsn0000       1.00      1.00      1.00        35\n",
      "     vsp00sm       1.00      1.00      1.00        32\n",
      "     vssi3p0       0.00      0.00      0.00         1\n",
      "     vssi3s0       1.00      0.67      0.80         3\n",
      "     vssp3p0       0.80      0.80      0.80         5\n",
      "     vssp3s0       1.00      1.00      1.00        12\n",
      "\n",
      "   micro avg       0.89      0.89      0.89     38876\n",
      "   macro avg       0.68      0.63      0.63     38876\n",
      "weighted avg       0.91      0.89      0.89     38876\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "results = pd.DataFrame(columns=['Expected', 'Predicted'])\n",
    "k = 0\n",
    "for i, lista_etiquetas_oracion in enumerate(test_tags):\n",
    "    for j, etiquetas in enumerate(lista_etiquetas_oracion):\n",
    "        k = k + 1\n",
    "        results.loc[k, 'Expected'] = etiquetas\n",
    "        results.loc[k, 'Predicted'] = log_tokens[i][j]\n",
    "\n",
    "# print(results)\n",
    "\n",
    "\n",
    "print('\\nclassification_report:\\n', classification_report(results['Expected'], results['Predicted']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nrAAFx0XrWT1"
   },
   "source": [
    "## PARTE 4  -  Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uvOz-IShFzRR"
   },
   "source": [
    "### Creamos un pequeño Ejemplo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_WT1PtS_Qui0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Correr', 'es', 'importante', 'para', 'mi', '.'], ['El', 'hombre', 'bajo', 'corre', 'bajo', 'el', 'puente', 'con', 'bajo', 'índice', 'de', 'adrenalina', '.']]\n"
     ]
    }
   ],
   "source": [
    "test_samples = [\n",
    "    \"Correr es importante para mi .\".split(),\n",
    "    \"El hombre bajo corre bajo el puente con bajo índice de adrenalina .\".split()\n",
    "]\n",
    "print(test_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "X5E7-zZdGCjY"
   },
   "source": [
    "### Convertimos el texto en Una entrada para el Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BApB6ScZ9jU8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2101 21890  4288  3407  8678 12889     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0]\n",
      " [10282  7752 20760 15480 20760 10282 12735 22163 20760 13703 17148     1\n",
      "  12889     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0]]\n"
     ]
    }
   ],
   "source": [
    "test_samples_X = []\n",
    "for s in test_samples:\n",
    "    s_int = []\n",
    "    for w in s:\n",
    "        try:\n",
    "            s_int.append(word2index[w.lower()])\n",
    "        except KeyError:\n",
    "            s_int.append(word2index['-OOV-'])\n",
    "    test_samples_X.append(s_int)\n",
    "\n",
    "test_samples_X = pad_sequences(test_samples_X, maxlen=MAX_LENGTH, padding='post')\n",
    "print(test_samples_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "trNZCjTWGLp-"
   },
   "source": [
    "### Se Ejecuta la predicion con la Entrada del modelo entrenado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OX6Bd2Rz9oha"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[6.60489593e-03 2.32876864e-05 7.53883069e-05 ... 1.74496658e-04\n",
      "   6.81499660e-05 1.46916613e-03]\n",
      "  [1.38316478e-08 6.62090827e-09 2.64082864e-05 ... 1.58525282e-08\n",
      "   1.35877553e-05 7.85295029e-08]\n",
      "  [6.36615482e-07 9.62019464e-10 6.23345472e-11 ... 2.46470108e-07\n",
      "   9.21214667e-12 2.30671318e-07]\n",
      "  ...\n",
      "  [9.99961734e-01 2.14040075e-09 8.48489545e-09 ... 3.50119848e-07\n",
      "   3.13173532e-09 1.44569967e-07]\n",
      "  [9.99943256e-01 6.81541712e-09 2.35762059e-08 ... 4.75925788e-07\n",
      "   7.92064814e-09 1.95562407e-07]\n",
      "  [9.99924183e-01 1.52773225e-08 5.10444593e-08 ... 6.08962807e-07\n",
      "   1.56394044e-08 2.26320893e-07]]\n",
      "\n",
      " [[1.66161882e-07 4.45222170e-09 3.19109148e-07 ... 2.53024227e-05\n",
      "   5.53881421e-07 2.76849689e-11]\n",
      "  [1.08880636e-06 1.25175281e-09 2.07711661e-08 ... 4.40670419e-07\n",
      "   7.84492471e-08 9.00594023e-06]\n",
      "  [2.12770265e-05 3.00470617e-08 3.43905504e-09 ... 3.22037784e-04\n",
      "   1.42620475e-08 8.57690949e-08]\n",
      "  ...\n",
      "  [9.99961734e-01 2.14042117e-09 8.48489545e-09 ... 3.50123202e-07\n",
      "   3.13175907e-09 1.44571203e-07]\n",
      "  [9.99943256e-01 6.81548151e-09 2.35762059e-08 ... 4.75930335e-07\n",
      "   7.92070765e-09 1.95564283e-07]\n",
      "  [9.99924183e-01 1.52774398e-08 5.10444593e-08 ... 6.08968094e-07\n",
      "   1.56394933e-08 2.26322840e-07]]] (2, 149, 291)\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(test_samples_X)\n",
    "print(predictions, predictions.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "l-XS5z-NGiM-"
   },
   "source": [
    "### Conversion de la Salida del Modelo a un lista de Indices de Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IgIutMjq92cp"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['vmn0000', 'vsip3s0', 'aq0cs0', 'sps00', 'dp1css', 'Fp', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-'], ['da0ms0', 'ncms000', 'aq0ms0', 'vmip3s0', 'sps00', 'da0ms0', 'ncms000', 'sps00', 'sps00', 'ncms000', 'sps00', 'np0000l', 'Fp', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-']]\n"
     ]
    }
   ],
   "source": [
    "#print(len(predictions))\n",
    "log_tokens = logits_to_tokens(predictions, {i: t for t, i in tag2index.items()})\n",
    "print(log_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VmWp09kyGrQC"
   },
   "source": [
    "### Presentacion de los Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wNMCM8_jSdCL"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correr    es       importante    para    mi      .\n",
      "--------  -------  ------------  ------  ------  ---\n",
      "vmn0000   vsip3s0  aq0cs0        sps00   dp1css  Fp\n",
      "\n",
      "\n",
      "El      hombre    bajo    corre    bajo    el      puente    con    bajo    índice    de     adrenalina    .\n",
      "------  --------  ------  -------  ------  ------  --------  -----  ------  --------  -----  ------------  ---\n",
      "da0ms0  ncms000   aq0ms0  vmip3s0  sps00   da0ms0  ncms000   sps00  sps00   ncms000   sps00  np0000l       Fp\n"
     ]
    }
   ],
   "source": [
    "#!pip install tabulate\n",
    "from tabulate import tabulate\n",
    "\n",
    "heads1 = test_samples[0]\n",
    "body1 = [log_tokens[0][:len(test_samples[0])]]\n",
    "\n",
    "heads2 = test_samples[1]\n",
    "body2 = [log_tokens[1][:len(test_samples[1])]]\n",
    "\n",
    "print(tabulate(body1, headers=heads1))\n",
    "\n",
    "print (\"\\n\")\n",
    "\n",
    "print(tabulate(body2, headers=heads2))\n",
    "\n",
    "'''\n",
    "## postagging Freeling 4.1\n",
    "\n",
    "El      hombre   bajo     corre    bajo  el      puente   con  bajo  índice   de  adrenalina  .\n",
    "DA0MS0  NCMS000  AQ0MS00  VMIP3S0  SP    DA0MS0  NCMS000  SP   SP    NCMS000  SP  NCFS000     Fp\n",
    "\n",
    "\n",
    "## pos tagger Stanford NLP\n",
    "\n",
    "El      hombre   bajo     corre    bajo  el      puente   con    bajo   índice  de    adrenalina  .\n",
    "da0000  nc0s000  aq0000   vmip000  sp000 da0000  nc0s000  sp000  aq0000 nc0s000 sp000 nc0s000     fp\n",
    "Rub1k0n$$\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zEqVaw-HSPiu"
   },
   "source": [
    "## PARTE 5  -  Mejorando la Precision y Exactitud del Modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1gR8kcV0GwFS"
   },
   "source": [
    "### Definimos una clase que permita ignorar los Valores de Relleno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QwNvdZiE956Y"
   },
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    " \n",
    "def ignore_class_accuracy(to_ignore=0):\n",
    "    def ignore_accuracy(y_true, y_pred):\n",
    "        y_true_class = K.argmax(y_true, axis=-1)\n",
    "        y_pred_class = K.argmax(y_pred, axis=-1)\n",
    " \n",
    "        ignore_mask = K.cast(K.not_equal(y_pred_class, to_ignore), 'int32')\n",
    "        matches = K.cast(K.equal(y_true_class, y_pred_class), 'int32') * ignore_mask\n",
    "        accuracy = K.sum(matches) / K.maximum(K.sum(ignore_mask), 1)\n",
    "        return accuracy\n",
    "    return ignore_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AxT3F3pHIGHk"
   },
   "source": [
    "### Definimos nuevamente nuestro modelo, agregado la clase Creada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KO4DTAAE-BaS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_5 (Embedding)      (None, 149, 128)          3135872   \n",
      "_________________________________________________________________\n",
      "bidirectional_5 (Bidirection (None, 149, 512)          788480    \n",
      "_________________________________________________________________\n",
      "time_distributed_5 (TimeDist (None, 149, 291)          149283    \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 149, 291)          0         \n",
      "=================================================================\n",
      "Total params: 4,073,635\n",
      "Trainable params: 4,073,635\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, InputLayer, Bidirectional, TimeDistributed, Embedding, Activation\n",
    "from keras.optimizers import Adam\n",
    " \n",
    "\n",
    "model = Sequential()\n",
    "model.add(InputLayer(input_shape=(MAX_LENGTH, )))\n",
    "model.add(Embedding(len(word2index), 128))\n",
    "model.add(Bidirectional(LSTM(256, return_sequences=True)))\n",
    "model.add(TimeDistributed(Dense(len(tag2index))))\n",
    "model.add(Activation('softmax'))\n",
    " \n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(0.001),  metrics=['accuracy', ignore_class_accuracy(0)]) \n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Z8AiPXp8IVOu"
   },
   "source": [
    "### Procedemos a Entrenar Nuevamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CwgZVEIW-ECo"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2894 samples, validate on 724 samples\n",
      "Epoch 1/40\n",
      "2894/2894 [==============================] - 13s 4ms/step - loss: 2.4904 - acc: 0.7510 - ignore_accuracy: 0.0131 - val_loss: 1.0565 - val_acc: 0.7849 - val_ignore_accuracy: 0.0000e+00\n",
      "Epoch 2/40\n",
      "2894/2894 [==============================] - 11s 4ms/step - loss: 0.9301 - acc: 0.7871 - ignore_accuracy: 0.0645 - val_loss: 0.8984 - val_acc: 0.7863 - val_ignore_accuracy: 0.2207\n",
      "Epoch 3/40\n",
      "2894/2894 [==============================] - 11s 4ms/step - loss: 0.8729 - acc: 0.8085 - ignore_accuracy: 0.1650 - val_loss: 0.8709 - val_acc: 0.8131 - val_ignore_accuracy: 0.1354\n",
      "Epoch 4/40\n",
      "2894/2894 [==============================] - 11s 4ms/step - loss: 0.8492 - acc: 0.8149 - ignore_accuracy: 0.1361 - val_loss: 0.8525 - val_acc: 0.8130 - val_ignore_accuracy: 0.1355\n",
      "Epoch 5/40\n",
      "2894/2894 [==============================] - 11s 4ms/step - loss: 0.8297 - acc: 0.8149 - ignore_accuracy: 0.1361 - val_loss: 0.8345 - val_acc: 0.8130 - val_ignore_accuracy: 0.1353\n",
      "Epoch 6/40\n",
      "2894/2894 [==============================] - 11s 4ms/step - loss: 0.8118 - acc: 0.8154 - ignore_accuracy: 0.1378 - val_loss: 0.8174 - val_acc: 0.8182 - val_ignore_accuracy: 0.1565\n",
      "Epoch 7/40\n",
      "2894/2894 [==============================] - 11s 4ms/step - loss: 0.7956 - acc: 0.8196 - ignore_accuracy: 0.1552 - val_loss: 0.8028 - val_acc: 0.8193 - val_ignore_accuracy: 0.1612\n",
      "Epoch 8/40\n",
      "2894/2894 [==============================] - 11s 4ms/step - loss: 0.7792 - acc: 0.8230 - ignore_accuracy: 0.1697 - val_loss: 0.7858 - val_acc: 0.8308 - val_ignore_accuracy: 0.2147\n",
      "Epoch 9/40\n",
      "2894/2894 [==============================] - 11s 4ms/step - loss: 0.7578 - acc: 0.8334 - ignore_accuracy: 0.2186 - val_loss: 0.7571 - val_acc: 0.8319 - val_ignore_accuracy: 0.2198\n",
      "Epoch 10/40\n",
      "2894/2894 [==============================] - 11s 4ms/step - loss: 0.7217 - acc: 0.8361 - ignore_accuracy: 0.2314 - val_loss: 0.7154 - val_acc: 0.8383 - val_ignore_accuracy: 0.2502\n",
      "Epoch 11/40\n",
      "2894/2894 [==============================] - 11s 4ms/step - loss: 0.6681 - acc: 0.8560 - ignore_accuracy: 0.3251 - val_loss: 0.6503 - val_acc: 0.8677 - val_ignore_accuracy: 0.3859\n",
      "Epoch 12/40\n",
      "2894/2894 [==============================] - 11s 4ms/step - loss: 0.6031 - acc: 0.8786 - ignore_accuracy: 0.4306 - val_loss: 0.5822 - val_acc: 0.8787 - val_ignore_accuracy: 0.4373\n",
      "Epoch 13/40\n",
      "2894/2894 [==============================] - 11s 4ms/step - loss: 0.5330 - acc: 0.8868 - ignore_accuracy: 0.4690 - val_loss: 0.5139 - val_acc: 0.8894 - val_ignore_accuracy: 0.4873\n",
      "Epoch 14/40\n",
      "2894/2894 [==============================] - 11s 4ms/step - loss: 0.4625 - acc: 0.8980 - ignore_accuracy: 0.5220 - val_loss: 0.4467 - val_acc: 0.9029 - val_ignore_accuracy: 0.5498\n",
      "Epoch 15/40\n",
      "2894/2894 [==============================] - 11s 4ms/step - loss: 0.3945 - acc: 0.9133 - ignore_accuracy: 0.5943 - val_loss: 0.3842 - val_acc: 0.9177 - val_ignore_accuracy: 0.6191\n",
      "Epoch 16/40\n",
      "2894/2894 [==============================] - 11s 4ms/step - loss: 0.3310 - acc: 0.9282 - ignore_accuracy: 0.6635 - val_loss: 0.3297 - val_acc: 0.9302 - val_ignore_accuracy: 0.6769\n",
      "Epoch 17/40\n",
      "2894/2894 [==============================] - 11s 4ms/step - loss: 0.2758 - acc: 0.9410 - ignore_accuracy: 0.7236 - val_loss: 0.2844 - val_acc: 0.9385 - val_ignore_accuracy: 0.7157\n",
      "Epoch 18/40\n",
      "2894/2894 [==============================] - 11s 4ms/step - loss: 0.2290 - acc: 0.9504 - ignore_accuracy: 0.7676 - val_loss: 0.2496 - val_acc: 0.9459 - val_ignore_accuracy: 0.7499\n",
      "Epoch 19/40\n",
      "2894/2894 [==============================] - 11s 4ms/step - loss: 0.1911 - acc: 0.9593 - ignore_accuracy: 0.8097 - val_loss: 0.2219 - val_acc: 0.9520 - val_ignore_accuracy: 0.7781\n",
      "Epoch 20/40\n",
      "2894/2894 [==============================] - 11s 4ms/step - loss: 0.1596 - acc: 0.9668 - ignore_accuracy: 0.8447 - val_loss: 0.2009 - val_acc: 0.9566 - val_ignore_accuracy: 0.7995\n",
      "Epoch 21/40\n",
      "2894/2894 [==============================] - 11s 4ms/step - loss: 0.1337 - acc: 0.9732 - ignore_accuracy: 0.8745 - val_loss: 0.1833 - val_acc: 0.9608 - val_ignore_accuracy: 0.8194\n",
      "Epoch 22/40\n",
      "2894/2894 [==============================] - 11s 4ms/step - loss: 0.1125 - acc: 0.9784 - ignore_accuracy: 0.8991 - val_loss: 0.1701 - val_acc: 0.9639 - val_ignore_accuracy: 0.8339\n",
      "Epoch 23/40\n",
      "2894/2894 [==============================] - 11s 4ms/step - loss: 0.0953 - acc: 0.9821 - ignore_accuracy: 0.9164 - val_loss: 0.1600 - val_acc: 0.9659 - val_ignore_accuracy: 0.8430\n",
      "Epoch 24/40\n",
      "2894/2894 [==============================] - 11s 4ms/step - loss: 0.0815 - acc: 0.9850 - ignore_accuracy: 0.9298 - val_loss: 0.1515 - val_acc: 0.9675 - val_ignore_accuracy: 0.8503\n",
      "Epoch 25/40\n",
      "2894/2894 [==============================] - 11s 4ms/step - loss: 0.0701 - acc: 0.9873 - ignore_accuracy: 0.9405 - val_loss: 0.1449 - val_acc: 0.9688 - val_ignore_accuracy: 0.8565\n",
      "Epoch 26/40\n",
      "2894/2894 [==============================] - 11s 4ms/step - loss: 0.0610 - acc: 0.9890 - ignore_accuracy: 0.9485 - val_loss: 0.1396 - val_acc: 0.9699 - val_ignore_accuracy: 0.8619\n",
      "Epoch 27/40\n",
      "2894/2894 [==============================] - 11s 4ms/step - loss: 0.0534 - acc: 0.9904 - ignore_accuracy: 0.9553 - val_loss: 0.1349 - val_acc: 0.9707 - val_ignore_accuracy: 0.8654\n",
      "Epoch 28/40\n",
      "2894/2894 [==============================] - 11s 4ms/step - loss: 0.0472 - acc: 0.9915 - ignore_accuracy: 0.9602 - val_loss: 0.1329 - val_acc: 0.9713 - val_ignore_accuracy: 0.8683\n",
      "Epoch 29/40\n",
      "2894/2894 [==============================] - 11s 4ms/step - loss: 0.0421 - acc: 0.9924 - ignore_accuracy: 0.9643 - val_loss: 0.1296 - val_acc: 0.9721 - val_ignore_accuracy: 0.8721\n",
      "Epoch 30/40\n",
      "2894/2894 [==============================] - 11s 4ms/step - loss: 0.0377 - acc: 0.9931 - ignore_accuracy: 0.9678 - val_loss: 0.1279 - val_acc: 0.9722 - val_ignore_accuracy: 0.8730\n",
      "Epoch 31/40\n",
      "2894/2894 [==============================] - 11s 4ms/step - loss: 0.0341 - acc: 0.9937 - ignore_accuracy: 0.9706 - val_loss: 0.1259 - val_acc: 0.9724 - val_ignore_accuracy: 0.8742\n",
      "Epoch 32/40\n",
      "2894/2894 [==============================] - 11s 4ms/step - loss: 0.0309 - acc: 0.9942 - ignore_accuracy: 0.9729 - val_loss: 0.1247 - val_acc: 0.9730 - val_ignore_accuracy: 0.8772\n",
      "Epoch 33/40\n",
      "2894/2894 [==============================] - 11s 4ms/step - loss: 0.0281 - acc: 0.9948 - ignore_accuracy: 0.9757 - val_loss: 0.1236 - val_acc: 0.9732 - val_ignore_accuracy: 0.8788\n",
      "Epoch 34/40\n",
      "2894/2894 [==============================] - 11s 4ms/step - loss: 0.0257 - acc: 0.9952 - ignore_accuracy: 0.9775 - val_loss: 0.1231 - val_acc: 0.9731 - val_ignore_accuracy: 0.8780\n",
      "Epoch 35/40\n",
      "2894/2894 [==============================] - 11s 4ms/step - loss: 0.0236 - acc: 0.9956 - ignore_accuracy: 0.9792 - val_loss: 0.1210 - val_acc: 0.9735 - val_ignore_accuracy: 0.8789\n",
      "Epoch 36/40\n",
      "2894/2894 [==============================] - 11s 4ms/step - loss: 0.0217 - acc: 0.9959 - ignore_accuracy: 0.9809 - val_loss: 0.1217 - val_acc: 0.9735 - val_ignore_accuracy: 0.8785\n",
      "Epoch 37/40\n",
      "2894/2894 [==============================] - 11s 4ms/step - loss: 0.0201 - acc: 0.9963 - ignore_accuracy: 0.9827 - val_loss: 0.1210 - val_acc: 0.9737 - val_ignore_accuracy: 0.8804\n",
      "Epoch 38/40\n",
      "2894/2894 [==============================] - 11s 4ms/step - loss: 0.0185 - acc: 0.9966 - ignore_accuracy: 0.9840 - val_loss: 0.1212 - val_acc: 0.9736 - val_ignore_accuracy: 0.8800\n",
      "Epoch 39/40\n",
      "2894/2894 [==============================] - 11s 4ms/step - loss: 0.0171 - acc: 0.9969 - ignore_accuracy: 0.9855 - val_loss: 0.1216 - val_acc: 0.9735 - val_ignore_accuracy: 0.8792\n",
      "Epoch 40/40\n",
      "2894/2894 [==============================] - 11s 4ms/step - loss: 0.0159 - acc: 0.9971 - ignore_accuracy: 0.9865 - val_loss: 0.1207 - val_acc: 0.9737 - val_ignore_accuracy: 0.8802\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f611615dc50>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_sentences_X, to_categorical(train_tags_y, len(tag2index)), batch_size=128, epochs=40, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LnExWbEmIa5U"
   },
   "source": [
    "### Calculamos nuevamente la Precisión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FKOa73gRNMm7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1206/1206 [==============================] - 5s 4ms/step\n",
      "acc: 97.29261903422784\n"
     ]
    }
   ],
   "source": [
    "scores2 = model.evaluate(test_sentences_X, to_categorical(test_tags_y, len(tag2index)))\n",
    "print(f\"{model.metrics_names[1]}: {scores2[1] * 100}\")   # acc: 99.09751977804825"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZzeCdasrIkuN"
   },
   "source": [
    "### Relaizamos nuevamente el calculo de F1-score, recall, y precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VbqNJa0pIvVT"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Nri9gFnwIxcN"
   },
   "source": [
    "### Realizamos nuevamente una prueba con el Ejemplo de Prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xruHro6L-LT2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['vmn0000', 'vsip3s0', 'aq0cs0', 'sps00', 'np0000l', 'Fp', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-'], ['da0ms0', 'ncms000', 'aq0cs0', 'vmip3s0', 'sps00', 'da0ms0', 'ncms000', 'sps00', 'sps00', 'ncms000', 'sps00', 'np0000l', 'Fp', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-']]\n"
     ]
    }
   ],
   "source": [
    "predictions1 = model.predict(test_samples_X)\n",
    "log_tokens1  = logits_to_tokens(predictions1, {i: t for t, i in tag2index.items()})\n",
    "print(log_tokens1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VL9taLbrI641"
   },
   "source": [
    "### Presentamos los Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QeRx8eSThbuq"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correr    es       importante    para    mi      .\n",
      "--------  -------  ------------  ------  ------  ---\n",
      "vmn0000   vsip3s0  aq0cs0        sps00   dp1css  Fp\n",
      "\n",
      "\n",
      "El      hombre    bajo    corre    bajo    el      puente    con    bajo    índice    de     adrenalina    .\n",
      "------  --------  ------  -------  ------  ------  --------  -----  ------  --------  -----  ------------  ---\n",
      "da0ms0  ncms000   aq0ms0  vmip3s0  sps00   da0ms0  ncms000   sps00  sps00   ncms000   sps00  np0000l       Fp\n"
     ]
    }
   ],
   "source": [
    "from tabulate import tabulate\n",
    "\n",
    "heads1 = test_samples[0]\n",
    "body1 = [log_tokens[0][:len(test_samples[0])]]\n",
    "\n",
    "heads2 = test_samples[1]\n",
    "body2 = [log_tokens[1][:len(test_samples[1])]]\n",
    "\n",
    "print(tabulate(body1, headers=heads1))\n",
    "\n",
    "print (\"\\n\")\n",
    "\n",
    "print(tabulate(body2, headers=heads2))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Preprocesamiento-Copy1.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
